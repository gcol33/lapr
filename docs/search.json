[{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Algorithm Details and Mathematical Foundations","text":"vignette provides detailed mathematical background algorithms implemented couplr. Understanding algorithms helps : Choose right method specific problem characteristics Debug unexpected behavior performance issues Appreciate theoretical foundations underlying assignment optimization","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"who-this-vignette-is-for","dir":"Articles","previous_headings":"Overview","what":"Who This Vignette Is For","title":"Algorithm Details and Mathematical Foundations","text":"Audience: Intermediate users, researchers, algorithm enthusiasts Prerequisites: Familiarity basic couplr usage (vignette(\"getting-started\")) Basic linear algebra (matrix notation) Comfort Big-O complexity notation ’ll Learn: algorithm works conceptual mathematical level use algorithm () Trade-offs algorithms Numerical considerations failure modes Time complete: 45-60 minutes (conceptual reading)","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"documentation-roadmap","dir":"Articles","previous_headings":"Overview","what":"Documentation Roadmap","title":"Algorithm Details and Mathematical Foundations","text":": Algorithms","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"formal-definition","dir":"Articles","previous_headings":"The Linear Assignment Problem","what":"Formal Definition","title":"Algorithm Details and Mathematical Foundations","text":"Given cost matrix C∈ℝn×mC \\\\mathbb{R}^{n \\times m}, linear assignment problem (LAP) seeks set assignments minimizes total cost: min⁡∑=1n∑j=1mcijxij \\min \\sum_{=1}^{n} \\sum_{j=1}^{m} c_{ij} x_{ij} subject : ∑j=1mxij≤1∀∈{1,…,n}∑=1nxij≤1∀j∈{1,…,m}xij∈{0,1}∀,j \\begin{aligned} \\sum_{j=1}^{m} x_{ij} &\\leq 1 \\quad \\forall \\\\{1,\\ldots,n\\} \\\\ \\sum_{=1}^{n} x_{ij} &\\leq 1 \\quad \\forall j \\\\{1,\\ldots,m\\} \\\\ x_{ij} &\\\\{0,1\\} \\quad \\forall ,j \\end{aligned} xij=1x_{ij} = 1 source ii assigned target jj, xij=0x_{ij} = 0 otherwise. constraints ensure source assigned one target, target receives one source.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"duality-and-optimality-conditions","dir":"Articles","previous_headings":"The Linear Assignment Problem","what":"Duality and Optimality Conditions","title":"Algorithm Details and Mathematical Foundations","text":"LAP strong dual formulation. source ii target jj, associate dual variables uiu_i vjv_j. dual problem : max⁡∑=1nui+∑j=1mvj \\max \\sum_{=1}^{n} u_i + \\sum_{j=1}^{m} v_j subject : ui+vj≤cij∀,j u_i + v_j \\leq c_{ij} \\quad \\forall ,j primal-dual solution (x*,u*,v*)(x^*, u^*, v^*) optimal satisfies complementary slackness: xij*>0⟹ui*+vj*=cij x_{ij}^* > 0 \\implies u_i^* + v_j^* = c_{ij} condition means assignments along tight edges (dual constraint holds equality) can part optimal solution. principle underlies efficient LAP algorithms.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"visualizing-the-assignment-problem","dir":"Articles","previous_headings":"The Linear Assignment Problem","what":"Visualizing the Assignment Problem","title":"Algorithm Details and Mathematical Foundations","text":"helps think LAP weighted bipartite graph: algorithms solve problem take different paths solution space.","code":"Sources (rows)          Targets (columns)      S₁ ───────2──────── T₁      │ ╲     ╱         ╱│      │  ╲4  ╱3        ╱ │      3   ╲ ╱        5   1      │    ╳          ╱  │      │   ╱ ╲       ╱    │     S₂ ─╱───╲──1──╱──── T₂        ╱     ╲   ╱     ╱       ╱       ╲ ╱    2     S₃ ────3───╳───── T₃  Edge weights = costs Goal: Select one edge per source, one per target, minimizing total weight"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"algorithm-selection-guide","dir":"Articles","previous_headings":"","what":"Algorithm Selection Guide","title":"Algorithm Details and Mathematical Foundations","text":"diving individual algorithms, ’s decision framework:","code":"Is the cost matrix binary (0/1)?                               |               ┌───────────────┴───────────────┐               Yes                             No               |                               |           Use HK01                    Is sparsity > 50%?                                               |                               ┌───────────────┴───────────────┐                               Yes                             No                               |                               |                           Use SAP                      Is n > 1000?                                                               |                                               ┌───────────────┴───────────────┐                                               Yes                             No                                               |                               |                                           Use Auction              Use JV (default)                                           or consider                                           approximations"},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"head-to-head-comparison","dir":"Articles","previous_headings":"Algorithm Selection Guide","what":"Head-to-Head Comparison","title":"Algorithm Details and Mathematical Foundations","text":"✓✓✓ = Excellent | ✓✓ = Good | ✓ = Acceptable | ✗ = recommended","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"hungarian-algorithm","dir":"Articles","previous_headings":"Algorithms in couplr","what":"Hungarian Algorithm","title":"Algorithm Details and Mathematical Foundations","text":"Complexity: O(n3)O(n^3) square problems, O(n2m)O(n^2m) rectangular Hungarian algorithm, developed Kuhn (1955) based work Kőnig Egerváry, classical method solving LAP. maintains dual feasibility throughout iteratively improves primal solution.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"algorithm-steps","dir":"Articles","previous_headings":"Algorithms in couplr > Hungarian Algorithm","what":"Algorithm Steps","title":"Algorithm Details and Mathematical Foundations","text":"Initialization: Start feasible dual solution, typically: ui=minjcij,vj=0u_i = \\min_j c_{ij}, \\quad v_j = 0 Construct equality graph: Build graph G=G_= containing tight edges: G=={(,j):ui+vj=cij}G_= = \\{(,j) : u_i + v_j = c_{ij}\\} Find maximum matching: Compute maximum cardinality matching MM G=G_= Check optimality: |M|=n|M| = n (sources matched), solution optimal Dual update: Otherwise, find minimum dual update adds new tight edges: Compute alternating tree unmatched sources Let SS sources tree, TT targets tree Compute Δ=min⁡∈S,j∉T(cij−ui−vj)\\Delta = \\min_{\\S, j \\notin T} (c_{ij} - u_i - v_j) Update: ui←ui+Δu_i \\leftarrow u_i + \\Delta ∈Si \\S, vj←vj−Δv_j \\leftarrow v_j - \\Delta j∈Tj \\T Repeat: Return step 2 updated dual variables","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-to-use","dir":"Articles","previous_headings":"Algorithms in couplr > Hungarian Algorithm","what":"When to Use","title":"Algorithm Details and Mathematical Foundations","text":"Hungarian algorithm : Exact: Always finds optimal solution Pedagogical: Easy understand conceptually Moderate performance: Good small medium problems (< 500×500) Stable: Numerically robust clean termination","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-not-to-use","dir":"Articles","previous_headings":"Algorithms in couplr > Hungarian Algorithm","what":"When NOT to Use","title":"Algorithm Details and Mathematical Foundations","text":"Large problems (n > 500): JV Auction significantly faster Sparse problems: SAP exploits sparsity; Hungarian Performance-critical applications: O(n³)O(n³) complexity accumulates quickly","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"edge-cases-and-limitations","dir":"Articles","previous_headings":"Algorithms in couplr > Hungarian Algorithm","what":"Edge Cases and Limitations","title":"Algorithm Details and Mathematical Foundations","text":"Rectangular matrices: Handled padding internally, less efficient SAP Multiple optimal solutions: Returns one arbitrarily (deterministic specified) Degenerate problems: Handles ties gracefully via perturbation","code":"# Example with Hungarian algorithm cost <- matrix(c(   10, 19, 8,   15, 10, 11,   9, 12, 14 ), nrow = 3, byrow = TRUE)  result <- lap_solve(cost, method = \"hungarian\") print(result) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      3     8 #> 2      2      2    10 #> 3      3      1     9 #>  #> Total cost: 27  #> Method: hungarian"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"jonker-volgenant-algorithm","dir":"Articles","previous_headings":"Algorithms in couplr","what":"Jonker-Volgenant Algorithm","title":"Algorithm Details and Mathematical Foundations","text":"Complexity: O(n3)O(n^3) expected time, O(n2)O(n^2) space Jonker-Volgenant (JV) algorithm (1987) optimized variant shortest augmenting path approach. ’s default algorithm couplr provides good performance problem types.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"key-ideas","dir":"Articles","previous_headings":"Algorithms in couplr > Jonker-Volgenant Algorithm","what":"Key Ideas","title":"Algorithm Details and Mathematical Foundations","text":"Shortest augmenting paths: Rather finding maximum matchings equality graphs, JV builds augmenting paths reduced cost graph respect dual variables Column reduction: initial preprocessing phase assigns targets greedily minimize reduced costs Auction phase: rapid auction-style update improves multiple dual variables simultaneously Shortest path phase: Classical shortest augmenting path handle remaining unmatched sources algorithm maintains ϵ\\epsilon-complementary slackness execution, allowing take larger steps classical Hungarian method still guaranteeing exact optimality termination.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"algorithm-phases","dir":"Articles","previous_headings":"Algorithms in couplr > Jonker-Volgenant Algorithm","what":"Algorithm Phases","title":"Algorithm Details and Mathematical Foundations","text":"Phase 1: Column Reduction target jj, find source *^* minimum cost: *=arg⁡miniciji^* = \\arg\\min_i c_{ij} *^* unmatched, assign (*,j)(^*, j) set vj=ci*jv_j = c_{^*j}. provides good initial solution dual bounds. Phase 2: Reduction Transfer Update dual variables satisfy reduced cost constraints: ui=minj(cij−vj)u_i = \\min_j (c_{ij} - v_j) Phase 3: Augmentation unmatched source: Build shortest augmenting path tree using Dijkstra-style search reduced costs Update dual variables along path Augment matching","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-to-use-1","dir":"Articles","previous_headings":"Algorithms in couplr > Jonker-Volgenant Algorithm","what":"When to Use","title":"Algorithm Details and Mathematical Foundations","text":"Jonker-Volgenant : Efficient: Good general-purpose performance, especially dense problems Default choice: Used method = \"auto\" problems Memory efficient: O(n2)O(n^2) space even dense problems","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-not-to-use-1","dir":"Articles","previous_headings":"Algorithms in couplr > Jonker-Volgenant Algorithm","what":"When NOT to Use","title":"Algorithm Details and Mathematical Foundations","text":"Extremely sparse problems: SAP faster Binary costs: HK01 specialized faster Need guaranteed worst-case: JV excellent average case auction may predictable","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"edge-cases-and-limitations-1","dir":"Articles","previous_headings":"Algorithms in couplr > Jonker-Volgenant Algorithm","what":"Edge Cases and Limitations","title":"Algorithm Details and Mathematical Foundations","text":"Cycling: Rare, possible near-degenerate problems. Implementation includes safeguards. Negative costs: Handled correctly (unlike implementations) Large cost ranges: May lose precision; consider scaling costs similar magnitude","code":"# Jonker-Volgenant on a larger problem set.seed(123) n <- 100 large_cost <- matrix(runif(n * n, 0, 100), n, n)  system.time({   result <- lap_solve(large_cost, method = \"jv\") }) #>    user  system elapsed  #>       0       0       0  cat(\"Total cost:\", get_total_cost(result), \"\\n\") #> Total cost: 149.0911"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"auction-algorithm-family","dir":"Articles","previous_headings":"Algorithms in couplr","what":"Auction Algorithm Family","title":"Algorithm Details and Mathematical Foundations","text":"Complexity: O(n2log⁡(nC)/ϵ)O(n^2 \\log(nC) / \\epsilon) maximum cost CC ϵ\\epsilon-optimality auction algorithm, developed Bertsekas (1988), takes economic approach assignment problem. Sources “bid” targets, prices (dual variables) adjust based competition. couplr implements three variants auction algorithm, different performance characteristics.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"core-auction-concept","dir":"Articles","previous_headings":"Algorithms in couplr > Auction Algorithm Family","what":"Core Auction Concept","title":"Algorithm Details and Mathematical Foundations","text":"auction variants share fundamental approach: Initialization: Set prices pj=0p_j = 0 (dual variables) Bidding phase: unmatched source ii finds best target: j*=arg⁡maxj(vij−pj)j^* = \\arg\\max_j (v_{ij} - p_j) vijv_{ij} value (negative cost) assigning ii jj Compute bid: Source ii bids target j*j^* increment: bidi=(vij*−pj*)−(vij2nd−pj2nd)+ϵ\\text{bid}_i = (v_{ij^*} - p_{j^*}) - (v_{ij^{\\text{2nd}}} - p_{j^{\\text{2nd}}}) + \\epsilon j2ndj^{\\text{2nd}} second-best target ii Assignment phase: target jj receiving bids: Assign jj highest bidder *^* Update price: pj←pj+bidi*p_j \\leftarrow p_j + \\text{bid}_{^*} Remove previous assignment jj () Repeat: Continue sources matched variants differ epsilon management, bidding order, convergence strategies.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"variant-1-standard-fixed-epsilon-auction","dir":"Articles","previous_headings":"Algorithms in couplr > Auction Algorithm Family","what":"Variant 1: Standard Fixed-Epsilon Auction","title":"Algorithm Details and Mathematical Foundations","text":"use: Default auction choice, general-purpose Key features: Uses adaptive epsilon: ϵ=spread/(2n2)\\epsilon = \\text{spread} / (2n^2) based cost range Queue-based: maintains unmatched sources queue, processes LIFO order Fast convergence problem types Good numerical stability Algorithm details: epsilon chosen balance speed accuracy: - large: fast may produce suboptimal results - small: slow convergence - Adaptive formula scales problem size cost range Epsilon selection: gives ϵ\\epsilon-optimality final cost within nϵn\\epsilon true optimum.","code":"lap_solve(cost, method = \"auction\") double spread = max_cost - min_cost; epsilon = spread / (2.0 * n * n); epsilon = max(epsilon, 1e-12);  // Defensive lower bound"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"variant-2-scaled-epsilon-auction","dir":"Articles","previous_headings":"Algorithms in couplr > Auction Algorithm Family","what":"Variant 2: Scaled-Epsilon Auction","title":"Algorithm Details and Mathematical Foundations","text":"use: Problems large cost ranges tighter optimality needed Key features: Epsilon-scaling phases: Starts large ϵ\\epsilon, progressively reduces Discards rebuilds matching phase Fewer total bids fixed-epsilon large-range problems Better final accuracy Algorithm structure: Initial epsilon: ϵ0=max⁡|cij|\\epsilon_0 = \\max|c_{ij}| (maximum absolute cost) Phase loop: Price updates: Uses cost minimization formulation prices decrease: pj←pj−(γ+ϵ)p_j \\leftarrow p_j - (\\gamma + \\epsilon) γ=second_best_cost−best_cost\\gamma = \\text{second\\_best\\_cost} - \\text{best\\_cost} Phases: Typically 3-7 phases depending cost range alpha parameter. Convergence: phase solves easier problem (larger ϵ\\epsilon), providing warm start next phase. Performance: - Better fixed-epsilon : cost range > 10610^6, need high accuracy - Worse fixed-epsilon : costs similar magnitude","code":"lap_solve(cost, method = \"auction_scaled\") for each phase:   epsilon = epsilon / alpha  (typically alpha = 7)   discard all assignments   rebuild complete matching at new epsilon   until epsilon < epsilon_final # Example with large cost range set.seed(123) n <- 50 cost <- matrix(runif(n * n, 1, 1e6), n, n)  # Large range: 1 to 1,000,000  system.time({   result_scaled <- lap_solve(cost, method = \"auction_scaled\") }) #>    user  system elapsed  #>       0       0       0  cat(\"Total cost:\", get_total_cost(result_scaled), \"\\n\") #> Total cost: 1543862"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"variant-3-gauss-seidel-auction","dir":"Articles","previous_headings":"Algorithms in couplr > Auction Algorithm Family","what":"Variant 3: Gauss-Seidel Auction","title":"Algorithm Details and Mathematical Foundations","text":"use: Problems sequential processing may exploit structure Key features: Sequential bidding: Processes sources order (1, 2, …, n) Immediate price updates: Price changes affect subsequent bids iteration Can converge faster problems spatial structure Handles n>mn > m automatically via internal transpose Algorithm details: Unlike queue-based approach, Gauss-Seidel sweeps sources: Key difference: Price update applied immediately, affecting next source’s decision sweep. Convergence behavior: Can faster queue-based problem structure Sequential processing can exploit correlations nearby sources Adaptive epsilon matching standard auction: ϵ=spread/(2n2)\\epsilon = \\text{spread} / (2n^2) Auto-transpose: n>mn > m, automatically transposes problem internally converts result back.","code":"lap_solve(cost, method = \"auction_gs\") repeat until converged:   for i = 1 to n:     if i is unmatched or displaced:       find best and second-best objects       compute bid = best - second + epsilon       update price[j_best] += bid       update assignments (may displace another source) # Example with spatial structure set.seed(456) n <- 100 # Create cost matrix with spatial correlation x_source <- 1:n y_source <- 1:n cost <- outer(x_source, y_source, function(i, j) abs(i - j) + runif(n*n, 0, 5))  system.time({   result_gs <- lap_solve(cost, method = \"auction_gs\") }) #>    user  system elapsed  #>       0       0       0  cat(\"Total cost:\", get_total_cost(result_gs), \"\\n\") #> Total cost: 204.2516"},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-to-use-which-auction-variant","dir":"Articles","previous_headings":"Algorithms in couplr > Auction Algorithm Family","what":"When to Use Which Auction Variant","title":"Algorithm Details and Mathematical Foundations","text":"Use standard auction (method = \"auction\"): - General-purpose default - Medium large dense problems (n>500n > 500) - Costs vary within reasonable range (< 10610^6 spread) - Want predictable, reliable performance Use scaled-epsilon (method = \"auction_scaled\"): - large cost ranges (spread > 10610^6) - Need provably tighter optimality bounds - Willing trade initial phase overhead better final accuracy - Integer costs large variation Use Gauss-Seidel (method = \"auction_gs\"): - Problem spatial sequential structure - n>mn > m problems (auto-handles via transpose) - Experimentation compare standard - Sequential access patterns may help cache performance","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"auction-algorithm-advantages","dir":"Articles","previous_headings":"Algorithms in couplr > Auction Algorithm Family","what":"Auction Algorithm Advantages","title":"Algorithm Details and Mathematical Foundations","text":"auction algorithm suitable : Large dense problems: Scales n>1000n > 1000 Parallel implementation: Bidding phase naturally parallelizes (future work) Approximate solutions: Can terminate early ϵ\\epsilon-optimal solutions Integer costs: Efficient small integer costs Numerical Stability: auction variants include safeguards: - Tie-breaking via deterministic perturbation (prevents cycling) - Iteration guards (prevent infinite loops) - Epsilon clamping (prevents denormal numbers) - Spread-based epsilon (scale-invariant)","code":"# Comparison on a medium-sized problem set.seed(789) n <- 200 cost <- matrix(runif(n * n, 0, 100), n, n)  times <- c(   standard = system.time(lap_solve(cost, method = \"auction\"))[\"elapsed\"],   scaled = system.time(lap_solve(cost, method = \"auction_scaled\"))[\"elapsed\"],   gauss_seidel = system.time(lap_solve(cost, method = \"auction_gs\"))[\"elapsed\"] )  print(times) #>     standard.elapsed       scaled.elapsed gauss_seidel.elapsed  #>                 0.00                 0.00                 0.02"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"sparse-assignment-sap","dir":"Articles","previous_headings":"Algorithms in couplr","what":"Sparse Assignment (SAP)","title":"Algorithm Details and Mathematical Foundations","text":"Complexity: O(n2+nm)O(n^2 + nm) sparse problems mm edges SAP algorithm optimized sparse problems cost matrix entries effectively infinite (forbidden assignments). uses efficient sparse data structures specialized shortest path algorithms.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"sparse-representation","dir":"Articles","previous_headings":"Algorithms in couplr > Sparse Assignment (SAP)","what":"Sparse Representation","title":"Algorithm Details and Mathematical Foundations","text":"Instead storing n×nn \\times n matrix, SAP maintains: Adjacency lists: non-forbidden edges stored Compressed costs: Efficient lookup edge costs Sparse priority queues: Fast extraction minimum reduced costs","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"algorithm-strategy","dir":"Articles","previous_headings":"Algorithms in couplr > Sparse Assignment (SAP)","what":"Algorithm Strategy","title":"Algorithm Details and Mathematical Foundations","text":"Graph construction: Build sparse directed graph edges finite costs Initialization: Set dual variables based minimum outgoing costs Shortest paths: Use Dijkstra’s algorithm (Bellman-Ford negative costs) reduced cost graph Path augmentation: Augment matching along shortest paths update dual variables","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-to-use-2","dir":"Articles","previous_headings":"Algorithms in couplr > Sparse Assignment (SAP)","what":"When to Use","title":"Algorithm Details and Mathematical Foundations","text":"SAP optimal : Sparse problems: > 50% entries forbidden (NA Inf) Rectangular problems: Naturally handles n×mn \\times m problems efficiently Structured sparsity: Problems known graph structure Large sparse: Can handle large nn sparsity high","code":"# Sparse assignment problem set.seed(789) n <- 200 # Create sparse cost matrix (70% forbidden) cost <- matrix(Inf, n, n) n_edges <- floor(0.3 * n^2) edges <- sample(1:(n^2), n_edges) cost[edges] <- runif(n_edges, 0, 100)  system.time({   result <- lap_solve(cost, method = \"sap\") }) #>    user  system elapsed  #>    0.02    0.00    0.02  cat(\"Assignments found:\", nrow(result), \"\\n\") #> Assignments found: 200 cat(\"Total cost:\", get_total_cost(result), \"\\n\") #> Total cost: 564.3393"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"hopcroft-karp-for-binary-costs-hk01","dir":"Articles","previous_headings":"Algorithms in couplr","what":"Hopcroft-Karp for Binary Costs (HK01)","title":"Algorithm Details and Mathematical Foundations","text":"Complexity: O(n2.5)O(n^{2.5}) binary cost matrices HK01 algorithm specialized problems costs either 0 1 (binary). ’s based Hopcroft-Karp algorithm maximum cardinality bipartite matching.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"binary-problem-structure","dir":"Articles","previous_headings":"Algorithms in couplr > Hopcroft-Karp for Binary Costs (HK01)","what":"Binary Problem Structure","title":"Algorithm Details and Mathematical Foundations","text":"costs cij∈{0,1}c_{ij} \\\\{0, 1\\}, LAP reduces : Find maximum matching subgraph 0-cost edges complete: optimal solution (cost = 0 matched edges) Otherwise: Augment minimum number 1-cost edges","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"algorithm-approach","dir":"Articles","previous_headings":"Algorithms in couplr > Hopcroft-Karp for Binary Costs (HK01)","what":"Algorithm Approach","title":"Algorithm Details and Mathematical Foundations","text":"Phase 1: Maximum matching 0-edges: Use Hopcroft-Karp find maximum matching using zero-cost edges Phase 2: Augmentation: matching incomplete, augment using shortest augmenting paths full graph Hopcroft-Karp algorithm finds maximal sets augmenting paths simultaneously, achieving O(n)O(\\sqrt{n}) augmentation phases.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-to-use-3","dir":"Articles","previous_headings":"Algorithms in couplr > Hopcroft-Karp for Binary Costs (HK01)","what":"When to Use","title":"Algorithm Details and Mathematical Foundations","text":"HK01 designed : Binary costs: Problems cij∈{0,1}c_{ij} \\\\{0, 1\\} Uniform costs: Problems costs equal (can transformed binary) Bipartite matching: Unweighted unit-weight bipartite matching large binary problems: Can handle n>10000n > 10000 efficiently","code":"# Binary cost problem set.seed(101) n <- 300 binary_cost <- matrix(sample(0:1, n^2, replace = TRUE, prob = c(0.3, 0.7)), n, n)  system.time({   result <- lap_solve(binary_cost, method = \"hk01\") }) #>    user  system elapsed  #>       0       0       0  cat(\"Total cost:\", get_total_cost(result), \"\\n\") #> Total cost: 0"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"murtys-algorithm-for-k-best-solutions","dir":"Articles","previous_headings":"","what":"Murty’s Algorithm for K-Best Solutions","title":"Algorithm Details and Mathematical Foundations","text":"Complexity: O(k⋅T(n))O(k \\cdot T(n)) T(n)T(n) complexity solving single LAP Murty’s algorithm (1968) finds k best assignments order increasing cost. ’s based partition solution space search tree.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"algorithm-structure","dir":"Articles","previous_headings":"Murty’s Algorithm for K-Best Solutions","what":"Algorithm Structure","title":"Algorithm Details and Mathematical Foundations","text":"Solve initial LAP: Find optimal assignment *^* using LAP solver Partitioning: kk-th best solution: Take partial assignment priority queue Forbid one edge current solution Force edges included Solve modified LAP Add new partial solution queue Priority queue: Maintain solutions ranked total cost Repeat: Extract next best solution partition k solutions found","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"partition-tree-structure","dir":"Articles","previous_headings":"Murty’s Algorithm for K-Best Solutions","what":"Partition Tree Structure","title":"Algorithm Details and Mathematical Foundations","text":"algorithm maintains tree : Root: Complete optimal assignment Internal nodes: Partial assignments edges forced/forbidden Leaves: Complete assignments Children: Formed adding one constraint node, solve constrained LAP : edges forced solution edges forbidden solution remaining edges solved optimally","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-to-use-4","dir":"Articles","previous_headings":"Murty’s Algorithm for K-Best Solutions","what":"When to Use","title":"Algorithm Details and Mathematical Foundations","text":"K-best solutions useful : Robustness analysis: Understanding sensitivity cost perturbations Alternative plans: backup assignments constraints change Decision support: Presenting multiple good options human decision-makers Cost landscapes: Understanding structure near-optimal solutions","code":"# Find k-best solutions cost <- matrix(c(   10, 19, 8, 15,   10, 18, 7, 17,   13, 16, 9, 14,   12, 19, 8, 18 ), nrow = 4, byrow = TRUE)  kbest <- lap_solve_kbest(cost, k = 10)  # Show cost progression summary(kbest) |>    print(n = 10) #> # A tibble: 10 × 4 #>     rank solution_id total_cost n_assignments #>    <int>       <int>      <dbl>         <int> #>  1     1           1         49             4 #>  2     2           2         50             4 #>  3     3           3         50             4 #>  4     4           4         51             4 #>  5     5           5         51             4 #>  6     6           6         51             4 #>  7     7           7         51             4 #>  8     8           8         52             4 #>  9     9           9         52             4 #> 10    10          10         52             4"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"automatic-algorithm-selection","dir":"Articles","previous_headings":"","what":"Automatic Algorithm Selection","title":"Algorithm Details and Mathematical Foundations","text":"method = \"auto\" option uses heuristics select best algorithm: selection provides good performance across diverse problem types without requiring user expertise.","code":"auto_select <- function(cost_matrix) {   n <- nrow(cost_matrix)   m <- ncol(cost_matrix)      # Check for binary costs   if (all(cost_matrix %in% c(0, 1, NA, Inf))) {     return(\"hk01\")  # Binary costs → HK01   }      # Check sparsity   finite_ratio <- sum(is.finite(cost_matrix)) / (n * m)   if (finite_ratio < 0.3 || abs(n - m) > 0.5 * max(n, m)) {     return(\"sap\")  # Sparse or very rectangular → SAP   }      # Large dense problems   if (n > 1000) {     return(\"auction\")  # Large → Auction   }      # Default: Jonker-Volgenant   return(\"jv\") }"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"performance-comparison","dir":"Articles","previous_headings":"","what":"Performance Comparison","title":"Algorithm Details and Mathematical Foundations","text":"’s rough guide algorithm performance: † sparse problems (< 30% density) ‡ binary costs ","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"floating-point-precision","dir":"Articles","previous_headings":"Numerical Considerations","what":"Floating Point Precision","title":"Algorithm Details and Mathematical Foundations","text":"algorithms handle floating-point costs correctly, aware: Rounding errors: Can accumulate dual variables Tight tolerances: Complementary slackness checked ϵ=10−10\\epsilon = 10^{-10} Large cost ranges: Avoid mixing costs differ > 101210^{12}","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"integer-costs","dir":"Articles","previous_headings":"Numerical Considerations","what":"Integer Costs","title":"Algorithm Details and Mathematical Foundations","text":"integer costs, algorithms exact guarantee integer optimal dual variables.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"numerical-stability","dir":"Articles","previous_headings":"Numerical Considerations","what":"Numerical Stability","title":"Algorithm Details and Mathematical Foundations","text":"implementations include safeguards: Overflow detection: Large costs clamped prevent overflow Epsilon comparisons: Floating-point comparisons use tolerances Dual feasibility: Maintained throughout algorithm execution","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"when-algorithms-fail","dir":"Articles","previous_headings":"","what":"When Algorithms Fail","title":"Algorithm Details and Mathematical Foundations","text":"Understanding failure modes helps debug unexpected results.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"infeasible-problems","dir":"Articles","previous_headings":"When Algorithms Fail","what":"Infeasible Problems","title":"Algorithm Details and Mathematical Foundations","text":"many entries forbidden (NA/Inf), valid assignment may exist:","code":"# Infeasible: no column reachable from row 2 cost_infeasible <- matrix(c(   1, 2, 3,   Inf, Inf, Inf,  # Row 2 cannot be assigned  4, 5, 6 ), nrow = 3, byrow = TRUE)  # Detection: check that each row has at least one finite entry feasible_rows <- rowSums(is.finite(cost_infeasible)) > 0 cat(\"Feasible rows:\", feasible_rows, \"\\n\") #> Feasible rows: TRUE FALSE TRUE cat(\"Problem is\", ifelse(all(feasible_rows), \"feasible\", \"INFEASIBLE\"), \"\\n\") #> Problem is INFEASIBLE"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"nearly-degenerate-problems","dir":"Articles","previous_headings":"When Algorithms Fail","what":"Nearly Degenerate Problems","title":"Algorithm Details and Mathematical Foundations","text":"many costs nearly equal, small numerical errors can cause: Different algorithms finding different solutions (optimal) Cycling auction algorithms (rare, safeguarded) Incorrect optimality certification (rare) Mitigation: Add small random perturbations need deterministic behavior, accept optimal solution acceptable.","code":"# Degenerate: many tied costs cost_degen <- matrix(c(   1, 1, 1,   1, 1, 1,   1, 1, 1 ), nrow = 3, byrow = TRUE)  # Multiple solutions exist - algorithms may find different ones r1 <- lap_solve(cost_degen, method = \"hungarian\") r2 <- lap_solve(cost_degen, method = \"jv\")  # Both optimal (cost = 3), but possibly different assignments cat(\"Hungarian total:\", get_total_cost(r1), \"\\n\") #> Hungarian total: 3 cat(\"JV total:\", get_total_cost(r2), \"\\n\") #> JV total: 3"},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"overflow-in-dual-variables","dir":"Articles","previous_headings":"When Algorithms Fail","what":"Overflow in Dual Variables","title":"Algorithm Details and Mathematical Foundations","text":"large cost ranges (> 101010^{10}), dual variable updates may overflow: Mitigation: Scale costs reasonable range (0 10610^{6}) solving.","code":"# Problematic: cost range is 10^15 cost_overflow <- matrix(c(1e-5, 1e10, 1e10, 1e-5), nrow = 2) # May produce incorrect results on some systems"},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Algorithm Details and Mathematical Foundations","text":"deeper mathematical treatment: Hungarian algorithm: Kuhn, H. W. (1955). “Hungarian method assignment problem.” Naval Research Logistics Quarterly. Jonker-Volgenant: Jonker, R., & Volgenant, . (1987). “shortest augmenting path algorithm dense sparse linear assignment problems.” Computing. Auction algorithm: Bertsekas, D. P. (1988). “auction algorithm: distributed relaxation method assignment problem.” Annals Operations Research. Murty’s algorithm: Murty, K. G. (1968). “algorithm ranking assignments order increasing cost.” Operations Research. General theory: Burkard, R., Dell’Amico, M., & Martello, S. (2009). Assignment Problems. SIAM.","code":""},{"path":"https://gcol33.github.io/couplr/articles/algorithms.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Algorithm Details and Mathematical Foundations","text":"vignette covered mathematical foundations practical considerations LAP algorithms couplr: Key Takeaways: Algorithm selection matters large problems – O(n3)O(n^3) adds quickly method = \"auto\" handles cases well, understanding options helps debugging Numerical issues rare can occur extreme cost ranges degenerate problems algorithms find optimal solutions – differences speed edge case handling Algorithm Summary: ’s Next? Function reference: ?lap_solve, ?assignment","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting Started with couplr","text":"linear assignment problem (LAP) fundamental optimization problem: given cost matrix entry (, j) represents cost assigning source target j, find one--one assignment minimizes (maximizes) total cost. LAP appears throughout data science, operations research, scientific computing – scheduling resource allocation computer vision bioinformatics. couplr provides efficient LAP solvers tidy interface integrates naturally modern R workflows.","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"why-couplr","dir":"Articles","previous_headings":"Overview","what":"Why couplr?","title":"Getting Started with couplr","text":"R packages address LAP, couplr distinguishes : 1. Tidy integration: First-class support tibbles, dplyr workflows, grouped data 2. Algorithm selection: 12+ algorithms automatic selection based problem characteristics 3. Production matching: High-level matching functions observational studies (v1.0.0) 4. Scalability: small matrices thousands parallel problems Alternative packages differ: clue: General-purpose optimization toolkit LAP one feature among many lpSolve: Broad linear programming focus, less specialized assignment RcppHungarian: Single algorithm implementation without tidy interface couplr focuses specifically assignment problems user-friendly API modern R idioms.","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"who-this-vignette-is-for","dir":"Articles","previous_headings":"Overview","what":"Who This Vignette Is For","title":"Getting Started with couplr","text":"Audience: Beginners couplr, R users familiar basic matrix operations Prerequisites: Basic R knowledge (data frames, functions) Understanding “cost” “distance” matrix means ’ll Learn: solve basic assignment problems lap_solve() Working data frames, rectangular problems, forbidden assignments Batch solving finding multiple solutions use different algorithms Time complete: 20-30 minutes","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"documentation-roadmap","dir":"Articles","previous_headings":"Overview","what":"Documentation Roadmap","title":"Getting Started with couplr","text":"couplr documentation organized follows: : Getting Started","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"key-features","dir":"Articles","previous_headings":"Overview","what":"Key Features","title":"Getting Started with couplr","text":"Tidy interface: Works data frames, tibbles, grouped data Efficient: Implements multiple algorithms automatic selection Flexible inputs: Handles matrices, data frames, rectangular problems, forbidden assignments Batch processing: Solve thousands problems efficiently optional parallelization K-best solutions: Find multiple near-optimal solutions using Murty’s algorithm","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with couplr","text":"","code":"# Install from CRAN install.packages(\"couplr\")  # Or install development version from GitHub # install.packages(\"remotes\") remotes::install_github(\"gcol33/couplr\")"},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"problem-definition","dir":"Articles","previous_headings":"The Assignment Problem","what":"Problem Definition","title":"Getting Started with couplr","text":"Consider assigning nurses shifts hospital. nurse different suitability shift based skills, travel time, overtime likelihood. assignment problem finds optimal one--one matching minimizes total cost (maximizes total preference). vignette uses recurring hospital staff scheduling example demonstrates increasingly complex scenarios. conceptual problem – assigning nurses shifts – evolves show different couplr features. Simple Example: Three nurses can cover three shifts following costs (lower = better fit): optimal assignment : Nurse 1 → Shift 2 (cost 2), Nurse 2 → Shift 1 (cost 3), Nurse 3 → Shift 3 (cost 4), total cost 9. Note: couplr includes comprehensive hospital_staff dataset ’ll use throughout vignette. Type ?hospital_staff details.","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"matrix-input","dir":"Articles","previous_headings":"Basic Usage","what":"Matrix Input","title":"Getting Started with couplr","text":"simplest way use couplr numeric cost matrix: result tidy tibble showing source (nurse) assigned target (shift), along individual total costs. Reading output: Row 1 shows Nurse 1 assigned Shift 2 cost 2. total_cost column shows cumulative cost assignments (9). larger problems, use built-hospital_staff dataset:","code":"# Cost matrix: 3 nurses × 3 shifts (from our simple example above) cost <- matrix(c(   4, 2, 5,  # Nurse 1 costs for shifts 1, 2, 3   3, 3, 6,  # Nurse 2 costs   7, 5, 4   # Nurse 3 costs ), nrow = 3, byrow = TRUE)  # Solve the assignment problem result <- lap_solve(cost) print(result) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      2     2 #> 2      2      1     3 #> 3      3      3     4 #>  #> Total cost: 9  #> Method: bruteforce # 10 nurses × 10 shifts result_10x10 <- lap_solve(hospital_staff$basic_costs) head(result_10x10) #> Assignment Result #> ================= #>  #> # A tibble: 6 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      8     2 #> 2      2      2     2 #> 3      3      7     2 #> 4      4      4     2 #> 5      5      9     2 #> 6      6     10     3 #>  #> Total cost: 22  #> Method: hungarian  # Total cost cat(\"Total assignment cost:\", get_total_cost(result_10x10), \"\\n\") #> Total assignment cost: 22"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"data-frame-input","dir":"Articles","previous_headings":"Basic Usage","what":"Data Frame Input","title":"Getting Started with couplr","text":"complex workflows, especially working existing data pipelines, use data frames: approach particularly useful data already long format, pulling databases, integrating dplyr workflows. Now can solve basic problem, happens shifts nurses fill ?","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  # The hospital_staff dataset includes a data frame version head(hospital_staff$schedule_df) #> # A tibble: 6 × 5 #>   nurse_id shift_id  cost preference skill_match #>      <int>    <int> <dbl>      <dbl>       <int> #> 1        1        1     3          8           0 #> 2        1        2     7          4           0 #> 3        1        3     5          6           1 #> 4        1        4     9          2           0 #> 5        1        5     4          7           1 #> 6        1        6     8          3           1  # Solve using column names result <- lap_solve(hospital_staff$schedule_df, nurse_id, shift_id, cost) print(result) #> Assignment Result #> ================= #>  #> # A tibble: 10 × 3 #>    source target  cost #>     <int>  <int> <dbl> #>  1      1      8     2 #>  2      2      2     2 #>  3      3      7     2 #>  4      4      4     2 #>  5      5      9     2 #>  6      6     10     3 #>  7      7      1     2 #>  8      8      3     2 #>  9      9      6     3 #> 10     10      5     2 #>  #> Total cost: 22  #> Method: hungarian"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"working-with-rectangular-problems","dir":"Articles","previous_headings":"","what":"Working with Rectangular Problems","title":"Getting Started with couplr","text":"Real scheduling problems rarely equal numbers nurses shifts. hospital might 8 nurses available need cover 12 shifts, 15 nurses 10 shifts fill. Unlike many assignment solvers, couplr handles rectangular problems (unequal numbers sources targets) without manual padding: solver automatically handles rectangular structure, assigning 3 nurses best available shift among 5 options. Notice shifts 3 4 remain unassigned (’re target column). Interpretation: rows < columns, row (nurse) gets exactly one column (shift), columns remain unassigned. rows > columns, matrix transposed internally column gets one row. certain nurse-shift combinations impossible due scheduling conflicts skill requirements?","code":"# 3 nurses, 5 available shifts - assign each nurse to one shift cost_rect <- matrix(c(   1, 2, 3, 4, 5,   # Nurse 1's costs for 5 shifts   6, 5, 4, 3, 2,   # Nurse 2's costs   2, 3, 4, 5, 6    # Nurse 3's costs ), nrow = 3, byrow = TRUE)  result <- lap_solve(cost_rect) print(result) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      5     2 #> 3      3      2     3 #>  #> Total cost: 6  #> Method: bruteforce"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"forbidden-assignments","dir":"Articles","previous_headings":"","what":"Forbidden Assignments","title":"Getting Started with couplr","text":"real scheduling, assignments simply impossible: nurse lacks required certification ICU shift, scheduling conflict makes night shift impossible. Use NA Inf mark impossible forbidden assignments: solver respects constraints finds optimal assignment among feasible options. Compare result unconstrained solution: Nurse 1 still gets Shift 2 (cost 2), assignments adjust around constraints. use NA vs Inf: mark forbidden assignments. Use NA “applicable” (e.g., skill mismatch) Inf “infinitely costly” (e.g., severe overtime). Functionally behave identically. far ’ve minimized costs. maximizing preferences instead?","code":"# Fresh cost matrix cost <- matrix(c(   4, 2, 5,   3, 3, 6,   7, 5, 4 ), nrow = 3, byrow = TRUE)  # Nurse 1 cannot work Shift 3 (lacks ICU certification) cost[1, 3] <- NA  # Nurse 2 cannot work Shift 1 (scheduling conflict) cost[2, 1] <- Inf  result <- lap_solve(cost) print(result) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     4 #> 2      2      2     3 #> 3      3      3     4 #>  #> Total cost: 11  #> Method: bruteforce"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"maximization-problems","dir":"Articles","previous_headings":"","what":"Maximization Problems","title":"Getting Started with couplr","text":"Sometimes want maximize preferences rather minimize costs. Nurses shift preferences (higher = preferred), happier nurses mean lower turnover. Switch maximization setting maximize = TRUE: Behind scenes: maximize = TRUE internally negates costs, solves minimization problem, reports results original scale. need schedule multiple days , cost matrix?","code":"# Preference matrix from hospital_staff (0-10 scale, higher = more preferred) head(hospital_staff$preferences) #>         Shift_1 Shift_2 Shift_3 Shift_4 Shift_5 Shift_6 Shift_7 Shift_8 Shift_9 #> Nurse_1       8       4       6       2       7       3       5       9       4 #> Nurse_2       5       9       3       7       4       8       2       6       7 #> Nurse_3       6       7       8       4       3       5       9       2       6 #> Nurse_4       3       5       4       9       6       7       8       5       3 #> Nurse_5       7       2       5       6       8       4       3       7       9 #> Nurse_6       4       8       7       3       5       9       6       4       2 #>         Shift_10 #> Nurse_1        6 #> Nurse_2        5 #> Nurse_3        7 #> Nurse_4        4 #> Nurse_5        2 #> Nurse_6        8  # Maximize total nurse satisfaction result <- lap_solve(hospital_staff$preferences, maximize = TRUE) head(result) #> Assignment Result #> ================= #>  #> # A tibble: 6 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      8     9 #> 2      2      2     9 #> 3      3      7     9 #> 4      4      4     9 #> 5      5      9     9 #> 6      6     10     8 #>  #> Total cost: 88  #> Method: hungarian  cat(\"\\nTotal preference score:\", get_total_cost(result), \"\\n\") #>  #> Total preference score: 88"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"grouped-data-frames","dir":"Articles","previous_headings":"","what":"Grouped Data Frames","title":"Getting Started with couplr","text":"One couplr’s powerful features seamless integration grouped data frames, allowing solve many related problems . hospital_staff$weekly_df dataset contains scheduling costs 5 days. day needs optimal assignment: pattern—grouping, solving—works naturally dplyr pipelines much cleaner writing loops.","code":"# Weekly schedule: 5 days × 10 nurses × 10 shifts head(hospital_staff$weekly_df) #> # A tibble: 6 × 5 #>   day    nurse_id shift_id  cost preference #>   <fct>     <int>    <int> <dbl>      <dbl> #> 1 Monday        1        1     2          7 #> 2 Monday        1        2     5          3 #> 3 Monday        1        3     4          6 #> 4 Monday        1        4    11          3 #> 5 Monday        1        5     6          8 #> 6 Monday        1        6     9          4  # Solve all days at once weekly_results <- hospital_staff$weekly_df |>   group_by(day) |>   lap_solve(nurse_id, shift_id, cost)  # View assignments by day weekly_results |>   group_by(day) |>   summarise(total_cost = sum(cost), .groups = \"drop\") #> # A tibble: 5 × 2 #>   day       total_cost #>   <fct>          <dbl> #> 1 Monday            18 #> 2 Tuesday           15 #> 3 Wednesday         25 #> 4 Thursday          18 #> 5 Friday            20"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"batch-solving","dir":"Articles","previous_headings":"","what":"Batch Solving","title":"Getting Started with couplr","text":"even larger scale—hundreds thousands independent problems—grouped data frames may become unwieldy. ’s batch solving shines. maximum efficiency solving many independent problems, use lap_solve_batch():","code":"# Create list of cost matrices set.seed(123) cost_list <- lapply(1:100, function(i) matrix(runif(9, 1, 10), 3, 3))  # Solve all problems at once batch_results <- lap_solve_batch(cost_list)  # View summary statistics batch_results |>   distinct(problem_id, total_cost) |>   summarise(     n_problems = n(),     mean_cost = mean(total_cost),     min_cost = min(total_cost),     max_cost = max(total_cost)   ) #> # A tibble: 1 × 4 #>   n_problems mean_cost min_cost max_cost #>        <int>     <dbl>    <dbl>    <dbl> #> 1        100      11.3     5.20     19.1"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"parallel-batch-solving","dir":"Articles","previous_headings":"Batch Solving","what":"Parallel Batch Solving","title":"Getting Started with couplr","text":"large numbers problems, enable parallel processing:","code":"# Solve with 4 threads batch_results <- lap_solve_batch(cost_list, n_threads = 4)  # Use all available cores batch_results <- lap_solve_batch(cost_list, n_threads = NULL)"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"finding-multiple-solutions","dir":"Articles","previous_headings":"","what":"Finding Multiple Solutions","title":"Getting Started with couplr","text":"optimal schedule might mathematically perfect practically impossible—Nurse 1 vacation week. alternatives? Sometimes want explore alternative near-optimal solutions. Use lap_solve_kbest() find k best solutions: useful : Exploring alternative plans optimal solution infeasible practice Robustness analysis Understanding cost landscape around optimum","code":"cost <- matrix(c(   1, 2, 3,   4, 3, 2,   5, 4, 1 ), nrow = 3, byrow = TRUE)  # Find top 5 solutions kbest <- lap_solve_kbest(cost, k = 5) print(kbest) #> K-Best Assignment Results #> ========================= #>  #> Number of solutions: 5  #>  #> Solution costs: #>   Rank 1: 5.0000 #>   Rank 2: 7.0000 #>   Rank 3: 7.0000 #>   Rank 4: 9.0000 #>   Rank 5: 11.0000 #>  #> Assignments: #> # A tibble: 15 × 6 #>     rank solution_id source target  cost total_cost #>    <int>       <int>  <int>  <int> <dbl>      <dbl> #>  1     1           1      1      1     1          5 #>  2     1           1      2      2     3          5 #>  3     1           1      3      3     1          5 #>  4     2           2      1      2     2          7 #>  5     2           2      2      1     4          7 #>  6     2           2      3      3     1          7 #>  7     3           3      1      1     1          7 #>  8     3           3      2      3     2          7 #>  9     3           3      3      2     4          7 #> 10     4           4      1      2     2          9 #> 11     4           4      2      3     2          9 #> 12     4           4      3      1     5          9 #> 13     5           5      1      3     3         11 #> 14     5           5      2      2     3         11 #> 15     5           5      3      1     5         11  # Get summary of solutions summary(kbest) #> # A tibble: 5 × 4 #>    rank solution_id total_cost n_assignments #>   <int>       <int>      <dbl>         <int> #> 1     1           1          5             3 #> 2     2           2          7             3 #> 3     3           3          7             3 #> 4     4           4          9             3 #> 5     5           5         11             3"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"extracting-and-working-with-results","dir":"Articles","previous_headings":"","what":"Extracting and Working with Results","title":"Getting Started with couplr","text":"couplr provides several utility functions working results:","code":"result <- lap_solve(cost)  # Extract total cost get_total_cost(result) #> [1] 5  # Get algorithm used get_method_used(result) #> [1] \"bruteforce\"  # Convert to binary assignment matrix as_assignment_matrix(result) #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    0    1    0 #> [3,]    0    0    1  # Check result type is_lap_solve_result(result) #> [1] TRUE"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"algorithm-selection","dir":"Articles","previous_headings":"","what":"Algorithm Selection","title":"Getting Started with couplr","text":"default, couplr chooses algorithm automatically. understanding options can help performance tuning debugging. couplr includes multiple algorithms optimized different scenarios. default \"auto\" method automatically selects best algorithm:","code":"# Let couplr choose (default) lap_solve(cost, method = \"auto\") #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      2     3 #> 3      3      3     1 #>  #> Total cost: 5  #> Method: bruteforce  # Force specific algorithm: lap_solve(cost, method = \"jv\")         # Jonker-Volgenant (general purpose) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      2     3 #> 3      3      3     1 #>  #> Total cost: 5  #> Method: jv lap_solve(cost, method = \"hungarian\")  # Hungarian algorithm #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      2     3 #> 3      3      3     1 #>  #> Total cost: 5  #> Method: hungarian lap_solve(cost, method = \"auction\")    # Auction algorithm #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      2     3 #> 3      3      3     1 #>  #> Total cost: 5  #> Method: auction lap_solve(cost, method = \"sap\")        # Sparse assignment (for sparse problems) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      2     3 #> 3      3      3     1 #>  #> Total cost: 5  #> Method: sap"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"auction-algorithm-variants","dir":"Articles","previous_headings":"Algorithm Selection","what":"Auction Algorithm Variants","title":"Getting Started with couplr","text":"auction algorithm multiple variants different problem characteristics:","code":"# Standard fixed-epsilon auction (default) lap_solve(cost, method = \"auction\")  # Scaled-epsilon auction with epsilon-scaling phases # Better for problems with large cost ranges lap_solve(cost, method = \"auction_scaled\")  # Gauss-Seidel auction with sequential bidding # Can be faster for certain problem structures lap_solve(cost, method = \"auction_gs\")"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"binary-cost-problems","dir":"Articles","previous_headings":"Algorithm Selection","what":"Binary Cost Problems","title":"Getting Started with couplr","text":"problems costs 0 1, use specialized HK01 algorithm: \"auto\" method selects algorithms based problem characteristics: Binary/uniform costs → HK01 algorithm Sparse/rectangular → SAP algorithm Large dense → Auction algorithm (standard variant) General case → Jonker-Volgenant users, method = \"auto\" (default) provides good performance.","code":"# Create binary cost matrix binary_cost <- matrix(sample(0:1, 9, replace = TRUE), 3, 3)  # Specialized algorithm for binary costs lap_solve(binary_cost, method = \"hk01\") #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <int> #> 1      1      2     0 #> 2      2      3     0 #> 3      3      1     0 #>  #> Total cost: 0  #> Method: hk01"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"parallelization","dir":"Articles","previous_headings":"Algorithm Selection","what":"Parallelization","title":"Getting Started with couplr","text":"Note parallelization: Currently, lap_solve_batch() supports parallel execution via n_threads parameter. individual LAP solvers (lap_solve(), lap_solve_kbest()) run sequentially. Future versions may add parallel support single large problems.","code":"# Parallel batch solving (supported) lap_solve_batch(cost_list, n_threads = 4)  # Single problem (currently sequential) lap_solve(cost)  # No parallelization yet"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"real-world-example-employee-scheduling","dir":"Articles","previous_headings":"","what":"Real-World Example: Employee Scheduling","title":"Getting Started with couplr","text":"’s practical example using couplr create weekly work schedule:","code":"set.seed(42)  # Generate employee preferences for shifts schedule_data <- tibble(   day = rep(c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"), each = 12),   employee = rep(1:4, times = 15),   shift = rep(c(\"morning\", \"afternoon\", \"night\"), each = 4, times = 5),   preference_score = rnorm(60, mean = 5, sd = 2) ) |>   mutate(     # Some employees can't work certain shifts     preference_score = case_when(       employee == 1 & shift == \"night\" ~ NA_real_,       employee == 2 & shift == \"morning\" ~ NA_real_,       TRUE ~ preference_score     ),     # Create shift IDs within each day     shift_id = as.integer(factor(shift, levels = c(\"morning\", \"afternoon\", \"night\")))   )  # Solve for optimal assignments per day (maximize preferences) optimal_schedule <- schedule_data |>   group_by(day) |>   lap_solve(employee, shift_id, preference_score, maximize = TRUE)  # View first few assignments head(optimal_schedule, 10) #> # A tibble: 10 × 4 #>    day   source target  cost #>    <chr>  <int>  <int> <dbl> #>  1 Fri        1      2  8.15 #>  2 Fri        3      1  5.64 #>  3 Fri        4      3  5.57 #>  4 Mon        1      1  7.74 #>  5 Mon        3      2  8.02 #>  6 Mon        4      3  9.57 #>  7 Thu        1      1  3.43 #>  8 Thu        3      2  6.52 #>  9 Thu        4      3  7.89 #> 10 Tue        1      2  4.43  # Summary statistics by day optimal_schedule |>   group_by(day) |>   summarise(     shifts_filled = n(),     avg_preference = mean(cost, na.rm = TRUE),     .groups = \"drop\"   ) #> # A tibble: 5 × 3 #>   day   shifts_filled avg_preference #>   <chr>         <int>          <dbl> #> 1 Fri               3           6.46 #> 2 Mon               3           8.45 #> 3 Thu               3           5.95 #> 4 Tue               3           5.53 #> 5 Wed               3           7.07"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"performance-considerations","dir":"Articles","previous_headings":"","what":"Performance Considerations","title":"Getting Started with couplr","text":"couplr designed efficiency: C++ backend: Core algorithms implemented optimized C++ using Rcpp Automatic algorithm selection: Chooses efficient method problem Batch processing: Amortizes overhead solving many problems Parallel execution: Distributes work across cores large batches small problems (< 100×100), setup overhead dominates methods fast. large problems (> 1000×1000) many problems, algorithm selection parallelization become important.","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"problem-all-assignments-have-inf-cost","dir":"Articles","previous_headings":"Common Pitfalls and Troubleshooting","what":"Problem: “All assignments have Inf cost”","title":"Getting Started with couplr","text":"Cause: many forbidden entries (NA/Inf) make problem infeasible. Solution: Check feasible solution exists. rectangular problems forbidden entries, ensure least one valid assignment exists source.","code":"# Check feasibility before solving cost_problematic <- matrix(c(   1, NA, NA,   NA, NA, NA,  # Row 2 has no valid targets!   NA, 2, 3 ), nrow = 3, byrow = TRUE)  # Check which rows have at least one finite value feasible <- rowSums(is.finite(cost_problematic)) > 0 if (!all(feasible)) {   cat(\"Infeasible rows:\", which(!feasible), \"\\n\") } #> Infeasible rows: 2"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"problem-unexpected-assignments","dir":"Articles","previous_headings":"Common Pitfalls and Troubleshooting","what":"Problem: Unexpected assignments","title":"Getting Started with couplr","text":"Cause: Cost matrix orientation wrong (rows vs columns swapped). Solution: Remember: rows = sources (nurses), columns = targets (shifts). result shows source→target assignments.","code":"# Verify orientation cost_check <- matrix(c(1, 100, 100, 1), nrow = 2) rownames(cost_check) <- c(\"Nurse_A\", \"Nurse_B\") colnames(cost_check) <- c(\"Shift_1\", \"Shift_2\") print(cost_check) #>         Shift_1 Shift_2 #> Nurse_A       1     100 #> Nurse_B     100       1  # Nurse_A should get Shift_1 (cost 1), Nurse_B should get Shift_2 (cost 1) lap_solve(cost_check) #> Assignment Result #> ================= #>  #> # A tibble: 2 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      2     1 #>  #> Total cost: 2  #> Method: bruteforce"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"problem-different-results-with-different-methods","dir":"Articles","previous_headings":"Common Pitfalls and Troubleshooting","what":"Problem: Different results with different methods","title":"Getting Started with couplr","text":"Cause: Multiple optimal solutions may exist. Different algorithms may find different optima total cost. Solution: need deterministic results, use method = \"hungarian\" deterministic tie-breaking. verify total costs match even assignments differ.","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"problem-slow-performance-on-large-problems","dir":"Articles","previous_headings":"Common Pitfalls and Troubleshooting","what":"Problem: Slow performance on large problems","title":"Getting Started with couplr","text":"Cause: O(n3)O(n^3) complexity exact algorithms. Solutions: n > 1000: Try method = \"auction\" n > 3000: Use blocking via vignette(\"matching-workflows\") n > 5000: Consider greedy matching greedy_couples()","code":"# For large problems, auction algorithm is often faster large_cost <- matrix(runif(1000000), nrow = 1000) system.time(lap_solve(large_cost, method = \"auction\"))"},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"problem-memory-errors","dir":"Articles","previous_headings":"Common Pitfalls and Troubleshooting","what":"Problem: Memory errors","title":"Getting Started with couplr","text":"Cause: Cost matrix large available RAM. 10,000×10,000 matrix requires ~800 MB. Solution: Use blocking divide problem, switch greedy matching doesn’t require full cost matrix memory.","code":""},{"path":"https://gcol33.github.io/couplr/articles/getting-started.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Getting Started with couplr","text":"vignette walked hospital staff scheduling demonstrate couplr’s core functionality: Basic solving: Matrix data frame inputs lap_solve() Rectangular problems: shifts nurses (vice versa) Forbidden assignments: Using NA/Inf impossible pairings Maximization: Optimizing preferences instead minimizing costs Grouped data: Solving multiple days dplyr Batch solving: Handling hundreds independent problems K-best solutions: Exploring alternatives optimal Algorithm selection: Choosing right solver problem ’s Next? Function reference: ?lap_solve, ?lap_solve_batch, ?lap_solve_kbest, ?hospital_staff Source code: github.com/gcol33/couplr","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Matching Workflows: From Data to Publication","text":"Matching fundamental technique creating comparable groups observational studies. Unlike random assignment, observational data often contain systematic differences treatment control groups confound causal inference. Matching addresses pairing similar units based observed characteristics, creating “apples--apples” comparisons. vignette follows complete workflow raw data publication-ready results, using realistic job training evaluation running example. ’ll learn handle full pipeline: preprocessing, matching, assessment, reporting.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"who-this-vignette-is-for","dir":"Articles","previous_headings":"Overview","what":"Who This Vignette Is For","title":"Matching Workflows: From Data to Publication","text":"Audience: Researchers, epidemiologists, economists, data scientists working observational data Prerequisites: Familiarity basic couplr usage (vignette(\"getting-started\")) Understanding causal inference concepts (treatment effects, confounding) Basic statistics (means, standard deviations, t-tests) ’ll Learn: match treatment control units match_couples() Automatic preprocessing: scaling, health checks, categorical encoding Assessing match quality balance_diagnostics() use optimal vs greedy matching Creating publication-ready balance tables Time complete: 30-45 minutes","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"documentation-roadmap","dir":"Articles","previous_headings":"Overview","what":"Documentation Roadmap","title":"Matching Workflows: From Data to Publication","text":": Matching Workflows","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"the-running-example-job-training-evaluation","dir":"Articles","previous_headings":"Overview","what":"The Running Example: Job Training Evaluation","title":"Matching Workflows: From Data to Publication","text":"Throughout vignette, evaluate job training program’s effect earnings. challenge: participants self-selected program, differ systematically non-participants age, education, prior earnings. Without matching, earnings difference due baseline differences rather program . goal: Create comparable treatment control groups, assess balance quality, estimate treatment effect credibly.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"key-features","dir":"Articles","previous_headings":"Overview","what":"Key Features","title":"Matching Workflows: From Data to Publication","text":"Automatic preprocessing health checks smart scaling Optimal matching via linear assignment algorithms Fast greedy matching large datasets (n > 5,000) Blocking stratification support Comprehensive balance diagnostics Publication-ready output tables","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"the-matching-problem","dir":"Articles","previous_headings":"Problem Definition","what":"The Matching Problem","title":"Matching Workflows: From Data to Publication","text":"Given two groups units: Left group (treatment, exposed, cases): nLn_L units Right group (control, unexposed, controls): nRn_R units unit ii covariate vector 𝐱∈ℝp\\mathbf{x}_i \\\\mathbb{R}^p describing characteristics want balance (age, income, education, etc.). Goal: Find one--one matches minimize total distance: minπ∑=1nd(𝐱iL,𝐱π()R) \\min_{\\pi} \\sum_{=1}^{n} d(\\mathbf{x}_i^L, \\mathbf{x}_{\\pi()}^R) d(⋅,⋅)d(\\cdot, \\cdot) distance function (typically Euclidean Mahalanobis) π\\pi matching assignment.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"why-matching-matters","dir":"Articles","previous_headings":"Problem Definition","what":"Why Matching Matters","title":"Matching Workflows: From Data to Publication","text":"Without matching: - Groups may differ systematically important covariates - Treatment effect estimates confounded differences - Statistical adjustments (regression) rely untestable assumptions matching: - Create comparable groups differ primarily treatment status - Balance covariates reduce confounding - Improve causal inference mimicking randomized experiments - Transparent, non-parametric preprocessing step","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"distance-metrics","dir":"Articles","previous_headings":"Problem Definition","what":"Distance Metrics","title":"Matching Workflows: From Data to Publication","text":"quality matching depends distance metric: Euclidean distance (scaling): d(𝐱,𝐱j)=∑k=1p(xik−xjk)2 d(\\mathbf{x}_i, \\mathbf{x}_j) = \\sqrt{\\sum_{k=1}^{p} (x_{ik} - x_{jk})^2} Mahalanobis distance (accounts correlations): d(𝐱,𝐱j)=(𝐱−𝐱j)⊤Σ−1(𝐱−𝐱j) d(\\mathbf{x}_i, \\mathbf{x}_j) = \\sqrt{(\\mathbf{x}_i - \\mathbf{x}_j)^\\top \\Sigma^{-1} (\\mathbf{x}_i - \\mathbf{x}_j)} Propensity score distance (single dimension): d(,j)=|pi−pj| d(, j) = |p_i - p_j| pi=P(treatment∣𝐱)p_i = P(\\text{treatment} \\mid \\mathbf{x}_i) propensity score. couplr defaults Euclidean distance automatic scaling, works well applications.","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"creating-a-matched-sample","dir":"Articles","previous_headings":"Basic Usage","what":"Creating a Matched Sample","title":"Matching Workflows: From Data to Publication","text":"simplest workflow uses match_couples() automatic preprocessing: result contains: pairs: Matched pairs IDs distances info: Matching method, counts, total distance left_unmatched, right_unmatched: Units without matches cost_matrix: Full distance matrix (return_diagnostics = TRUE)","code":"# Simulate observational data set.seed(123) n_left <- 100 n_right <- 150  # Treatment group (tends to be younger, higher income) left_data <- tibble(   id = 1:n_left,   age = rnorm(n_left, mean = 45, sd = 10),   income = rnorm(n_left, mean = 60000, sd = 15000),   education = sample(c(\"HS\", \"BA\", \"MA\"), n_left, replace = TRUE),   group = \"treatment\" )  # Control group (older, lower income on average) right_data <- tibble(   id = 1:n_right,   age = rnorm(n_right, mean = 52, sd = 12),   income = rnorm(n_right, mean = 50000, sd = 18000),   education = sample(c(\"HS\", \"BA\", \"MA\"), n_right, replace = TRUE),   group = \"control\" )  # Perform optimal matching result <- match_couples(   left = left_data,   right = right_data,   vars = c(\"age\", \"income\"),   auto_scale = TRUE,   return_diagnostics = TRUE ) #> Auto-selected scaling method: standardize  # View matched pairs head(result$pairs) #> # A tibble: 6 × 5 #>   left_id right_id distance .age_diff .income_diff #>   <chr>   <chr>       <dbl>     <dbl>        <dbl> #> 1 1       27         0.530   -5.68           2942. #> 2 2       37         0.299    3.33            980. #> 3 3       15         0.0382  -0.251          -512. #> 4 4       11         0.691   -7.19           4587. #> 5 5       73         0.425   -4.48           2583. #> 6 6       131        0.133    0.00187       -2186.  # Summary statistics result$info #> $solver #> [1] \"auction_scaled\" #>  #> $n_matched #> [1] 100 #>  #> $total_distance #> [1] 33.77392 #>  #> $method #> [1] \"lap\" #>  #> $distance_metric #> [1] \"euclidean\" #>  #> $scaled #> [1] TRUE #>  #> $n_left #> [1] 100 #>  #> $n_right #> [1] 150"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"understanding-the-output","dir":"Articles","previous_headings":"Basic Usage","what":"Understanding the Output","title":"Matching Workflows: From Data to Publication","text":"Interpretation: Lower distances indicate better matches (similar units) Median distance provides typical match quality Large distances suggest poor matches (consider caliper constraints)","code":"# How many matched? cat(\"Matched pairs:\", result$info$n_matched, \"\\n\") #> Matched pairs: 100 cat(\"Unmatched left:\", nrow(result$left_unmatched), \"\\n\") #> Unmatched left: cat(\"Unmatched right:\", nrow(result$right_unmatched), \"\\n\") #> Unmatched right:  # Distribution of match distances summary(result$pairs$distance) #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.002044 0.139855 0.249548 0.337739 0.466174 1.939711  # Visualize match quality ggplot(result$pairs, aes(x = distance)) +   geom_histogram(bins = 30, fill = \"steelblue\", alpha = 0.7) +   labs(     title = \"Distribution of Match Distances\",     x = \"Euclidean Distance (scaled)\",     y = \"Count\"   ) +   theme_minimal()"},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"why-preprocessing-matters","dir":"Articles","previous_headings":"Automatic Preprocessing","what":"Why Preprocessing Matters","title":"Matching Workflows: From Data to Publication","text":"Raw covariates often : Different scales: Age years (20-80), income dollars (20,000-200,000) Different units: Continuous (age), categorical (education), binary (smoker) Data quality issues: Missing values, constant variables, extreme outliers Without preprocessing, high-variance variables dominate distance calculations.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"smart-scaling-with-auto_scale-true","dir":"Articles","previous_headings":"Automatic Preprocessing","what":"Smart Scaling with auto_scale = TRUE","title":"Matching Workflows: From Data to Publication","text":"auto_scale = TRUE, match_couples() automatically: Constant variables (SD = 0) → excluded warning High missingness (>50%) → warned Extreme skewness (|skew| > 2) → informed Continuous variables → scaled selected method Binary variables (0/1) → used -Categorical → converted numeric ordered Unordered factors → converted binary indicators Ordered factors → converted numeric ranks","code":"# Create data with scaling challenges set.seed(456) challenging_data <- tibble(   id = 1:50,   age = rnorm(50, 50, 10),                    # Years (reasonable scale)   income = rnorm(50, 60000, 20000),           # Dollars (large scale)   bmi = rnorm(50, 25, 5),                     # Ratio (small scale)   smoker = sample(0:1, 50, replace = TRUE),   # Binary   education = factor(     sample(c(\"HS\", \"BA\", \"MA\", \"PhD\"), 50, replace = TRUE),     ordered = TRUE,     levels = c(\"HS\", \"BA\", \"MA\", \"PhD\")   ) )  left_chal <- challenging_data[1:25, ] right_chal <- challenging_data[26:50, ]  # Match WITHOUT auto-scaling (income dominates) result_no_scale <- match_couples(   left_chal, right_chal,   vars = c(\"age\", \"income\", \"bmi\"),   auto_scale = FALSE )  # Match WITH auto-scaling (all variables contribute) result_scaled <- match_couples(   left_chal, right_chal,   vars = c(\"age\", \"income\", \"bmi\"),   auto_scale = TRUE,   scale = \"robust\"  # Median/MAD scaling (robust to outliers) )  # Compare match quality cat(\"Without scaling - mean distance:\", mean(result_no_scale$pairs$distance), \"\\n\") #> Without scaling - mean distance: 3572.096 cat(\"With scaling - mean distance:\", mean(result_scaled$pairs$distance), \"\\n\") #> With scaling - mean distance: 0.9784372"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"scaling-methods","dir":"Articles","previous_headings":"Automatic Preprocessing","what":"Scaling Methods","title":"Matching Workflows: From Data to Publication","text":"Three scaling strategies available via scale parameter: 1. Robust scaling (scale = \"robust\", default): xscaled=x−median(x)MAD(x) x_{\\text{scaled}} = \\frac{x - \\text{median}(x)}{\\text{MAD}(x)} Uses median median absolute deviation (MAD) Resistant outliers skewness Best : Real-world data potential outliers 2. Standardization (scale = \"standardize\"): xscaled=x−mean(x)SD(x) x_{\\text{scaled}} = \\frac{x - \\text{mean}(x)}{\\text{SD}(x)} Classical z-score normalization Assumes approximate normality Best : Clean, normally-distributed data 3. Range scaling (scale = \"range\"): xscaled=x−min⁡(x)max⁡(x)−min⁡(x) x_{\\text{scaled}} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} Scales [0, 1] range Preserves exact relationships Best : Bounded variables, visualization","code":"# Demonstrate scaling methods demo_var <- c(10, 20, 25, 30, 100)  # Contains outlier (100)  # Function to show scaling show_scaling <- function(x, method) {   left_demo <- tibble(id = 1:3, var = x[1:3])   right_demo <- tibble(id = 1:2, var = x[4:5])    result <- match_couples(     left_demo, right_demo,     vars = \"var\",     auto_scale = TRUE,     scale = method,     return_diagnostics = TRUE   )    # Extract scaled values from cost matrix   cat(method, \"scaling:\\n\")   cat(\"  Original:\", x, \"\\n\")   cat(\"  Distance matrix diagonal:\", diag(result$cost_matrix)[1:2], \"\\n\\n\") }  show_scaling(demo_var, \"robust\") #> robust scaling: #>   Original: 10 20 25 30 100  #>   Distance matrix diagonal: NA NA show_scaling(demo_var, \"standardize\") #> standardize scaling: #>   Original: 10 20 25 30 100  #>   Distance matrix diagonal: NA NA show_scaling(demo_var, \"range\") #> range scaling: #>   Original: 10 20 25 30 100  #>   Distance matrix diagonal: NA NA"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"health-checks-and-warnings","dir":"Articles","previous_headings":"Automatic Preprocessing","what":"Health Checks and Warnings","title":"Matching Workflows: From Data to Publication","text":"preprocessing system provides informative diagnostics:","code":"# Create data with issues problematic_data <- tibble(   id = 1:100,   age = rnorm(100, 50, 10),   constant_var = 5,                           # No variation - will warn   mostly_missing = c(rnorm(20, 50, 10), rep(NA, 80)),  # >50% missing   extreme_skew = rexp(100, rate = 0.1)       # Very skewed )  # Attempt matching - will show warnings result <- match_couples(   problematic_data[1:50, ],   problematic_data[51:100, ],   vars = c(\"age\", \"constant_var\", \"mostly_missing\", \"extreme_skew\"),   auto_scale = TRUE )  # Warning messages will indicate: # - \"constant_var excluded (SD = 0)\" # - \"mostly_missing has 80% missing values\" # - \"extreme_skew has high skewness (3.2)\""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"optimal-vs-greedy-matching","dir":"Articles","previous_headings":"","what":"Optimal vs Greedy Matching","title":"Matching Workflows: From Data to Publication","text":"large datasets (n > 5,000), optimal matching becomes computationally expensive. couplr provides fast greedy alternatives.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"when-to-use-each-approach","dir":"Articles","previous_headings":"Optimal vs Greedy Matching","what":"When to Use Each Approach","title":"Matching Workflows: From Data to Publication","text":"Optimal matching (method = \"optimal\"): Minimizes total distance (globally optimal solution) Uses linear assignment algorithms (O(n3)O(n^3) complexity) Suitable : n < 5,000, optimality critical Typical runtime: <1 second n=1,000, ~10 seconds n=3,000 Greedy matching (method = \"greedy\"): Fast approximation (10-100x faster) Three strategies: sorted, row_best, pq Suitable : n > 5,000, exploratory analysis, speed matters Typical runtime: <1 second n=10,000","code":"# Create moderately large dataset set.seed(789) n <- 1000 large_left <- tibble(   id = 1:n,   x1 = rnorm(n),   x2 = rnorm(n),   x3 = rnorm(n) ) large_right <- tibble(   id = 1:n,   x1 = rnorm(n),   x2 = rnorm(n),   x3 = rnorm(n) )  # Optimal matching time_optimal <- system.time({   result_optimal <- match_couples(     large_left, large_right,     vars = c(\"x1\", \"x2\", \"x3\"),     method = \"hungarian\"   ) })  # Greedy matching (row_best strategy) time_greedy <- system.time({   result_greedy <- greedy_couples(     large_left, large_right,     vars = c(\"x1\", \"x2\", \"x3\"),     strategy = \"row_best\"   ) })  # Compare cat(\"Optimal matching:\\n\") #> Optimal matching: cat(\"  Time:\", round(time_optimal[\"elapsed\"], 3), \"seconds\\n\") #>   Time: 22.16 seconds cat(\"  Mean distance:\", round(mean(result_optimal$pairs$distance), 4), \"\\n\\n\") #>   Mean distance: 0.3368  cat(\"Greedy matching:\\n\") #> Greedy matching: cat(\"  Time:\", round(time_greedy[\"elapsed\"], 3), \"seconds\\n\") #>   Time: 0.91 seconds cat(\"  Mean distance:\", round(mean(result_greedy$pairs$distance), 4), \"\\n\") #>   Mean distance: 0.4667 cat(\"  Speedup:\", round(time_optimal[\"elapsed\"] / time_greedy[\"elapsed\"], 1), \"x\\n\") #>   Speedup: 24.4 x"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"greedy-strategies","dir":"Articles","previous_headings":"Optimal vs Greedy Matching","what":"Greedy Strategies","title":"Matching Workflows: From Data to Publication","text":"Three greedy strategies available via greedy_couples(): 1. Sorted (strategy = \"sorted\"): Sort possible pairs distance Assign greedily best worst Best quality among greedy methods Slowest greedy option (still much faster optimal) 2. Row-best (strategy = \"row_best\", default): left unit, find best available right unit Process left units order Fast simple Medium quality 3. Priority queue (strategy = \"pq\"): Maintains priority queue potential matches Updates dynamically assignments made Best large problems Fastest option Recommendation: Default strategy = \"row_best\" good speed/quality balance Use strategy = \"sorted\" quality important optimal slow Use strategy = \"pq\" n > 10,000","code":"Algorithm: 1. Compute all n_L × n_R distances 2. Sort pairs by distance (ascending) 3. For each pair in sorted order:    - If both units unmatched, assign them 4. Stop when no more matches possible Algorithm: 1. For i = 1 to n_L:    - Find unmatched right unit j with minimum distance to i    - Assign (i, j) 2. Return all assignments # Compare greedy strategies on same data set.seed(101) test_left <- tibble(id = 1:200, x = rnorm(200)) test_right <- tibble(id = 1:200, x = rnorm(200))  strategies <- c(\"sorted\", \"row_best\", \"pq\") results <- list()  for (strat in strategies) {   time <- system.time({     result <- greedy_couples(       test_left, test_right,       vars = \"x\",       strategy = strat     )   })    results[[strat]] <- list(     time = time[\"elapsed\"],     mean_dist = mean(result$pairs$distance),     total_dist = result$info$total_distance   ) }  # Display comparison comparison <- do.call(rbind, lapply(names(results), function(s) {   data.frame(     strategy = s,     time_sec = round(results[[s]]$time, 4),     mean_distance = round(results[[s]]$mean_dist, 4),     total_distance = round(results[[s]]$total_dist, 2)   ) }))  print(comparison) #>          strategy time_sec mean_distance total_distance #> elapsed    sorted     0.05        0.0912          18.24 #> elapsed1 row_best     0.05        0.0968          19.36 #> elapsed2       pq     0.04        0.0912          18.24"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"caliper-constraints","dir":"Articles","previous_headings":"","what":"Caliper Constraints","title":"Matching Workflows: From Data to Publication","text":"Calipers impose maximum allowable match distances ensure minimum quality.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"why-use-calipers","dir":"Articles","previous_headings":"Caliper Constraints","what":"Why Use Calipers","title":"Matching Workflows: From Data to Publication","text":"Without calipers, optimal matching may pair dissimilar units just maximize number matches. Calipers prevent : Setting distance threshold beyond matches forbidden Reducing number matches improve average quality Implementing “common support” requirement propensity score matching","code":"# Create data where some units are far apart set.seed(202) left_cal <- tibble(   id = 1:50,   x = c(rnorm(40, mean = 0, sd = 1), rnorm(10, mean = 5, sd = 0.5))  # Some outliers ) right_cal <- tibble(   id = 1:50,   x = rnorm(50, mean = 0, sd = 1) )  # Match without caliper - pairs everything result_no_cal <- match_couples(   left_cal, right_cal,   vars = \"x\",   auto_scale = FALSE )  # Match with caliper - excludes poor matches result_with_cal <- match_couples(   left_cal, right_cal,   vars = \"x\",   max_distance = 1.5,  # Caliper: max distance = 1.5   auto_scale = FALSE )  cat(\"Without caliper:\\n\") #> Without caliper: cat(\"  Matched:\", result_no_cal$info$n_matched, \"\\n\") #>   Matched: 50 cat(\"  Mean distance:\", round(mean(result_no_cal$pairs$distance), 3), \"\\n\") #>   Mean distance: 1.129 cat(\"  Max distance:\", round(max(result_no_cal$pairs$distance), 3), \"\\n\\n\") #>   Max distance: 5.453  cat(\"With caliper (1.5):\\n\") #> With caliper (1.5): cat(\"  Matched:\", result_with_cal$info$n_matched, \"\\n\") #>   Matched: 40 cat(\"  Mean distance:\", round(mean(result_with_cal$pairs$distance), 3), \"\\n\") #>   Mean distance: 0.143 cat(\"  Max distance:\", round(max(result_with_cal$pairs$distance), 3), \"\\n\") #>   Max distance: 0.763  # Visualize caliper effect ggplot(result_no_cal$pairs, aes(x = distance)) +   geom_histogram(aes(fill = \"No caliper\"), bins = 30, alpha = 0.5) +   geom_histogram(     data = result_with_cal$pairs,     aes(fill = \"With caliper\"),     bins = 30,     alpha = 0.5   ) +   geom_vline(xintercept = 1.5, linetype = \"dashed\", color = \"red\") +   labs(     title = \"Caliper Effect on Match Distances\",     x = \"Distance\",     y = \"Count\",     fill = \"Condition\"   ) +   theme_minimal()"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"choosing-caliper-width","dir":"Articles","previous_headings":"Caliper Constraints","what":"Choosing Caliper Width","title":"Matching Workflows: From Data to Publication","text":"Common approaches: 1. Standard deviation rule: Caliper = 0.1 0.25 pooled SD 2. Propensity score rule: 0.1 0.25 SD propensity score logit 3. Empirical rule: Examine distance distribution, exclude extreme tail","code":"# Calculate pooled SD combined <- bind_rows(   left_data %>% mutate(group = \"left\"),   right_data %>% mutate(group = \"right\") )  pooled_sd <- sd(combined$age)  # For single variable caliper_width <- 0.2 * pooled_sd  result <- match_couples(   left_data, right_data,   vars = \"age\",   max_distance = caliper_width ) # Fit all matches first all_matches <- match_couples(left_cal, right_cal, vars = \"x\")  # Choose caliper at 90th percentile caliper_90 <- quantile(all_matches$pairs$distance, 0.90)  # Refit with caliper refined_matches <- match_couples(   left_cal, right_cal,   vars = \"x\",   max_distance = caliper_90 )  cat(\"90th percentile caliper:\", round(caliper_90, 3), \"\\n\") #> 90th percentile caliper: 4.532 cat(\"Matches retained:\",     round(100 * refined_matches$info$n_matched / all_matches$info$n_matched, 1), \"%\\n\") #> Matches retained: 100 %"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"blocking-and-stratification","dir":"Articles","previous_headings":"","what":"Blocking and Stratification","title":"Matching Workflows: From Data to Publication","text":"Blocking (exact matching key variables) combined distance matching remaining covariates powerful strategy.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"why-use-blocking","dir":"Articles","previous_headings":"Blocking and Stratification","what":"Why Use Blocking","title":"Matching Workflows: From Data to Publication","text":"Benefits: Ensures exact balance critical variables (site, gender, age category) Reduces problem size (smaller within-block matching problems) Prevents poor cross-block matches Transparent interpretable use: Strong domain knowledge important stratification variables Variables absolutely must balanced (e.g., study site multi-center trials) Large datasets blocking reduces computational burden","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"exact-blocking-with-matchmaker","dir":"Articles","previous_headings":"Blocking and Stratification","what":"Exact Blocking with matchmaker()","title":"Matching Workflows: From Data to Publication","text":"","code":"# Create multi-site data set.seed(303) multi_site <- bind_rows(   tibble(     id = 1:100,     site = sample(c(\"A\", \"B\", \"C\"), 100, replace = TRUE),     age = rnorm(100, 50, 10),     income = rnorm(100, 55000, 15000),     group = \"treatment\"   ),   tibble(     id = 101:250,     site = sample(c(\"A\", \"B\", \"C\"), 150, replace = TRUE),     age = rnorm(150, 50, 10),     income = rnorm(150, 55000, 15000),     group = \"control\"   ) )  left_site <- multi_site %>% filter(group == \"treatment\") right_site <- multi_site %>% filter(group == \"control\")  # Create exact blocks by site blocks <- matchmaker(   left = left_site,   right = right_site,   block_type = \"group\",   block_by = \"site\" )  cat(\"Blocking structure:\\n\") #> Blocking structure: print(blocks$block_summary) #> # A tibble: 3 × 3 #>   block_id n_left n_right #>   <chr>     <dbl>   <dbl> #> 1 A            36      58 #> 2 B            26      42 #> 3 C            38      50  # Match within blocks result_blocked <- match_couples(   left = blocks$left,   right = blocks$right,   vars = c(\"age\", \"income\"),   block_id = \"block_id\",  # Use block IDs from matchmaker   auto_scale = TRUE ) #> Auto-selected scaling method: standardize  # Verify exact site balance result_blocked$pairs %>%   mutate(left_id = as.integer(left_id), right_id = as.integer(right_id)) %>%   left_join(left_site %>% select(id, site), by = c(\"left_id\" = \"id\")) %>%   left_join(right_site %>% select(id, site), by = c(\"right_id\" = \"id\"), suffix = c(\"_left\", \"_right\")) %>%   count(site_left, site_right) #> # A tibble: 3 × 3 #>   site_left site_right     n #>   <chr>     <chr>      <int> #> 1 A         A             36 #> 2 B         B             26 #> 3 C         C             38"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"cluster-based-blocking","dir":"Articles","previous_headings":"Blocking and Stratification","what":"Cluster-Based Blocking","title":"Matching Workflows: From Data to Publication","text":"continuous variables, use k-means clustering create blocks:","code":"# Create blocks based on age groups (data-driven) cluster_blocks <- matchmaker(   left = left_site,   right = right_site,   block_type = \"cluster\",   block_vars = \"age\",   n_blocks = 3 )  cat(\"Cluster-based blocks:\\n\") #> Cluster-based blocks: print(cluster_blocks$block_summary) #> # A tibble: 3 × 4 #>   block_id  n_left n_right mean_age #>   <chr>      <dbl>   <dbl>    <dbl> #> 1 cluster_1     37      56     61.2 #> 2 cluster_2     41      65     48.4 #> 3 cluster_3     22      29     37.9  # Match within clusters result_clustered <- match_couples(   left = cluster_blocks$left,   right = cluster_blocks$right,   vars = c(\"age\", \"income\"),   block_id = \"block_id\",   auto_scale = TRUE ) #> Auto-selected scaling method: standardize  # Show age distribution by cluster cluster_blocks$left %>%   group_by(block_id) %>%   summarise(     n = n(),     mean_age = mean(age),     sd_age = sd(age)   ) #> # A tibble: 3 × 4 #>   block_id      n mean_age sd_age #>   <chr>     <int>    <dbl>  <dbl> #> 1 cluster_1    37     61.2   4.59 #> 2 cluster_2    41     48.4   3.27 #> 3 cluster_3    22     37.9   4.42"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"balance-diagnostics","dir":"Articles","previous_headings":"","what":"Balance Diagnostics","title":"Matching Workflows: From Data to Publication","text":"matching, assess balance quality using balance_diagnostics().","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"key-balance-metrics","dir":"Articles","previous_headings":"Balance Diagnostics","what":"Key Balance Metrics","title":"Matching Workflows: From Data to Publication","text":"1. Standardized differences: Std Diff=x‾left−x‾right(sleft2+sright2)/2 \\text{Std Diff} = \\frac{\\bar{x}_{\\text{left}} - \\bar{x}_{\\text{right}}}{\\sqrt{(s_{\\text{left}}^2 + s_{\\text{right}}^2) / 2}} Thresholds: - < 0.1: Excellent balance - 0.1 - 0.25: Good balance - 0.25 - 0.5: Acceptable (may need adjustment) - > 0.5: Poor balance (reconsider matching strategy) 2. Variance ratios: VR=sleft2sright2 \\text{VR} = \\frac{s_{\\text{left}}^2}{s_{\\text{right}}^2} Interpretation: - Close 1.0: Similar variability (good) - < 0.5 > 2.0: Concerning imbalance spread 3. Kolmogorov-Smirnov tests: Non-parametric test distributional differences Sensitive differences beyond mean/variance P-value > 0.05 suggests similar distributions","code":"# Perform matching match_result <- match_couples(   left = left_data,   right = right_data,   vars = c(\"age\", \"income\"),   auto_scale = TRUE ) #> Auto-selected scaling method: standardize  # Get matched samples matched_left <- left_data %>%   filter(id %in% match_result$pairs$left_id)  matched_right <- right_data %>%   filter(id %in% match_result$pairs$right_id)  # Compute balance diagnostics balance <- balance_diagnostics(   result = match_result,   left = left_data,   right = right_data,   vars = c(\"age\", \"income\") )  # Print balance summary print(balance) #>  #> Balance Diagnostics for Matched Pairs #> ====================================== #>  #> Matching Summary: #>   Method: lap #>   Matched pairs: 100 #>   Unmatched left: 0 (of 100) #>   Unmatched right: 50 (of 150) #>  #> Variable-level Balance: #> # A tibble: 2 × 7 #>   Variable `Mean Left` `Mean Right` `Mean Diff` `Std Diff` `Var Ratio` `KS Stat` #>   <chr>          <dbl>        <dbl>       <dbl>      <dbl>       <dbl>     <dbl> #> 1 age             45.9         47.3       -1.43     -0.148       0.891      0.18 #> 2 income       58387.       56118.      2269.        0.155       0.982      0.09 #>  #> Overall Balance: #>   Mean |Std Diff|: 0.151 (Good) #>   Max |Std Diff|: 0.155 #>   Vars with |Std Diff| > 0.25: 0.0% #>  #> Balance Interpretation: #>   |Std Diff| < 0.10: Excellent balance #>   |Std Diff| 0.10-0.25: Good balance #>   |Std Diff| 0.25-0.50: Acceptable balance #>   |Std Diff| > 0.50: Poor balance  # Extract balance table for reporting balance_table(balance) #> # A tibble: 2 × 7 #>   Variable `Mean Left` `Mean Right` `Mean Diff` `Std Diff` `Var Ratio` `KS Stat` #>   <chr>          <dbl>        <dbl>       <dbl>      <dbl>       <dbl>     <dbl> #> 1 age             45.9         47.3       -1.43     -0.148       0.891      0.18 #> 2 income       58387.       56118.      2269.        0.155       0.982      0.09"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"how-to-interpret-balance-results","dir":"Articles","previous_headings":"Balance Diagnostics","what":"How to Interpret Balance Results","title":"Matching Workflows: From Data to Publication","text":"balance diagnostics output tells whether match succeeded. ’s read : Reading column: Quality thresholds standardized differences: < 0.1: Excellent balance—treat successfully matched 0.1–0.25: Good balance—acceptable purposes 0.25–0.5: Marginal—consider refinement sensitivity analysis > 0.5: Poor balance—matching strategy needs revision balance poor: Add matching variables explain imbalance Tighten calipers (accept fewer matches better quality) Try blocking problematic variable Report discuss limitations section","code":"Balance Diagnostics ------------------- Variables: age, income  Variable Statistics:   variable mean_left mean_right std_diff var_ratio ks_stat ks_p   age      45.2      45.8       -0.08    0.95      0.06    0.89   income   58000     56500      0.12     1.08      0.09    0.45"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"visualizing-balance","dir":"Articles","previous_headings":"Balance Diagnostics","what":"Visualizing Balance","title":"Matching Workflows: From Data to Publication","text":"","code":"# Before-after balance plot # (Requires creating pre-match balance for comparison)  # For pre-match comparison, just compute summary statistics directly pre_match_stats <- tibble(   variable = c(\"age\", \"income\"),   std_diff = c(     (mean(left_data$age) - mean(right_data$age)) / sqrt((sd(left_data$age)^2 + sd(right_data$age)^2) / 2),     (mean(left_data$income) - mean(right_data$income)) / sqrt((sd(left_data$income)^2 + sd(right_data$income)^2) / 2)   ),   when = \"Before\" )  # Combine for plotting balance_comparison <- bind_rows(   pre_match_stats,   balance$var_stats %>% select(variable, std_diff) %>% mutate(when = \"After\") )  ggplot(balance_comparison, aes(x = variable, y = std_diff, fill = when)) +   geom_col(position = \"dodge\") +   geom_hline(yintercept = c(-0.1, 0.1), linetype = \"dashed\", color = \"darkgreen\") +   geom_hline(yintercept = c(-0.25, 0.25), linetype = \"dashed\", color = \"orange\") +   labs(     title = \"Covariate Balance Before and After Matching\",     x = \"Variable\",     y = \"Standardized Difference\",     fill = \"Timing\"   ) +   theme_minimal() +   coord_flip()"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"real-world-example-treatment-effect-estimation","dir":"Articles","previous_headings":"","what":"Real-World Example: Treatment Effect Estimation","title":"Matching Workflows: From Data to Publication","text":"Complete workflow estimating treatment effects observational study.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"scenario","dir":"Articles","previous_headings":"Real-World Example: Treatment Effect Estimation","what":"Scenario","title":"Matching Workflows: From Data to Publication","text":"Evaluate effect job training program earnings. Participants self-selected program, creating potential selection bias. Data: - Treatment: 200 program participants - Control: 500 non-participants - Covariates: age, education, prior earnings, employment status - Outcome: Earnings one year program","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"step-1-data-preparation","dir":"Articles","previous_headings":"Real-World Example: Treatment Effect Estimation","what":"Step 1: Data Preparation","title":"Matching Workflows: From Data to Publication","text":"","code":"set.seed(404)  # Simulate realistic scenario with selection bias # Program attracts younger, more educated, currently employed individuals create_participant <- function(n, is_treatment) {   if (is_treatment) {     tibble(       id = 1:n,       age = rnorm(n, mean = 35, sd = 8),       education_years = rnorm(n, mean = 14, sd = 2),       prior_earnings = rnorm(n, mean = 35000, sd = 10000),       employed = sample(c(0, 1), n, replace = TRUE, prob = c(0.3, 0.7)),       treatment = 1     )   } else {     tibble(       id = (n+1):(n+500),       age = rnorm(500, mean = 42, sd = 12),       education_years = rnorm(500, mean = 12, sd = 3),       prior_earnings = rnorm(500, mean = 30000, sd = 12000),       employed = sample(c(0, 1), 500, replace = TRUE, prob = c(0.5, 0.5)),       treatment = 0     )   } }  treatment_group <- create_participant(200, TRUE) control_group <- create_participant(500, FALSE)  # Simulate outcome (earnings) with treatment effect # True effect: +$5,000, with heterogeneity treatment_group <- treatment_group %>%   mutate(     earnings = prior_earnings +       5000 +  # True treatment effect       2000 * rnorm(n()) +  # Random variation       100 * education_years  # Education effect   )  control_group <- control_group %>%   mutate(     earnings = prior_earnings +       2000 * rnorm(n()) +       100 * education_years   )  # Examine baseline imbalance cat(\"Pre-matching differences:\\n\") #> Pre-matching differences: cat(\"Age diff:\",     mean(treatment_group$age) - mean(control_group$age), \"\\n\") #> Age diff: -5.525329 cat(\"Education diff:\",     mean(treatment_group$education_years) - mean(control_group$education_years), \"\\n\") #> Education diff: 1.801605 cat(\"Prior earnings diff:\",     mean(treatment_group$prior_earnings) - mean(control_group$prior_earnings), \"\\n\") #> Prior earnings diff: 5420.931"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"step-2-perform-matching","dir":"Articles","previous_headings":"Real-World Example: Treatment Effect Estimation","what":"Step 2: Perform Matching","title":"Matching Workflows: From Data to Publication","text":"","code":"# Match on baseline covariates job_match <- match_couples(   left = treatment_group,   right = control_group,   vars = c(\"age\", \"education_years\", \"prior_earnings\", \"employed\"),   auto_scale = TRUE,   scale = \"robust\",   return_diagnostics = TRUE )  cat(\"Matching summary:\\n\") #> Matching summary: cat(\"  Treated units:\", nrow(treatment_group), \"\\n\") #>   Treated units: 200 cat(\"  Matched treated:\", job_match$info$n_matched, \"\\n\") #>   Matched treated: 200 cat(\"  Match rate:\",     round(100 * job_match$info$n_matched / nrow(treatment_group), 1), \"%\\n\") #>   Match rate: 100 %"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"step-3-assess-balance","dir":"Articles","previous_headings":"Real-World Example: Treatment Effect Estimation","what":"Step 3: Assess Balance","title":"Matching Workflows: From Data to Publication","text":"","code":"# Extract matched samples matched_treated <- treatment_group %>%   filter(id %in% job_match$pairs$left_id)  matched_control <- control_group %>%   filter(id %in% job_match$pairs$right_id)  # Compute balance job_balance <- balance_diagnostics(   result = job_match,   left = treatment_group,   right = control_group,   vars = c(\"age\", \"education_years\", \"prior_earnings\", \"employed\") ) #> Warning in ks.test.default(left_clean, right_clean): p-value will be #> approximate in the presence of ties  print(job_balance) #>  #> Balance Diagnostics for Matched Pairs #> ====================================== #>  #> Matching Summary: #>   Method: lap #>   Matched pairs: 200 #>   Unmatched left: 0 (of 200) #>   Unmatched right: 300 (of 500) #>  #> Variable-level Balance: #> # A tibble: 4 × 7 #>   Variable `Mean Left` `Mean Right` `Mean Diff` `Std Diff` `Var Ratio` `KS Stat` #>   <chr>          <dbl>        <dbl>       <dbl>      <dbl>       <dbl>     <dbl> #> 1 age             35.4       36.0        -0.656     -0.081       0.869     0.1   #> 2 educati…        13.9       13.5         0.4        0.195       0.93      0.18  #> 3 prior_e…     35015.     33795.       1219.         0.121       1.01      0.08  #> 4 employed         0.7        0.635       0.065      0.138       0.952     0.065 #>  #> Overall Balance: #>   Mean |Std Diff|: 0.134 (Good) #>   Max |Std Diff|: 0.195 #>   Vars with |Std Diff| > 0.25: 0.0% #>  #> Balance Interpretation: #>   |Std Diff| < 0.10: Excellent balance #>   |Std Diff| 0.10-0.25: Good balance #>   |Std Diff| 0.25-0.50: Acceptable balance #>   |Std Diff| > 0.50: Poor balance  # Check overall balance quality cat(\"\\nOverall balance:\\n\") #>  #> Overall balance: cat(\"  Mean |std diff|:\", round(job_balance$overall$mean_abs_std_diff, 3), \"\\n\") #>   Mean |std diff|: 0.134 cat(\"  Max |std diff|:\", round(job_balance$overall$max_abs_std_diff, 3), \"\\n\") #>   Max |std diff|: 0.195 cat(\"  % with |std diff| > 0.1:\",     round(job_balance$overall$pct_large_imbalance, 1), \"%\\n\") #>   % with |std diff| > 0.1: 0 %"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"step-4-estimate-treatment-effect","dir":"Articles","previous_headings":"Real-World Example: Treatment Effect Estimation","what":"Step 4: Estimate Treatment Effect","title":"Matching Workflows: From Data to Publication","text":"","code":"# Naive estimate (without matching) - BIASED naive_effect <- mean(treatment_group$earnings) - mean(control_group$earnings)  # Matched estimate - accounts for baseline differences matched_effect <- mean(matched_treated$earnings) - mean(matched_control$earnings)  # Paired t-test for significance paired_comparison <- tibble(   treated = matched_treated$earnings,   control = matched_control$earnings[match(     matched_treated$id,     job_match$pairs$left_id   )] )  t_test <- t.test(paired_comparison$treated, paired_comparison$control, paired = TRUE)  # Report results cat(\"Treatment Effect Estimates:\\n\\n\") #> Treatment Effect Estimates: cat(\"Naive (unmatched):\\n\") #> Naive (unmatched): cat(\"  Difference: $\", round(naive_effect, 0), \"\\n\") #>   Difference: $ 10680 cat(\"  (Upward biased due to selection)\\n\\n\") #>   (Upward biased due to selection)  cat(\"Matched estimate:\\n\") #> Matched estimate: cat(\"  Difference: $\", round(matched_effect, 0), \"\\n\") #>   Difference: $ 6276 cat(\"  95% CI: ($\", round(t_test$conf.int[1], 0), \", $\",     round(t_test$conf.int[2], 0), \")\\n\") #>   95% CI: ($ 4301 , $ 8252 ) cat(\"  P-value:\", format.pval(t_test$p.value, digits = 3), \"\\n\") #>   P-value: 2.26e-09 cat(\"  (Closer to true effect of $5,000)\\n\") #>   (Closer to true effect of $5,000)"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"step-5-publication-ready-output","dir":"Articles","previous_headings":"Real-World Example: Treatment Effect Estimation","what":"Step 5: Publication-Ready Output","title":"Matching Workflows: From Data to Publication","text":"","code":"# Table 1: Balance table balance_publication <- balance_table(job_balance) print(balance_publication)  # Table 2: Sample characteristics sample_table <- bind_rows(   matched_treated %>%     summarise(       Group = \"Treatment\",       N = n(),       `Age (mean ± SD)` = sprintf(\"%.1f ± %.1f\", mean(age), sd(age)),       `Education (years)` = sprintf(\"%.1f ± %.1f\", mean(education_years), sd(education_years)),       `Prior Earnings` = sprintf(\"$%s ± %s\",                                  format(round(mean(prior_earnings)), big.mark = \",\"),                                  format(round(sd(prior_earnings)), big.mark = \",\")),       `Employed (%)` = sprintf(\"%.1f\", 100 * mean(employed))     ),   matched_control %>%     summarise(       Group = \"Control\",       N = n(),       `Age (mean ± SD)` = sprintf(\"%.1f ± %.1f\", mean(age), sd(age)),       `Education (years)` = sprintf(\"%.1f ± %.1f\", mean(education_years), sd(education_years)),       `Prior Earnings` = sprintf(\"$%s ± %s\",                                  format(round(mean(prior_earnings)), big.mark = \",\"),                                  format(round(sd(prior_earnings)), big.mark = \",\")),       `Employed (%)` = sprintf(\"%.1f\", 100 * mean(employed))     ) )  print(sample_table)  # Table 3: Treatment effect effect_table <- tibble(   Method = c(\"Unmatched\", \"Matched\"),   `N (Treated)` = c(nrow(treatment_group), nrow(matched_treated)),   `N (Control)` = c(nrow(control_group), nrow(matched_control)),   `Effect Estimate` = sprintf(\"$%s\", format(round(c(naive_effect, matched_effect)), big.mark = \",\")),   `95% CI` = c(\"--\", sprintf(\"($%s, $%s)\",                             format(round(t_test$conf.int[1]), big.mark = \",\"),                             format(round(t_test$conf.int[2]), big.mark = \",\"))) )  print(effect_table)"},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"scalability","dir":"Articles","previous_headings":"Performance Considerations","what":"Scalability","title":"Matching Workflows: From Data to Publication","text":"Optimal matching complexity: O(n3)O(n^3) using Jonker-Volgenant n = 100: < 0.01 seconds n = 500: ~ 0.1 seconds n = 1,000: ~ 1 second n = 3,000: ~ 10 seconds n = 5,000: ~ 30-60 seconds Greedy matching complexity: O(n2log⁡n)O(n^2 \\log n) sorted, O(n2)O(n^2) row-best n = 5,000: ~ 1 second n = 10,000: ~ 3-5 seconds n = 50,000: ~ 30-60 seconds","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"memory-usage","dir":"Articles","previous_headings":"Performance Considerations","what":"Memory Usage","title":"Matching Workflows: From Data to Publication","text":"Cost matrix: 8n² bytes (n×n problem) n = 1,000: ~ 8 MB n = 5,000: ~ 200 MB n = 10,000: ~ 800 MB large problems: Use greedy matching avoid full cost matrix Use blocking reduce within-block size Consider approximate methods (upcoming vignette)","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"optimization-tips","dir":"Articles","previous_headings":"Performance Considerations","what":"Optimization Tips","title":"Matching Workflows: From Data to Publication","text":"1. Use blocking large datasets 2. Start greedy, refine needed 3. Use calipers reduce problem size","code":"# Instead of matching 10,000 × 10,000: # Create 10 blocks of ~1,000 × 1,000 each blocks <- matchmaker(   left_large, right_large,   block_type = \"cluster\",   cluster_vars = \"age\",   n_clusters = 10 )  # Much faster: 10 * O(1000^3) << O(10000^3) result <- match_couples(   blocks$left, blocks$right,   vars = covariates,   block_id = \"block_id\" ) # Quick greedy match for exploration quick <- greedy_couples(   left_data, right_data,   vars = covariates,   strategy = \"row_best\" )  # Assess balance balance_quick <- balance_diagnostics(quick, left_data, right_data, vars = covariates)  # If balance is acceptable, done! # If not, try optimal or add blocking # Caliper removes distant pairs from cost matrix # Can dramatically reduce effective problem size result <- match_couples(   left_data, right_data,   vars = covariates,   max_distance = 0.25,  # Strict caliper   auto_scale = TRUE )"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"what-can-go-wrong","dir":"Articles","previous_headings":"","what":"What Can Go Wrong","title":"Matching Workflows: From Data to Publication","text":"Matching doesn’t always succeed. common problems solutions.","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"problem-poor-balance-despite-matching","dir":"Articles","previous_headings":"What Can Go Wrong","what":"Problem: Poor Balance Despite Matching","title":"Matching Workflows: From Data to Publication","text":"Symptom: balance_diagnostics() shows |std_diff| > 0.25 variables. Causes: - Groups fundamentally different (weak overlap) - Important confounders included matching variables - Caliper loose Solutions:","code":"# 1. Add more matching variables result <- match_couples(left, right,                         vars = c(\"age\", \"income\", \"education\", \"region\"),  # Added!                         auto_scale = TRUE)  # 2. Tighten caliper (fewer but better matches) result <- match_couples(left, right, vars = vars,                         max_distance = 0.1)  # Was 0.5  # 3. Block on the problematic variable blocks <- matchmaker(left, right, block_type = \"group\", block_by = \"region\") result <- match_couples(blocks$left, blocks$right, vars = other_vars,                         block_id = \"block_id\")"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"problem-very-few-matches","dir":"Articles","previous_headings":"What Can Go Wrong","what":"Problem: Very Few Matches","title":"Matching Workflows: From Data to Publication","text":"Symptom: n_matched much smaller nrow(left). Causes: - Caliper strict - Non-overlapping covariate distributions - Blocking creates small strata Diagnosis: Solutions: - Relax caliper - Use coarser blocking categories - Accept treatment units unmatchable (report !)","code":"# Check covariate overlap library(ggplot2) combined <- bind_rows(   left %>% mutate(group = \"treatment\"),   right %>% mutate(group = \"control\") ) ggplot(combined, aes(x = age, fill = group)) +   geom_density(alpha = 0.5) +   labs(title = \"Check for Overlap\")"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"problem-matching-takes-too-long","dir":"Articles","previous_headings":"What Can Go Wrong","what":"Problem: Matching Takes Too Long","title":"Matching Workflows: From Data to Publication","text":"Symptom: match_couples() runs minutes doesn’t complete. Cause: O(n3)O(n^3) complexity optimal matching. Solutions:","code":"# For n > 3000: use greedy result <- greedy_couples(left, right, vars = vars, strategy = \"sorted\")  # For n > 5000: add blocking blocks <- matchmaker(left, right, block_type = \"cluster\", n_blocks = 20) result <- match_couples(blocks$left, blocks$right, vars = vars,                         block_id = \"block_id\")"},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"problem-memory-error","dir":"Articles","previous_headings":"What Can Go Wrong","what":"Problem: Memory Error","title":"Matching Workflows: From Data to Publication","text":"Symptom: R crashes reports “allocate vector size X”. Cause: Full cost matrix doesn’t fit RAM. 10,000×10,000 matrix needs ~800 MB. Solutions: - Use greedy_couples() doesn’t require full matrix - Use blocking create smaller sub-problems - Consider random sampling sample size permits","code":""},{"path":"https://gcol33.github.io/couplr/articles/matching-workflows.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Matching Workflows: From Data to Publication","text":"vignette walked complete matching workflow using job training evaluation example: Problem framing: Treatment effect estimation selection bias Matching: Creating comparable groups match_couples() Preprocessing: Automatic scaling variable health checks Assessment: Balance diagnostics interpretation Refinement: Calipers, blocking, greedy alternatives Estimation: Treatment effect confidence intervals Key Takeaways: Recommended Workflow: ’s Next? Function reference: ?match_couples, ?greedy_couples, ?balance_diagnostics, ?matchmaker","code":"1. Explore data → Identify confounders                       ↓ 2. First match   → match_couples(vars, auto_scale = TRUE)                       ↓ 3. Check balance → balance_diagnostics()                       ↓        ┌──────────────┴──────────────┐     Balance OK                   Balance poor        ↓                              ↓ 4. Estimate effect             Refine: caliper, blocking,                                more variables                                       ↓                                Return to step 3"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Optimal Matching in Science: From Theory to Practice","text":"vignette serves three purposes: Build intuition: Use pixel morphing visual analogy assignment problems Scale : Demonstrate approximation strategies exact LAP becomes infeasible Scientific applications: Show matching applies ecology, physics, chemistry vignette different: Unlike couplr documentation, emphasizes understanding . ’re looking solve matching problem today, start vignette(\"getting-started\") vignette(\"matching-workflows\"). Come want understand algorithms work approximations appropriate.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"who-this-vignette-is-for","dir":"Articles","previous_headings":"Overview","what":"Who This Vignette Is For","title":"Optimal Matching in Science: From Theory to Practice","text":"Audience: Advanced users, researchers, algorithm developers, curious minds Prerequisites: Familiarity lap_solve() (vignette(\"getting-started\")) Basic complexity analysis (Big-O notation) Interest algorithm design scientific computing ’ll Learn: exact LAP becomes infeasible large n Three approximation strategies trade-offs matching problems appear ecology, physics, chemistry Mathematical connections optimal transport theory Time complete: 45-60 minutes (conceptual reading)","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"documentation-roadmap","dir":"Articles","previous_headings":"Overview","what":"Documentation Roadmap","title":"Optimal Matching in Science: From Theory to Practice","text":": Pixel Morphing (Advanced)","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"why-pixels","dir":"Articles","previous_headings":"Overview","what":"Why Pixels?","title":"Optimal Matching in Science: From Theory to Practice","text":"Pixels provide ideal testbed understanding assignment problems: pixel entity measurable properties Color = feature (looks like) Position = spatial location () matching visually verifiable—can see worked algorithms morph images smoothly also track particles physics, align molecules chemistry, match vegetation plots ecology.","code":""},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"problem-formulation","dir":"Articles","previous_headings":"The General Matching Problem","what":"Problem Formulation","title":"Optimal Matching in Science: From Theory to Practice","text":"Given two sets entities ={a1,…,}= \\{a_1, \\ldots, a_n\\} B={b1,…,bn}B = \\{b_1, \\ldots, b_n\\}, find optimal one--one correspondence minimizing minπ∑=1nci,π() \\min_{\\pi} \\sum_{=1}^{n} c_{,\\pi()} cost combines feature similarity spatial proximity: cij=αdfeature(ai,bj)+βdspatial(𝐱,𝐱j). c_{ij} = \\alpha \\, d_{\\text{feature}}(a_i, b_j) + \\beta \\, d_{\\text{spatial}}(\\mathbf{x}_i, \\mathbf{x}_j). Feature distance dfeatured_{\\text{feature}}: domain-specific similarity Ecology: Bray-Curtis dissimilarity species vectors Physics: difference particle intensity size Chemistry: penalty mismatched atom types Images: Euclidean distance RGB color space Spatial distance dspatiald_{\\text{spatial}}: physical proximity Ecology: geographic distance plot centers Physics: Euclidean distance accounting predicted motion Chemistry: 3D distance atomic coordinates Images: 2D pixel position distance Weights α,β≥0\\alpha, \\beta \\ge 0 balance feature matching vs. spatial coherence.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"computational-challenge","dir":"Articles","previous_headings":"The General Matching Problem","what":"Computational Challenge","title":"Optimal Matching in Science: From Theory to Practice","text":"Exact solution: solve full n×nn \\times n LAP. Complexity: O(n3)O(n^3) using Jonker-Volgenant Feasible: n≈1000n \\approx 1000 (30×3030 \\times 30 images, 10001000 plots/particles/atoms) Prohibitive: n=10000n = 10\\,000 (100×100100 \\times 100 images), runtime memory become expensive Real applications often involve High-resolution images: 200×200=40000200 \\times 200 = 40\\,000 pixels Large ecological surveys: 5000+5000+ plots Particle tracking: 10000+10\\,000+ particles per frame Molecular dynamics: 100000+100\\,000+ atoms therefore need approximations much faster still produce high-quality matchings.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"visual-illustration-pixel-morphing","dir":"Articles","previous_headings":"","what":"Visual Illustration: Pixel Morphing","title":"Optimal Matching in Science: From Theory to Practice","text":"make abstract ideas concrete, visualize using image morphing entities = pixels features = RGB color values spatial position = (x,y)(x, y) coordinates first show static input images (80×8080 \\times 80 display), animated morphs produced different matching strategies.  first pair real photographs, second pair simple geometric shapes. Internally, matching computed logical 40×4040 \\times 40 grids; upscale 80×8080 \\times 80 purely clearer display.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"exact-pixel-matching","dir":"Articles","previous_headings":"Visual Illustration: Pixel Morphing","what":"Exact Pixel Matching","title":"Optimal Matching in Science: From Theory to Practice","text":"exact pixel morph uses full LAP solution 1600×16001600 \\times 1600 cost matrix. pair pixels (,j)(, j) compute cij=α‖RGBiA−RGBjB‖2+β‖(xi,yi)−(xj,yj)‖2, c_{ij} = \\alpha \\,\\lVert \\text{RGB}_i^- \\text{RGB}_j^B \\rVert_2 +          \\beta \\,\\lVert (x_i, y_i) - (x_j, y_j) \\rVert_2, color distances normalized [0,3][0, \\sqrt{3}] (RGB [0,1][0,1]) spatial distances [0,1][0,1] using image diagonal.  yields optimal one--one assignment pixels. resulting animations smooth artifact-free require solving full LAP.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"feature-quantization-morph-strategy-1","dir":"Articles","previous_headings":"Visual Illustration: Pixel Morphing","what":"Feature Quantization Morph (Strategy 1)","title":"Optimal Matching in Science: From Theory to Practice","text":"feature quantization morph, similar colors grouped, groups matched rather individual pixels. Colors move coherent “bands,” preserving global color structure losing fine-grained per-pixel detail.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"hierarchical-morph-strategy-2","dir":"Articles","previous_headings":"Visual Illustration: Pixel Morphing","what":"Hierarchical Morph (Strategy 2)","title":"Optimal Matching in Science: From Theory to Practice","text":"hierarchical morph first matches large patches, refines within patches. motion locally coherent scales well large problems, price potentially missing globally optimal cross-patch matches.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"three-approximation-strategies","dir":"Articles","previous_headings":"","what":"Three Approximation Strategies","title":"Optimal Matching in Science: From Theory to Practice","text":"now describe three approximation strategies detail. animations correspond directly methods.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"strategy-1-feature-quantization","dir":"Articles","previous_headings":"Three Approximation Strategies","what":"Strategy 1: Feature Quantization","title":"Optimal Matching in Science: From Theory to Practice","text":"Core idea: reduce problem size grouping entities similar features, match groups.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"mathematical-formulation","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 1: Feature Quantization","what":"Mathematical Formulation","title":"Optimal Matching in Science: From Theory to Practice","text":"Quantize features Map continuous feature space finite palette quantize:ℝd→{1,…,k}, \\text{quantize}: \\mathbb{R}^d \\\\{1, \\ldots, k\\}, k≪nk \\ll n (example k≈64k \\approx 64 n=1600n = 1600). Group palette Form groups GA(c)={:quantize(fi)=c} G_A^{(c)} = \\{ : \\text{quantize}(f_i) = c \\}  similarly BB. Match groups Solve k×kk \\times k LAP palette entries costs c′ij=αd(pi,pj)+βd(𝐱‾,𝐱‾j), c'_{ij} = \\alpha \\, d(p_i, p_j) + \\beta \\, d(\\bar{\\mathbf{x}}_i, \\bar{\\mathbf{x}}_j), pip_i palette color 𝐱‾\\bar{\\mathbf{x}}_i centroid position group ii. Assign entities Every entity GA(c)G_A^{(c)} assigned according group--group match.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"complexity-reduction","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 1: Feature Quantization","what":"Complexity Reduction","title":"Optimal Matching in Science: From Theory to Practice","text":"Original: O(n3)O(n^3) n×nn \\times n LAP Quantized: O(k3+nk)O(k^3 + n k) k×kk \\times k LAP plus group assignment Speedup: approximately (n/k)3(n/k)^3 example, n=1600n = 1600 (40×4040 \\times 40 image) k=64k = 64 get (160064)3=253≈15000 \\left(\\frac{1600}{64}\\right)^3 = 25^3 \\approx 15\\,000 times fewer LAP operations.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"quality-trade-offs","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 1: Feature Quantization","what":"Quality Trade-offs","title":"Optimal Matching in Science: From Theory to Practice","text":"Advantages large speedups big nn Preserves global structure (similar features stay together) Produces smooth, band-like motion without large jumps Disadvantages Loses detail within palette group Quantization artifacts kk small May miss optimal local pairings similar distinct feature values corresponding GIFs color walk morphs shown earlier.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"strategy-2-hierarchical-decomposition","dir":"Articles","previous_headings":"Three Approximation Strategies","what":"Strategy 2: Hierarchical Decomposition","title":"Optimal Matching in Science: From Theory to Practice","text":"Core idea: split domain smaller subproblems spatial partitioning, solve subproblems, combine.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"mathematical-formulation-1","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 2: Hierarchical Decomposition","what":"Mathematical Formulation","title":"Optimal Matching in Science: From Theory to Practice","text":"Spatial partitioning Divide domain m×mm \\times m patches (example m=4m = 4 get 1616 patches). Denote subset entities AA patch kk PA(k)={ai:𝐱∈Patchk}. P_A^{(k)} = \\{ a_i : \\mathbf{x}_i \\\\text{Patch}_k \\}. Patch-level matching Form patch representatives: centroid position mean features per patch. Solve m2×m2m^2 \\times m^2 LAP patches, costs defined using feature spatial distances now patch level. Recursive refinement Within matched patch pair (PA(k),PB(l))(P_A^{(k)}, P_B^{(l)}): |PA(k)|≤τ\\lvert P_A^{(k)} \\rvert \\le \\tau (threshold, e.g. τ=50\\tau = 50) solve subproblem exactly. Otherwise, partition patch pair repeat. Combine solutions Concatenate assignments leaf subproblems obtain global matching.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"complexity-sketch","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 2: Hierarchical Decomposition","what":"Complexity (Sketch)","title":"Optimal Matching in Science: From Theory to Practice","text":"dd levels decomposition (level splitting four patches), work can made close O(nlog⁡n)O(n \\log n) practice, compared O(n3)O(n^3) single full LAP. Intuitively, LAPs near leaves small, costly large LAP replaced series much smaller ones.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"quality-trade-offs-1","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 2: Hierarchical Decomposition","what":"Quality Trade-offs","title":"Optimal Matching in Science: From Theory to Practice","text":"Advantages Scales large nn (tens thousands entities) Preserves local structure: nearby entities tend matched within spatial patch feature discretization, feature precision retained Disadvantages May miss globally optimal cross-patch matches Quality depends partitioning scheme threshold τ\\tau Possible boundary artifacts important structure crosses patch boundaries","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"high-level-algorithm","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 2: Hierarchical Decomposition","what":"High-Level Algorithm","title":"Optimal Matching in Science: From Theory to Practice","text":"couplr implementation adds pragmatic details normalization color spatial distances, conversion (x,y)(x, y) coordinates raster indexing, handling remainder patches grid divide evenly.","code":"// Pseudocode for hierarchical LAP matching  FUNCTION match_hierarchical(region_A, region_B, threshold, level):    // Base case: region small enough for exact LAP   IF size(region_A) <= threshold THEN     cost ← compute_cost_matrix(region_A, region_B, α, β)     RETURN lap_solve(cost)   END IF    // Divide into 2×2 spatial grid (4 patches)   patches_A ← spatial_partition(region_A, grid = 2×2)   patches_B ← spatial_partition(region_B, grid = 2×2)    // Compute patch representatives   FOR each patch p DO     centroid[p]      ← mean(positions in p)     mean_feature[p]  ← mean(features in p)   END FOR    // Match patches using 4×4 LAP   patch_cost ← matrix(4, 4)   FOR i = 1 TO 4 DO     FOR j = 1 TO 4 DO       patch_cost[i, j] ← α·distance(mean_feature_A[i], mean_feature_B[j]) +                          β·distance(centroid_A[i], centroid_B[j])     END FOR   END FOR    patch_assignment ← lap_solve(patch_cost)    // Recursively solve within matched patches   assignments ← []   FOR i = 1 TO 4 DO     j ← patch_assignment[i]     sub_assignment ← match_hierarchical(       patches_A[i],       patches_B[j],       threshold,       level + 1     )     assignments ← append(assignments, sub_assignment)   END FOR    RETURN concatenate(assignments) END FUNCTION"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"strategy-3-resolution-reduction","dir":"Articles","previous_headings":"Three Approximation Strategies","what":"Strategy 3: Resolution Reduction","title":"Optimal Matching in Science: From Theory to Practice","text":"Core idea: solve LAP coarse grid, lift/upscale assignment full-resolution grid.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"mathematical-formulation-2","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 3: Resolution Reduction","what":"Mathematical Formulation","title":"Optimal Matching in Science: From Theory to Practice","text":"Downscale Reduce spatial resolution factor ss (example s=2s = 2): ′=downsample(,s),B′=downsample(B,s). ' = \\text{downsample}(, s), \\qquad B' = \\text{downsample}(B, s). Now ′' B′B' n′=n/s2n' = n / s^2 entities. Solve low resolution Compute exact LAP solution n′×n′n' \\times n' problem: π′=arg⁡minπ′∑=1n′c′,π′(). \\pi' = \\arg\\min_{\\pi'} \\sum_{=1}^{n'} c'_{,\\pi'()}. Upscale assignment Map low-resolution assignment back full resolution: π()=upscale(π′(coarse_index()),s), \\pi() = \\text{upscale}\\!\\bigl(\\pi'(\\text{coarse\\_index}()), s\\bigr), full-resolution entity inherits assignment coarse cell.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"complexity","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 3: Resolution Reduction","what":"Complexity","title":"Optimal Matching in Science: From Theory to Practice","text":"Original: O(n3)O(n^3) Downscaled: O((n/s2)3)=O(n3/s6)O\\bigl((n/s^2)^3\\bigr) = O(n^3 / s^6) Speedup: s6s^6 s=2s = 2 gives 64×64\\times reduction LAP work.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"quality-trade-offs-2","dir":"Articles","previous_headings":"Three Approximation Strategies > Strategy 3: Resolution Reduction","what":"Quality Trade-offs","title":"Optimal Matching in Science: From Theory to Practice","text":"Advantages simple implement Exact LAP coarse level Large speedups moderate ss Disadvantages Loss fine detail blocky artifacts Assignment longer true permutation pixel level (multiple fine pixels can map coarse target) Quality deteriorates quickly larger ss practice, resolution reduction useful crude initialization step large problems (n>100000n > 100\\,000).","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"strategy-comparison","dir":"Articles","previous_headings":"Three Approximation Strategies","what":"Strategy Comparison","title":"Optimal Matching in Science: From Theory to Practice","text":"Practical rules thumb n<1000n < 1000: use exact LAP. 1000<n<50001000 < n < 5000: feature quantization shallow hierarchy. n>5000n > 5000: hierarchical decomposition 2-3 levels. n>50000n > 50\\,000: combine s=2s = 2 resolution reduction hierarchical method.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"implementation-details-of-exact-pixel-matching","dir":"Articles","previous_headings":"","what":"Implementation Details of Exact Pixel Matching","title":"Optimal Matching in Science: From Theory to Practice","text":"now spell exact LAP-based morph concretely. use cost cij=α‖RGBiA−RGBjB‖2+β‖(xi,yi)−(xj,yj)‖2. c_{ij} = \\alpha \\,\\lVert \\text{RGB}_i^- \\text{RGB}_j^B \\rVert_2 +          \\beta \\,\\lVert (x_i, y_i) - (x_j, y_j) \\rVert_2. algorithm: couplr implementation handles indexing, raster layout, shows saves resulting GIFs. Approximate performance: 100×100100 \\times 100 (10 000 pixels) typical hardware fine exact LAP.","code":"// Pseudocode for exact pixel matching  // Step 1: Compute full cost matrix (normalized) n_pixels ← height × width cost ← matrix(0, n_pixels, n_pixels)  FOR i = 1 TO n_pixels DO   FOR j = 1 TO n_pixels DO     // RGB color distance (normalized to [0, sqrt(3)])     color_dist ← sqrt((R_A[i] - R_B[j])^2 +                       (G_A[i] - G_B[j])^2 +                       (B_A[i] - B_B[j])^2) / (255 · sqrt(3))      // Spatial distance (normalized to [0, 1] by diagonal)     spatial_dist ← sqrt((x_A[i] - x_B[j])^2 +                         (y_A[i] - y_B[j])^2) / diagonal_length      // Combined cost     cost[i, j] ← α · color_dist + β · spatial_dist   END FOR END FOR  // Step 2: Solve with Jonker-Volgenant assignment ← lap_solve(cost, method = \"jv\")  // Step 3: Generate morph frames by linear interpolation FOR frame_idx = 1 TO n_frames DO   t ← frame_idx / n_frames  // Time parameter in [0, 1]    FOR pixel_i = 1 TO n_pixels DO     j ← assignment[pixel_i]  // Matched target pixel      // Interpolate position     x_new[pixel_i] ← (1 - t) · x_A[pixel_i] + t · x_B[j]     y_new[pixel_i] ← (1 - t) · y_A[pixel_i] + t · y_B[j]      // Keep source color (transport-only, no blending)     RGB_new[pixel_i] ← RGB_A[pixel_i]   END FOR    frames[frame_idx] ← render(x_new, y_new, RGB_new) END FOR"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"application-to-scientific-domains","dir":"Articles","previous_headings":"","what":"Application to Scientific Domains","title":"Optimal Matching in Science: From Theory to Practice","text":"now return pixel morphs scientific settings motivated .","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"ecology-vegetation-plot-matching","dir":"Articles","previous_headings":"Application to Scientific Domains","what":"Ecology: Vegetation Plot Matching","title":"Optimal Matching in Science: From Theory to Practice","text":"Problem: match nn vegetation plots surveyed time tt nn plots time t+Δtt + \\Delta t track community dynamics. Feature distance: Bray-Curtis dissimilarity species abundance vectors dBC(,b)=∑s|−bs|∑s(+bs), d_{\\text{BC}}(, b) = \\frac{\\sum_s \\lvert a_s - b_s \\rvert}      {\\sum_s (a_s + b_s)}, ,bsa_s, b_s abundances species ss plots aa bb. Spatial distance: geographic distance (e.g. kilometers) plot centers. Exact solution small studies (n<100n < 100): large studies (n>1000n > 1000) hierarchical approach region practical: allows tracking individual plot trajectories across time, distinguishing stable communities, successional trends, invasion fronts.","code":"// Pseudocode for ecological plot matching FOR i = 1 TO n_plots_t DO   FOR j = 1 TO n_plots_tplus DO      // Bray-Curtis dissimilarity for species composition     numerator   ← sum over species s of |abundance_t[i, s] - abundance_tplus[j, s]|     denominator ← sum over species s of (abundance_t[i, s] + abundance_tplus[j, s])     bc_distance ← numerator / denominator      // Geographic distance (kilometers)     geo_distance ← sqrt((x_t[i] - x_tplus[j])^2 +                         (y_t[i] - y_tplus[j])^2)      // Combined cost (α = 0.7 emphasizes species composition)     cost[i, j] ← 0.7 · bc_distance + 0.3 · (geo_distance / max_distance)    END FOR END FOR  plot_correspondence ← lap_solve(cost) // Hierarchical decomposition by geographic region  // 1. Divide landscape into spatial grid (e.g. 10 km × 10 km cells) regions_t     ← spatial_partition(plots_t,     grid_size = 10 km) regions_tplus ← spatial_partition(plots_tplus, grid_size = 10 km)  // 2. Compute region representatives FOR each region r DO   mean_composition[r] ← average species vector across plots in r   centroid[r]         ← geographic center of r END FOR  // 3. Match regions (small LAP: ~100 regions) region_cost       ← compute_cost(mean_composition, centroids, α = 0.7, β = 0.3) region_assignment ← lap_solve(region_cost)  // 4. Within matched regions, solve plot-level LAP full_assignment ← [] FOR r = 1 TO n_regions DO   r_matched ← region_assignment[r]   plots_A   ← plots in regions_t[r]   plots_B   ← plots in regions_tplus[r_matched]    // Local LAP (smaller problem, e.g. 50 × 50)   cost_local       ← compute_plot_cost(plots_A, plots_B, α = 0.7, β = 0.3)   local_assignment ← lap_solve(cost_local)    full_assignment ← append(full_assignment, local_assignment) END FOR  RETURN full_assignment"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"physics-particle-tracking","dir":"Articles","previous_headings":"Application to Scientific Domains","what":"Physics: Particle Tracking","title":"Optimal Matching in Science: From Theory to Practice","text":"Problem: track nn particles frame tt t+Δtt + \\Delta t experimental video. Feature distance: differences intensity, size, shape. Spatial distance: displacement relative predicted motion: dspatial(,j)=∥𝐱+𝐯iΔt−𝐱j∥2, d_{\\text{spatial}}(, j) = \\bigl\\| \\mathbf{x}_i + \\mathbf{v}_i \\Delta t - \\mathbf{x}_j \\bigr\\|_2, 𝐯\\mathbf{v}_i estimated velocity previous frames. also impose maximum displacement dmaxd_{\\max} beyond matches physically implausible. Exact solution (moderate nn): dense tracking (n>5000n > 5000), can first cluster particles: yields efficient robust trajectories even dense particle fields.","code":"// Pseudocode for particle tracking with velocity prediction  // Initialize cost matrix as forbidden everywhere cost ← matrix(Inf, n_particles_t, n_particles_tplus)  FOR i = 1 TO n_particles_t DO   // Predict position using previous velocity   x_predicted ← x_t[i] + v_x_t[i] · Δt   y_predicted ← y_t[i] + v_y_t[i] · Δt    FOR j = 1 TO n_particles_tplus DO     // Distance from predicted position     dx ← x_predicted - x_tplus[j]     dy ← y_predicted - y_tplus[j]     spatial_distance ← sqrt(dx^2 + dy^2)      // Only consider physically plausible matches     IF spatial_distance <= max_displacement THEN       // Feature similarity (intensity, size, etc.)       feature_distance ← |intensity_t[i] - intensity_tplus[j]|        // Combined cost       cost[i, j] ← α · feature_distance + β · spatial_distance     END IF   END FOR END FOR  // Solve assignment (Inf entries are forbidden) particle_tracks ← lap_solve(cost)  // Update velocities from assignments FOR i = 1 TO n_particles_t DO   j ← particle_tracks[i]   velocity_new[i] ← (position_tplus[j] - position_t[i]) / Δt END FOR // Two-stage: clustering then local matching  // Stage 1: spatial clustering clusters_t     ← spatial_cluster(particles_t,     radius = 2 · pixel_size) clusters_tplus ← spatial_cluster(particles_tplus, radius = 2 · pixel_size)  // Compute cluster representatives FOR each cluster c DO   centroid[c]       ← mean position of particles in c   mean_intensity[c] ← mean intensity   mean_velocity[c]  ← mean velocity (if available) END FOR  // Match clusters cluster_cost   ← compute_cluster_similarity(clusters_t, clusters_tplus) cluster_tracks ← lap_solve(cluster_cost)  // Stage 2: within matched clusters, track individual particles full_tracks ← [] FOR c = 1 TO n_clusters DO   c_matched   ← cluster_tracks[c]   particles_A ← particles in clusters_t[c]   particles_B ← particles in clusters_tplus[c_matched]    cost_local ← compute_particle_distance(     particles_A, particles_B,     max_displacement = 5,     α = 0.3,     β = 0.7   )    local_tracks ← lap_solve(cost_local)   full_tracks  ← append(full_tracks, local_tracks) END FOR  RETURN full_tracks"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"chemistry-molecular-conformation-alignment","dir":"Articles","previous_headings":"Application to Scientific Domains","what":"Chemistry: Molecular Conformation Alignment","title":"Optimal Matching in Science: From Theory to Practice","text":"Problem: align two conformations molecule (e.g. protein) nn atoms compute RMSD analyze structural change. Feature distance: strict element matching delement(,j)={0,elementi=elementj,∞,otherwise. d_{\\text{element}}(, j) = \\begin{cases} 0, & \\text{} \\text{element}_i = \\text{element}_j, \\\\ \\infty, & \\text{otherwise.} \\end{cases} Spatial distance: 3D Euclidean distance atomic coordinates. Exact LAP small molecules: large biomolecules, use hierarchical strategy, time secondary structure elements (helices, sheets, loops, etc.), aligning segments first atoms within matched segments.","code":"// Pseudocode for molecular conformation alignment  n_atoms ← number of atoms in molecule cost    ← matrix(0, n_atoms, n_atoms)  FOR i = 1 TO n_atoms DO   FOR j = 1 TO n_atoms DO      // Enforce strict element type matching     IF element_type_A[i] ≠ element_type_B[j] THEN       cost[i, j] ← Inf     ELSE       dx ← x_A[i] - x_B[j]       dy ← y_A[i] - y_B[j]       dz ← z_A[i] - z_B[j]       cost[i, j] ← sqrt(dx^2 + dy^2 + dz^2)     END IF    END FOR END FOR  // Solve alignment alignment ← lap_solve(cost)  // Compute RMSD sum_sq_dist ← 0 FOR i = 1 TO n_atoms DO   j            ← alignment[i]   sum_sq_dist ← sum_sq_dist + cost[i, j]^2 END FOR  rmsd ← sqrt(sum_sq_dist / n_atoms)"},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"customizing-morph-duration","dir":"Articles","previous_headings":"Implementation Notes","what":"Customizing Morph Duration","title":"Optimal Matching in Science: From Theory to Practice","text":"morphing examples use default settings, can customize number frames speed: Total animation duration n_frames * frame_delay seconds.","code":"# From inst/scripts/generate_examples.R generate_morph <- function(assignment, pixels_A, pixels_B,                            n_frames    = 30,   # number of frames                            frame_delay = 0.1)  # delay between frames (seconds) {   frames <- lapply(seq(0, 1, length.out = n_frames), function(t) {     interpolate_frame(t, assignment, pixels_A, pixels_B)   })    save_gif(frames, delay = frame_delay) }"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"using-the-example-code","dir":"Articles","previous_headings":"Implementation Notes","what":"Using the Example Code","title":"Optimal Matching in Science: From Theory to Practice","text":"morphing implementation provided inst/scripts/generate_examples.R:","code":"# View the source example_script <- system.file(\"scripts\", \"generate_examples.R\", package = \"couplr\") file.show(example_script)  # Or source to use its helpers source(example_script)  # Apply to your own data my_cost       <- build_cost_matrix(my_data_A, my_data_B) my_assignment <- lap_solve(my_cost)"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"regenerating-examples","dir":"Articles","previous_headings":"Implementation Notes","what":"Regenerating Examples","title":"Optimal Matching in Science: From Theory to Practice","text":"regenerate demo GIFs PNGs: write assets inst/extdata.","code":"source(\"inst/scripts/generate_examples.R\")"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"mathematical-foundation-optimal-transport","dir":"Articles","previous_headings":"","what":"Mathematical Foundation: Optimal Transport","title":"Optimal Matching in Science: From Theory to Practice","text":"matching problems discussed discrete instances optimal transport.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"monge-problem","dir":"Articles","previous_headings":"Mathematical Foundation: Optimal Transport","what":"Monge Problem","title":"Optimal Matching in Science: From Theory to Practice","text":"original Monge formulation (1781) seeks transport map T:→BT: \\B minimizing ∫Ac(𝐱,T(𝐱))dμ(𝐱). \\int_A c(\\mathbf{x}, T(\\mathbf{x})) \\,\\mathrm{d}\\mu(\\mathbf{x}).","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"kantorovich-relaxation","dir":"Articles","previous_headings":"Mathematical Foundation: Optimal Transport","what":"Kantorovich Relaxation","title":"Optimal Matching in Science: From Theory to Practice","text":"Kantorovich (1942) relaxed transport plan γ\\gamma ×BA \\times B: minγ∫×Bc(𝐱,𝐲)dγ(𝐱,𝐲) \\min_{\\gamma} \\int_{\\times B} c(\\mathbf{x}, \\mathbf{y}) \\,\\mathrm{d}\\gamma(\\mathbf{x}, \\mathbf{y}) subject marginal constraints γ\\gamma.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"discrete-linear-assignment","dir":"Articles","previous_headings":"Mathematical Foundation: Optimal Transport","what":"Discrete Linear Assignment","title":"Optimal Matching in Science: From Theory to Practice","text":"discrete uniform distributions nn points AA BB obtain exactly linear assignment problem: minπ∈Sn∑=1nci,π(), \\min_{\\pi \\S_n} \\sum_{=1}^n c_{,\\pi()}, couplr solves efficiently.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"wasserstein-distance","dir":"Articles","previous_headings":"Mathematical Foundation: Optimal Transport","what":"Wasserstein Distance","title":"Optimal Matching in Science: From Theory to Practice","text":"cij=d(𝐱,𝐱j)c_{ij} = d(\\mathbf{x}_i, \\mathbf{x}_j) (often Euclidean distance), optimal cost defines 11‑Wasserstein distance: W1(μ,ν)=minπ∈Sn∑=1nci,π(). W_1(\\mu, \\nu) = \\min_{\\pi \\S_n} \\sum_{=1}^n c_{,\\pi()}. appears Earth mover’s distance image retrieval Distributional similarity statistics Generative modeling (e.g. Wasserstein GANs)","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"optimal-transport-theory","dir":"Articles","previous_headings":"Further Reading","what":"Optimal Transport Theory","title":"Optimal Matching in Science: From Theory to Practice","text":"Peyré, G., & Cuturi, M. (2019). Computational Optimal Transport. Foundations Trends Machine Learning. Villani, C. (2008). Optimal Transport: Old New. Springer.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"scientific-applications","dir":"Articles","previous_headings":"Further Reading","what":"Scientific Applications","title":"Optimal Matching in Science: From Theory to Practice","text":"Ecology Anderson, M. J. et al. (2011). Navigating multiple meanings beta diversity. Ecology Letters. Legendre, P., & Legendre, L. (2012). Numerical Ecology. Elsevier. Physics Adrian, R. J., & Westerweel, J. (2011). Particle Image Velocimetry. Cambridge University Press. Crocker, J. C., & Grier, D. G. (1996). Methods digital video microscopy. Journal Colloid Interface Science. Chemistry Kabsch, W. (1976). solution best rotation relate two sets vectors. Acta Crystallographica. Coutsias, E. . et al. (2004). Using quaternions calculate RMSD. Journal Computational Chemistry.","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"assignment-algorithms","dir":"Articles","previous_headings":"Further Reading","what":"Assignment Algorithms","title":"Optimal Matching in Science: From Theory to Practice","text":"Burkard, R., Dell’Amico, M., & Martello, S. (2009). Assignment Problems. SIAM. implementation details package see vignette(\"algorithms\").","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"connection-to-couplr-workflows","dir":"Articles","previous_headings":"","what":"Connection to couplr Workflows","title":"Optimal Matching in Science: From Theory to Practice","text":"approximation strategies vignette become relevant working couplr’s practical matching functions.","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"practical-recommendations","dir":"Articles","previous_headings":"Connection to couplr Workflows","what":"Practical Recommendations","title":"Optimal Matching in Science: From Theory to Practice","text":"n < 3,000: Use match_couples() exact algorithms: 3,000 < n < 10,000: Use blocking create smaller subproblems: n > 10,000: Use greedy matching: n > 50,000: Combine strategies—blocking + greedy within blocks, implement custom approximations using techniques vignette.","code":"result <- match_couples(left, right, vars = c(\"x\", \"y\", \"z\"), auto_scale = TRUE) blocks <- matchmaker(left, right, block_type = \"cluster\", n_blocks = 10) result <- match_couples(blocks$left, blocks$right, vars = vars, block_id = \"block_id\") result <- greedy_couples(left, right, vars = vars, strategy = \"sorted\")"},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"limitations-of-approximation-strategies","dir":"Articles","previous_headings":"Connection to couplr Workflows","what":"Limitations of Approximation Strategies","title":"Optimal Matching in Science: From Theory to Practice","text":"approximation trades accuracy speed. Know failure modes:","code":""},{"path":"https://gcol33.github.io/couplr/articles/pixel-morphing.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Optimal Matching in Science: From Theory to Practice","text":"vignette explored optimal matching lens pixel morphing scientific applications. Key Ideas: Assignment = matching: LAP finds optimal correspondences two sets Scalability matters: O(n3)O(n^3) becomes prohibitive n>3,000n > 3{,}000 Three approximations: Feature quantization, hierarchical decomposition, resolution reduction math, different domains: Pixels, particles, plots, atoms use algorithms ’s Next? Function reference: ?lap_solve, ?match_couples, ?greedy_couples algorithms morph images smoothly also track particles physics, align molecules chemistry, match vegetation plots ecology. Together, methods couplr let move exact optimal matchings principled approximations, depending problem size accuracy requirements.","code":""},{"path":"https://gcol33.github.io/couplr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"https://gcol33.github.io/couplr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2025). couplr: Optimal Pairing Matching via Linear Assignment. R package version 1.0.0, https://gcol33.github.io/couplr/.","code":"@Manual{,   title = {couplr: Optimal Pairing and Matching via Linear Assignment},   author = {First Last},   year = {2025},   note = {R package version 1.0.0},   url = {https://gcol33.github.io/couplr/}, }"},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":null,"dir":"","previous_headings":"","what":"Changelog","title":"Changelog","text":"notable changes project documented file. format based Keep Changelog, project adheres Semantic Versioning.","code":""},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"matching-enhancements---step-1-automatic-scaling-and-preprocessing","dir":"","previous_headings":"1.0.0 - 2025-11-19 > Added","what":"Matching Enhancements - Step 1: Automatic Scaling and Preprocessing","title":"Changelog","text":"Automatic preprocessing auto_scale parameter match_couples() greedy_couples() Detects constant columns (SD = 0) excludes warning Detects nearly-constant columns (SD < threshold) warns Detects -NA columns excludes warning Detects high missingness (>50%) warns Detects extreme skewness (|skewness| > 2) provides info messages Returns detailed diagnostics including per-variable statistics Analyzes variable distributions detects outliers using IQR method Checks different scales across variables Recommends “robust”, “standardize”, “range”, “none” Uses median MAD (median absolute deviation) Resistant outliers skewed distributions Formula: (x - median) / MAD Binary variables → 0/1 encoding Ordered factors → numeric codes Error unordered categorical (requires Gower distance) Runs variable health checks Automatically excludes problematic variables Suggests applies scaling method Returns preprocessing result metadata Exported direct user access print.variable_health() - Pretty printing health diagnostics print.preprocessing_result() - Summary preprocessing results 10 comprehensive tests preprocessing functionality Example file examples/auto_scale_demo.R 5 demonstrations","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"matching-enhancements---step-2-balance-diagnostics","dir":"","previous_headings":"1.0.0 - 2025-11-19 > Added","what":"Matching Enhancements - Step 2: Balance Diagnostics","title":"Changelog","text":"Computes standardized differences (mean diff / pooled SD) Calculates variance ratios (SD_left / SD_right) Performs Kolmogorov-Smirnov tests distribution comparison Overall balance metrics (mean, max, % large imbalance) Per-block statistics quality ratings blocking used Counts matched unmatched units Works match_couples() greedy_couples() results Clean tabular output suitable reports publications Configurable decimal precision Internal function robust edge case handling Supports pooled group-specific SD Handles NA values, empty vectors, constant data Per-variable balance statistics Mean, SD, mean difference groups Standardized difference, variance ratio, KS statistic Matching summary (method, matched/unmatched counts) Variable-level balance table Overall balance assessment quality ratings Block-level statistics (blocking used) Interpretation guide standardized differences Excellent: |Std Diff| < 0.10 Good: |Std Diff| 0.10-0.25 Fair: |Std Diff| 0.25-0.50 Poor: |Std Diff| > 0.50 Unknown: edge cases (empty blocks, NA) 11 comprehensive tests balance diagnostics Basic balance diagnostics Comparing optimal vs greedy matching Balance blocking Detecting poor balance Extracting specific metrics Using balance tables publication","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"matching-enhancements---step-3-joined-matched-dataset-output","dir":"","previous_headings":"1.0.0 - 2025-11-19 > Added","what":"Matching Enhancements - Step 3: Joined Matched Dataset Output","title":"Changelog","text":"Automatically joins matched pairs original left right data Eliminates manual data wrangling matching Selectable variables via left_vars right_vars parameters Customizable suffixes disambiguating overlapping column names (default: _left, _right) Optional metadata columns: pair_id, distance, block_id Custom ID column support via left_id right_id parameters Clean column ordering: pair_id → left_id → right_id → distance → block_id → variables Works matching methods (optimal greedy) Preserves block information blocking used S3 method following broom package conventions Thin wrapper around join_matched() sensible defaults Integration tidymodels workflows Supports join_matched() parameters via ... Checks matching_result object type Validates data frame inputs Verifies ID column existence Confirms variable availability Validates suffix format (must length 2) Handles empty matching results informative warning Basic joining functionality Custom suffixes Variable selection Blocking integration Include/exclude options (distance, pair_id, block_id) Custom ID columns Input validation Empty matches Greedy matching compatibility augment() method Column ordering Basic treatment effect analysis Custom variable selection Matched analysis blocking Minimal output compact datasets Using augment() (broom-style) Greedy matching integration Custom ID columns Complete workflow balance diagnostics","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"matching-enhancements---step-4-precomputed-and-reusable-distances","dir":"","previous_headings":"1.0.0 - 2025-11-19 > Added","what":"Matching Enhancements - Step 4: Precomputed and Reusable Distances","title":"Changelog","text":"Precomputes distance matrix left right datasets Stores complete metadata (vars, distance metric, scaling, timestamps) Preserves original datasets seamless integration join_matched() Enables reuse across multiple matching operations Performance: ~60% faster trying multiple matching parameters Contains: cost_matrix, left/right IDs, block information, metadata, original datasets Works match_couples() greedy_couples() Can passed first parameter instead datasets Example: dist_obj <- compute_distances(left, right, vars); result <- match_couples(dist_obj) Apply new max_distance calipers without recomputing distances Creates new distance_object updated cost matrix Follows R’s copy--modify semantics Modified match_couples() signature: match_couples(left, right = NULL, vars = NULL, ...) Modified greedy_couples() signature: greedy_couples(left, right = NULL, vars = NULL, ...) Automatically detects distance_object routes specialized handlers 100% backward compatible existing code is_distance_object() - Type checking print.distance_object() - Informative summary distance statistics summary.distance_object() - Detailed statistics quantiles sparsity analysis match_couples_from_distance() - Handles optimal matching cached distances greedy_couples_from_distance() - Handles greedy matching cached distances","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"matching-enhancements---step-5-parallel-processing","dir":"","previous_headings":"1.0.0 - 2025-11-19 > Added","what":"Matching Enhancements - Step 5: Parallel Processing","title":"Changelog","text":"Distributes blocked matching across multiple cores using future package Automatic worker setup parallel = TRUE (uses availableCores() - 1) Custom plan support: pass plan name string (e.g., parallel = \"multisession\") Works optimal greedy matching strategies Graceful fallback sequential processing future packages unavailable setup_parallel() - Configure parallel backend auto-detection restore_parallel() - Restore original future plan execution can_parallelize() - Check future packages available parallel_lapply() - Unified parallel/sequential lapply interface match_blocks_parallel() - Parallel optimal matching across blocks greedy_blocks_parallel() - Parallel greedy matching across blocks Scales number blocks block size Best 10+ blocks 50+ units per block Speedup depends available cores problem complexity Minimal overhead small problems (automatic detection) Windows: multisession plan (separate R processes) Unix/Mac: multicore multisession plans Cluster: Distributed computing via future’s cluster plan Respects user-configured future plans Works seamlessly blocking (via block_id parameter) Compatible distance caching Step 4 Supports existing matching parameters Automatic plan restoration prevents side effects Basic parallel vs sequential comparison Custom parallel plan configuration Greedy matching parallelization parallel processing helps Combining parallel + distance caching Platform-specific plans Performance tips best practices","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"matching-enhancements---step-6-fun-error-messages-and-cost-checking","dir":"","previous_headings":"1.0.0 - 2025-11-19 > Added","what":"Matching Enhancements - Step 6: Fun Error Messages and Cost Checking","title":"Changelog","text":"Enabled default match_couples() greedy_couples() Detects common problems matching begins Can disabled check_costs = FALSE production code Light, memorable messages inspired testthat Themed around coupling, matching, pairing Less intimidating new users, memorable Clear actionable suggestions fixing problems 💔 errors (broken heart) 💌 warnings (love letter) 💬 info messages (speech balloon) 💖 success (sparkling heart) ✨ suggestions (sparkles) 🔍 search/investigation Automatically disabled non-interactive sessions couplr_stop() - Fun error messages emoji couplr_warn() - Fun warning messages couplr_inform() - Info messages couplr_success() - Success messages couplr_emoji() - Get themed emoji Specific error helpers: err_missing_data(), err_missing_vars(), err_no_valid_pairs(), etc. Specific warning helpers: warn_constant_var(), warn_many_zeros(), warn_extreme_costs(), etc. Detects many zero distances (>10%) - suggests checking duplicates Detects extreme cost ratios (99th percentile > 10x 95th) - suggests scaling Detects many forbidden pairs (>50%) - suggests relaxing constraints Detects constant distances - suggests checking variable informativeness Returns detailed diagnostic information Full analysis distance matrix quality Variable-specific problem detection Per-variable issue tracking (constant, extreme scale differences) Actionable suggestions improvements Quality rating: “good”, “fair”, “poor” Integrated match_couples_single(), match_couples_from_distance() Integrated greedy matching functions Warnings issued LAP solving catch problems early Backward compatible - tests pass check_costs enabled Basic friendly error messages Duplicate detection warnings Skewed distribution detection Overly strict constraints Constant variable detection valid pairs scenarios Distance matrix diagnostics Disabling cost checks Emoji control Balance quality messages","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"changed","dir":"","previous_headings":"1.0.0 - 2025-11-19","what":"Changed","title":"Changelog","text":"Updated DESCRIPTION include new matching features preprocess_matching_vars() balance_diagnostics() balance_table() join_matched() augment.matching_result() augment() generic compute_distances() is_distance_object() update_constraints() S3 print summary methods new classes match_couples(left, right = NULL, vars = NULL, ..., parallel = FALSE, check_costs = TRUE) - left can distance_object, parallel blocked matching, automatic cost checking greedy_couples(left, right = NULL, vars = NULL, ..., parallel = FALSE, check_costs = TRUE) - left can distance_object, parallel blocked matching, automatic cost checking Added future future.apply Suggests parallel processing support Updated error messages throughout package use fun, couple-themed helpers Added diagnose_distance_matrix() NAMESPACE exports","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"fixed","dir":"","previous_headings":"1.0.0 - 2025-11-19","what":"Fixed","title":"Changelog","text":"Greedy matching functions now properly exported via Rcpp interface Block statistics preserved correctly greedy_couples() return_diagnostics = FALSE Variable health checks now include required fields edge cases Variance ratio calculation handles NA values Block quality determination handles NA/NaN empty blocks Overall metrics handle -NA standardized differences","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"documentation","dir":"","previous_headings":"1.0.0 - 2025-11-19","what":"Documentation","title":"Changelog","text":"Added IMPLEMENTATION_STEP1.md documenting preprocessing implementation Added IMPLEMENTATION_STEP2.md documenting balance diagnostics implementation Updated Roxygen documentation new functions Created comprehensive examples demonstrating new features functions complete parameter descriptions return value documentation","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"tests","dir":"","previous_headings":"1.0.0 - 2025-11-19","what":"Tests","title":"Changelog","text":"Total: 1382 tests passing (1365) Added 10 tests preprocessing (Step 1) Added 11 tests balance diagnostics (Step 2) Added 13 tests joined dataset output (Step 3) existing tests continue pass warnings errors Variable health detection (constant, -NA, high missingness, skewness) Scaling suggestion Preprocessing integration Standardized difference calculation Balance diagnostics simple blocked matching Balance table formatting Joined dataset creation Variable selection suffix handling Custom ID columns Broom-style augment method Print methods Input validation Edge case handling","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"backward-compatibility","dir":"","previous_headings":"1.0.0 - 2025-11-19","what":"Backward Compatibility","title":"Changelog","text":"100% backward compatible new parameters default FALSE previous behavior breaking changes existing APIs existing code continues work unchanged Return structures extended, replaced","code":""},{"path":"https://gcol33.github.io/couplr/CHANGELOG.html","id":"id_010---previous-release","dir":"","previous_headings":"","what":"0.1.0 - Previous Release","title":"Changelog","text":"Initial release core LAP solving functionality, basic matching, pixel morphing.","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"project-overview","dir":"","previous_headings":"","what":"Project Overview","title":"CLAUDE.md","text":"couplr (formerly lapr) R package solving Linear Assignment Problems (LAP) production-ready matching workflows. package combines: 12 LAP algorithms - Hungarian, Jonker-Volgenant, Auction (3 variants), Gabow-Tarjan, Greedy matching - Fast approximate algorithms large-scale problems Automatic preprocessing - Smart scaling, variable health checks, categorical encoding Balance diagnostics - Standardized differences, variance ratios, KS tests Distance caching - Reusable precomputed distances faster experimentation Parallel processing - Distributed block matching via future framework Joined datasets - Analysis-ready merged output broom-style interface Fun error messages - Couple-themed warnings emoji support Current version: 1.0.0 (released 2025-11-19) Tests: 1382 passing License: MIT","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"system-configuration","dir":"","previous_headings":"Development Commands","what":"System Configuration","title":"CLAUDE.md","text":"R Installation Path (Windows): running R scripts command line Windows, use full path:","code":"C:\\Program Files\\R\\R-4.5.1\\bin\\Rscript.exe C:\\Program Files\\R\\R-4.5.1\\bin\\R.exe # Run R script \"C:\\Program Files\\R\\R-4.5.1\\bin\\Rscript.exe\" benchmark_readme.R  # Run R command \"C:\\Program Files\\R\\R-4.5.1\\bin\\Rscript.exe\" -e \"install.packages('bench', repos='https://cloud.r-project.org')\""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"core-package-development","dir":"","previous_headings":"Development Commands","what":"Core Package Development","title":"CLAUDE.md","text":"","code":"# Install dependencies install.packages(c(\"Rcpp\", \"RcppEigen\", \"tibble\", \"dplyr\", \"testthat\", \"devtools\"))  # Load package (recompiles C++ if needed) devtools::load_all()  # or Ctrl+Shift+L in RStudio  # Run all tests (1382 tests) devtools::test()  # or Ctrl+Shift+T  # Run specific test file testthat::test_file(\"tests/testthat/test-matching.R\")  # Run matching tests only devtools::test(filter = \"matching\")  # Build documentation (after editing roxygen comments) devtools::document()  # Full package check devtools::check()  # Build tarball devtools::build()  # Install from source (alternative to devtools) # From command line: R CMD INSTALL --build . # Or in R: install.packages(\".\", repos = NULL, type = \"source\")"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"c-development-workflow","dir":"","previous_headings":"Development Commands","what":"C++ Development Workflow","title":"CLAUDE.md","text":"modifying C++ code adding [[Rcpp::export]] functions: Critical: C++17 required. Windows users need Rtools g++ supporting C++17. Troubleshooting compilation issues: Note: src/ directory may contain committed object files (*.o, *.dll) can become stale. Clean building behavior unexpected.","code":"# Regenerate Rcpp exports (REQUIRED after C++ changes) Rcpp::compileAttributes()  # Update documentation devtools::document()  # Reload package devtools::load_all()  # Run tests devtools::test() # Windows: Clean stale object files if encountering binary mismatches Remove-Item src\\*.o, src\\*.dll -Force  # Then rebuild R CMD INSTALL --clean ."},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"git-workflow","dir":"","previous_headings":"Development Commands","what":"Git Workflow","title":"CLAUDE.md","text":"","code":"# Check status git status  # Add changes git add .  # Commit (use descriptive messages) git commit -m \"Description of changes\"  # Push to GitHub git push origin main  # Create release tag git tag -a v1.0.0 -m \"Release message\" git push origin v1.0.0"},{"path":[]},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"three-layer-api-design","dir":"","previous_headings":"Code Architecture","what":"Three-Layer API Design","title":"CLAUDE.md","text":"Layer 1 - Low-level LAP solvers (R/assignment.R): - assignment() - Core solver wrapper returning list(match, total_cost, status, method_used) - Direct mapping C++ implementations - Method auto-selection via method = \"auto\" Layer 2 - Tidy LAP interface (R/lap_solve.R): - lap_solve() - Returns tibble tidy output - Supports matrix, data frame, grouped inputs - Batch solving via lap_solve_batch() - K-best solutions via lap_solve_kbest() Layer 3 - Matching workflows (NEW v1.0.0): - match_couples() - Optimal one--one matching preprocessing (R/matching_core.R) - greedy_couples() - Fast greedy matching 3 strategies (R/matching_core.R) - matchmaker() - Blocking/stratification support (R/matching_blocks.R) - balance_diagnostics() - Comprehensive balance assessment (R/matching_diagnostics.R) - preprocess_matching_vars() - Automatic variable health checks (R/matching_preprocessing.R) - compute_distances() - Precompute cache distance matrices (R/matching_distance_cache.R) - join_matched() - Create analysis-ready merged datasets (R/matching_join.R)","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"matching-layer-architecture-v100","dir":"","previous_headings":"Code Architecture","what":"Matching Layer Architecture (v1.0.0)","title":"CLAUDE.md","text":"matching layer provides production-ready workflows observational studies, treatment effect estimation, sample matching. Core Workflow: Complete R File Structure (20 files): Key file responsibilities: - matching_core.R - Main matching entry points - matching_preprocessing.R - Variable health, scaling suggestions - matching_diagnostics.R - Balance metrics, quality ratings - matching_join.R - Analysis-ready merged datasets - matching_distance_cache.R - Distance object management - matching_parallel.R - Parallel block matching - matching_messages.R - Couple-themed error messages Key Features: Detects constant variables (SD = 0) → excludes warning Detects high missingness (>50%) → warns Detects extreme skewness (|skew| > 2) → info Smart scaling: “robust” (median/MAD), “standardize” (mean/SD), “range” (min-max) Categorical encoding: binary (0/1), ordered factors (numeric) sorted - Sort pairs cost, assign greedily row_best - row, pick best available column pq - Priority queue large problems 10-100x faster optimal large datasets Standardized differences: (mean_left - mean_right) / pooled_sd Variance ratios: SD_left / SD_right KS tests distribution comparison Per-block statistics quality ratings Quality thresholds: <0.1 excellent, 0.1-0.25 good, 0.25-0.5 acceptable, >0.5 poor Exact blocking: block_type = \"group\" + block_by = \"site\" K-means clustering: block_type = \"cluster\" + n_clusters = 5 Preserves block IDs matching pipeline","code":"# 1. Optional: Create blocks/strata blocks <- matchmaker(left, right, block_type = \"group\", block_by = \"site\")  # 2. Match with automatic preprocessing result <- match_couples(   left, right,   vars = c(\"age\", \"income\", \"education\"),   auto_scale = TRUE,           # Smart preprocessing   scale = \"robust\",             # MAD-based scaling   max_distance = 0.5,           # Caliper   return_diagnostics = TRUE )  # 3. Assess balance quality balance <- balance_diagnostics(result, left, right, vars = c(\"age\", \"income\")) print(balance)  # Standardized differences, variance ratios, KS tests balance_table(balance)  # Publication-ready table R/ ├── couplr-package.R              # Package documentation and imports ├── data.R                        # Dataset documentation ├── zzz.R                         # Package startup/attach messages ├── RcppExports.R                 # Auto-generated Rcpp bindings ├── utils.R                       # General utility functions │ ├── LAP Solvers (Layer 1 & 2): │   ├── lap_solve.R               # Tidy LAP interface (lap_solve) │   ├── lap_solve_batch.R         # Batch solving for multiple problems │   └── lap_solve_kbest.R         # K-best solutions (Murty, Lawler) │ ├── Matching Core (Layer 3): │   ├── matching_core.R           # match_couples(), greedy_couples() (625 lines) │   ├── matching_distance.R       # Distance computation, 3 scaling methods │   ├── matching_distance_cache.R # compute_distances(), update_constraints() │   ├── matching_constraints.R    # Calipers, weights, max_distance │   ├── matching_blocks.R         # matchmaker(), blocking/stratification │   ├── matching_parallel.R       # Parallel processing via future │   ├── matching_utils.R          # Shared matching utilities │   └── matching_messages.R       # Fun error/warning messages (270 lines) │ ├── Matching Analysis: │   ├── matching_preprocessing.R  # Auto-scaling, health checks (510 lines) │   ├── matching_diagnostics.R    # Balance diagnostics (461 lines) │   └── matching_join.R           # join_matched(), augment() (220 lines) │ └── Pixel Morphing:     ├── morph_pixel.R             # Pixel-level LAP morphing (modes)     ├── morph_tiling.R            # Recursive tiling for large images     └── morph_utils.R             # Morphing utilities"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"c-code-organization","dir":"","previous_headings":"Code Architecture","what":"C++ Code Organization","title":"CLAUDE.md","text":"Complete File Structure (22 .cpp files, 3 .h files): Key files: - rcpp_interface.cpp - [[Rcpp::export]] declarations - lap_internal.h - Forward declarations solver implementations - RcppExports.cpp - Auto-generated, EDIT manually Export Pattern (CRITICAL): Subdirectory files (e.g., src/solvers/greedy_matching.cpp) use [[Rcpp::export]] directly. Instead: Implementation subdirectory _impl suffix: Forward declaration src/rcpp_interface.cpp: Exported wrapper src/rcpp_interface.cpp: : Rcpp scans main source directory, subdirectories. [[Rcpp::export]] tags MUST src/*.cpp files root level.","code":"src/ ├── core/                      # Shared utilities │   ├── lap_internal.h            # Function declarations for all solvers │   ├── lap_utils.cpp             # Common helpers (cost computation, validation) │   └── lap_utils.h               # Utility function headers ├── interface/                 # Cost matrix preparation │   └── prepare_cost_matrix.cpp  # Rcpp interface for cost matrix creation ├── solvers/                   # LAP algorithm implementations (15 files) │   ├── greedy_matching.cpp       # Greedy strategies (sorted, row_best, pq) │   ├── solve_auction.cpp         # Auction algorithm variants │   ├── solve_bruteforce.cpp      # Exhaustive search for tiny problems │   ├── solve_cost_scaling.cpp    # Gabow's cost-scaling algorithm │   ├── solve_csflow.cpp          # Cost-scaling flow algorithm │   ├── solve_cycle_cancel.cpp    # Cycle canceling with Karp's trick │   ├── solve_hk01.cpp            # Hopcroft-Karp for binary costs │   ├── solve_hungarian.cpp       # Classic Hungarian algorithm │   ├── solve_jv.cpp              # Jonker-Volgenant (general purpose) │   ├── solve_kbest_lawler.cpp    # Lawler's k-best algorithm │   ├── solve_line_metric.cpp     # Specialized for 1D matching │   ├── solve_murty.cpp           # Murty's algorithm for k-best solutions │   ├── solve_ssap_bucket.cpp     # Dial's algorithm for integer costs │   ├── solve_ssp.cpp             # Shortest augmenting path │   └── solve_gabow_tarjan.cpp    # (note: also in gabow_tarjan/) ├── gabow_tarjan/              # Gabow-Tarjan specific code │   ├── solve_gabow_tarjan.cpp    # Main Gabow-Tarjan implementation │   ├── utils_gabow_tarjan.cpp    # Helper functions │   └── utils_gabow_tarjan.h      # Header for Gabow-Tarjan utilities ├── morph/                     # Pixel morphing for visualization │   ├── morph_pixel_level.cpp     # Pixel-level LAP morphing │   └── region_means.cpp          # Region-based color averaging ├── rcpp_interface.cpp         # Central export point (ALL [[Rcpp::export]] here) └── RcppExports.cpp            # Auto-generated by Rcpp::compileAttributes() // src/solvers/greedy_matching.cpp List greedy_matching_impl(NumericMatrix cost_matrix, bool maximize, std::string strategy) {     // Implementation } extern Rcpp::List greedy_matching_impl(Rcpp::NumericMatrix, bool, std::string); // [[Rcpp::export]] Rcpp::List greedy_matching(Rcpp::NumericMatrix cost_matrix,                            bool maximize = false,                            std::string strategy = \"row_best\") {     return greedy_matching_impl(cost_matrix, maximize, strategy); }"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"makefile-structure","dir":"","previous_headings":"Code Architecture","what":"Makefile Structure","title":"CLAUDE.md","text":"Makevars (Unix/Linux/Mac): Makevars.win (Windows): - structure uses $(shell ...) instead backticks - Collects .cpp files subdirectories using wildcards - Automatically links object files","code":"CXX_STD = CXX17 SOURCES = RcppExports.cpp rcpp_interface.cpp \\           $(wildcard interface/*.cpp) \\           $(wildcard core/*.cpp) \\           $(wildcard solvers/*.cpp) \\           $(wildcard gabow_tarjan/*.cpp) \\           $(wildcard morph/*.cpp) OBJECTS = $(SOURCES:.cpp=.o)"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"lap-solver-implementations","dir":"","previous_headings":"Code Architecture","what":"LAP Solver Implementations","title":"CLAUDE.md","text":"Available algorithms (see R/assignment.R): - jv - Jonker-Volgenant (general purpose, fast) - hungarian - Classic Hungarian - auction / auction_gs / auction_scaled - Auction variants - ssp / sap - Shortest augmenting path - csflow - Cost-scaling flow - cost_scaling - Gabow’s cost-scaling - cycle_cancel - Cycle canceling Karp - gabow_tarjan - Gabow-Tarjan complementary slackness - ssap_bucket - Dial’s algorithm integer costs - line_metric - Specialized 1D matching - hk01 - Hopcroft-Karp binary costs - bruteforce - Exhaustive tiny problems - auto - Automatic selection Greedy Algorithms (NEW): - greedy_sorted - Sort pairs, assign greedily - greedy_row_best - Row--row best match - greedy_pq - Priority queue based","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"testing-strategy","dir":"","previous_headings":"Code Architecture","what":"Testing Strategy","title":"CLAUDE.md","text":"CRITICAL: Test File Location Requirements devtools::test() requires specific directory structure: Common mistake: Placing test files package root tests/ directory instead tests/testthat/ ❌ WRONG: ✓ CORRECT: Test Organization (1382 total tests - passing): Running Tests: Test Coverage Highlights: - 12 LAP algorithms dedicated test files - Edge cases: empty matches, NA handling, constant variables - Backward compatibility: v0.1.0 tests still pass - Performance: regressions v0.1.0 - Integration: Cross-feature testing (preprocessing + matching + diagnostics)","code":"tests/ ├── testthat.R           # Test runner that calls testthat::test_check(\"couplr\") └── testthat/            # Directory containing all test files     ├── test-*.R         # All test files MUST be in this directory     └── ... couplr/ ├── test_auto_debug.R              # Will be ignored by devtools::test() ├── test_auto_selection.R          # Will be ignored by devtools::test() └── tests/     ├── testthat.R     ├── test_myfeature.R           # Will be ignored by devtools::test()     └── testthat/         └── test-matching.R        # ✓ Only this will run couplr/ └── tests/     ├── testthat.R                 # Test runner     └── testthat/         ├── test-matching.R        # ✓ All tests here         ├── test_auto_debug.R      # ✓ Found by devtools::test()         ├── test_auto_selection.R  # ✓ Found by devtools::test()         └── test-*.R               # ✓ All test files tests/testthat/ ├── LAP Solver Tests: │   ├── test-assignment-hungarian.R       # Hungarian algorithm tests │   ├── test-assignment-jv.R              # Jonker-Volgenant tests │   ├── test-assignment-auction.R         # Auction variants │   ├── test-assignment-*.R               # 14+ individual solver test files │   └── test-lap-solve.R                  # Tidy interface tests │ ├── Matching Workflow Tests (98 tests): │   └── test-matching.R                   # Comprehensive matching tests │       ├── Preprocessing: 10 tests │       ├── Balance diagnostics: 11 tests │       ├── Joined datasets: 13 tests │       ├── Distance caching: tests │       ├── Parallel processing: tests │       ├── Core matching: 9 tests │       ├── Greedy strategies: 4 tests │       └── Integration tests: remainder │ ├── Gabow-Tarjan Modular Tests: │   ├── test_gabow_tarjan_moduleA.R       # Component testing │   ├── test_gabow_tarjan_moduleB.R │   ├── ... │   └── test_gabow_tarjan_moduleH.R       # 8 module test files │ ├── Pixel Morphing Tests: │   └── test-pixel-morph.R                # Morphing algorithm tests │ └── Utility Tests:     ├── test-utils.R                      # General utilities     └── test-*.R                          # Other specialized tests # Run all tests devtools::test()  # or Ctrl+Shift+T in RStudio  # Run matching tests only devtools::test(filter = \"matching\")  # Run specific test file testthat::test_file(\"tests/testthat/test-matching.R\")  # Run single test testthat::test_that(\"balance_diagnostics works with blocking\", { ... })  # Run with parallel execution devtools::test(parallel = TRUE)"},{"path":[]},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"indexing","dir":"","previous_headings":"Important Conventions","what":"Indexing","title":"CLAUDE.md","text":"R code: 1-based (R standard) C++ code: 0-based internally, convert boundaries Unmatched: -1 (C++) / 0 (R, displayed NA output)","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"matrix-orientation","dir":"","previous_headings":"Important Conventions","what":"Matrix Orientation","title":"CLAUDE.md","text":"Rows = left/treatment units Cols = right/control units Auto-transpose rows > cols","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"cost-matrix-semantics","dir":"","previous_headings":"Important Conventions","what":"Cost Matrix Semantics","title":"CLAUDE.md","text":"NA Inf = forbidden assignment maximize = TRUE negates costs internally Always returns costs original scale","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"return-values","dir":"","previous_headings":"Important Conventions","what":"Return Values","title":"CLAUDE.md","text":"LAP Solvers: Matching Functions: Balance Diagnostics:","code":"list(   match = integer vector (1-based, length = nrow),   total_cost = numeric,   status = \"optimal\",   method_used = \"algorithm_name\" ) list(   pairs = tibble(left_id, right_id, distance, block_id),   info = list(     method = \"optimal\" or \"greedy\",     strategy = \"row_best\" (greedy only),     n_matched = integer,     total_distance = numeric,     n_blocks = integer (if blocking)   ),   # If return_diagnostics = TRUE:   left_unmatched = tibble(...),   right_unmatched = tibble(...),   cost_matrix = matrix,   distance_info = list(...) ) balance_diagnostics object with:   var_stats = tibble(variable, mean_left, mean_right, std_diff, ...),   overall = list(mean_abs_std_diff, max_abs_std_diff, pct_large_imbalance),   n_matched, n_unmatched_left, n_unmatched_right,   has_blocks, block_stats"},{"path":[]},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"adding-a-new-lap-solver","dir":"","previous_headings":"Adding New Functionality","what":"Adding a New LAP Solver","title":"CLAUDE.md","text":"Create src/solvers/solve_foo.cpp solve_foo_impl() Add forward declaration src/rcpp_interface.cpp Add [[Rcpp::export]] wrapper src/rcpp_interface.cpp Run Rcpp::compileAttributes() update R/RcppExports.R Add case switch assignment() (R/assignment.R) Create tests/testthat/test-assignment-foo.R Update documentation via devtools::document()","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"adding-matching-features","dir":"","previous_headings":"Adding New Functionality","what":"Adding Matching Features","title":"CLAUDE.md","text":"preprocessing: - Edit R/matching_preprocessing.R - Add tests tests/testthat/test-matching.R - Update print methods adding new diagnostics balance diagnostics: - Edit R/matching_diagnostics.R - Extend balance_diagnostics() add new functions - Update print methods new output new matching algorithms: - Add C++ implementation src/solvers/ - Export via src/rcpp_interface.cpp - Add R wrapper R/matching_core.R","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"common-pitfalls","dir":"","previous_headings":"","what":"Common Pitfalls","title":"CLAUDE.md","text":"Symptom: “find function” errors Fix: Always run adding/modifying [[Rcpp::export]] DON’T: Put [[Rcpp::export]] src/solvers/*.cpp : Forward declare wrap src/rcpp_interface.cpp Symptom: devtools::test() reports tests ignores test files DON’T: Put test files package root (e.g., test_foo.R couplr/) DON’T: Put test files tests/ directory directly : Put test files tests/testthat/ directory Fix: Move misplaced test files tests/testthat/ See: Testing Strategy section directory structure Always convert R/C++ boundary C++ match vectors use -1 unmatched, R uses 0/NA Always test nrow != ncol Check auto-transpose logic Test forbidden edges (calipers, blocking) Verify cost computation skips invalid pairs OLD: lapr (deprecated) NEW: couplr (current) Check tests, examples, vignettes Clean committing: git clean -fdX src/ (Unix/Mac) Remove-Item src\\*.o, src\\*.dll -Force (Windows) Note: object files may already repo - clean cause issues Consider adding src/*.o src/*.dll .gitignore already present","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"documentation-files","dir":"","previous_headings":"","what":"Documentation Files","title":"CLAUDE.md","text":"Package Documentation: - CLAUDE.md - file - comprehensive development guide - CHANGELOG.md - Detailed release notes (Keep Changelog format) - NEWS.md - User-facing changes (R package convention) - DESCRIPTION - Package metadata, dependencies, authors - LICENSE - MIT License Example Files (8 demos): Vignettes (3 comprehensive guides): Implementation Notes (historical): - IMPLEMENTATION_STEP1.md - Automatic preprocessing implementation details - IMPLEMENTATION_STEP2.md - Balance diagnostics implementation details - MATCHING_ENHANCEMENTS.md - Feature roadmap enhancement tracking - SETUP_REQUIRED.md - Initial setup documentation greedy matching","code":"examples/ ├── auto_scale_demo.R              # 5 preprocessing demonstrations ├── balance_diagnostics_demo.R     # 6 balance diagnostic examples ├── join_matched_demo.R            # 8 joined dataset examples ├── parallel_matching_demo.R       # 7 parallel processing examples ├── error_messages_demo.R          # 10 fun error message demonstrations └── (3 more demo files for distance caching, etc.) vignettes/ ├── getting-started.Rmd            # Entry-point tutorial (394 lines) ├── algorithms.Rmd                 # Mathematical foundations (667 lines) └── pixel-morphing.Rmd             # Advanced applications (884 lines)"},{"path":[]},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"pixel-morphing-semantics","dir":"","previous_headings":"Special Notes","what":"Pixel Morphing Semantics","title":"CLAUDE.md","text":"Complex multi-mode system (R/morph_pixel.R): Modes: - exact - Full pixel LAP (< 4096 pixels) - color_walk - Color quantization + spatial LAPs - recursive - Multi-scale 2×2 tiling CRITICAL rendering semantics: - Assignment uses images B - Renderer uses ’s colors (transport-) - B influences pixels go, colors - Result sharp (motion blur)","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"cost-computation-guarantee","dir":"","previous_headings":"Special Notes","what":"Cost Computation Guarantee","title":"CLAUDE.md","text":"solvers MUST use compute_total_cost() src/core/lap_utils.cpp: Never compute cost transformed/reduced/scaled matrices. cost field precise semantics: sum original_cost[, match[]] matched rows.","code":"double total_cost = compute_total_cost(original_cost_matrix, assignment_R);"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"backward-compatibility","dir":"","previous_headings":"Special Notes","what":"Backward Compatibility","title":"CLAUDE.md","text":"v1.0.0 100% backward compatible: - new parameters default previous behavior - auto_scale = FALSE default - breaking changes return structures - 1365 pre-existing tests still pass","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"existing-vignettes","dir":"","previous_headings":"Vignette Writing Style Guide","what":"Existing Vignettes","title":"CLAUDE.md","text":"package currently three vignettes demonstrate consistent, high-quality writing style: getting-started.Rmd - Entry-point tutorial (394 lines) algorithms.Rmd - Mathematical foundations (667 lines) pixel-morphing.Rmd - Advanced applications (884 lines)","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"core-style-principles","dir":"","previous_headings":"Vignette Writing Style Guide","what":"Core Style Principles","title":"CLAUDE.md","text":"1. Progressive Complexity - Start simplest use case (basic matrix input) - Add complexity incrementally (data frames → rectangular → forbidden → maximization) - section builds previous concepts - Clear “Use” sections method 2. Mathematical Rigor Accessibility - Formal definitions LaTeX precision - Plain language explanations /equations - Concrete examples immediately following theory - Balance mathematical correctness readability 3. Code-First Demonstration - Every concept illustrated working code - Self-contained examples using small, reproducible data - Real-world scenarios (employee scheduling, particle tracking, molecular alignment) - Comments explain “” just “” 4. Structured Narrative Flow 5. Visual Communication - Use tables algorithm comparisons - Include complexity notation (O(n³), O(n²)) - Show decision trees (use algorithm) - Pixel morphing vignette uses embedded images/GIFs visual learning 6. Cross-Referencing - Link vignettes appropriate moments - Point function documentation (?lap_solve) - Reference GitHub repository contributions - Suggest “Learn ” pathways end major section 7. Practical Guidance - Performance benchmarks system.time() - Memory/scalability considerations - “use” sections - Common pitfalls solutions 8. Code Formatting Standards 9. Pseudocode Algorithms - Indented, readable structure - Clear variable naming conventions - Step--step annotations - Mix mathematical notation plain English 10. Domain-Specific Applications - Ecology: vegetation plot matching Bray-Curtis dissimilarity - Physics: particle tracking velocity prediction - Chemistry: molecular alignment RMSD - Computer Vision: pixel morphing intuitive visualization","code":"Overview → Problem Definition → Basic Usage → Advanced Features → Performance Considerations → Real-World Examples → Summary → Further Reading # Use descriptive variable names cost <- matrix(c(...), nrow = 3, byrow = TRUE)  # Inline comments for complex logic result <- lap_solve(cost)  # Defaults to method = \"auto\"  # Show actual output print(result)"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"recommended-future-vignettes","dir":"","previous_headings":"Vignette Writing Style Guide","what":"Recommended Future Vignettes","title":"CLAUDE.md","text":"Priority 1 - Matching Workflows (NEW v1.0.0) : v1.0.0 added major matching functionality (match_couples(), greedy_couples(), balance_diagnostics()) dedicated vignette Treatment effect estimation workflow Preprocessing: auto-scaling, health checks, categorical encoding Optimal vs greedy trade-offs Blocking/stratification matchmaker() Balance assessment interpretation Publication-ready tables Target audience: Researchers, epidemiologists, economists Estimated length: 600-800 lines : Balance assessment complex multiple metrics (std diff, variance ratios, KS tests) balance matters Interpreting standardized differences (<0.1 excellent, 0.1-0.25 good, etc.) Variance ratios distributional similarity KS tests non-normal variables Handling imbalanced covariates Sensitivity analysis Target audience: Applied researchers needing causal inference Estimated length: 400-500 lines Priority 2 - Algorithm Selection : 14+ algorithms can overwhelm users; method = \"auto\" hides important details Decision flowchart algorithm selection Benchmarks across problem types (dense, sparse, rectangular, binary) Memory vs speed trade-offs override auto selection Auction variants comparison (standard, scaled, Gauss-Seidel) Greedy vs optimal: speed vs quality Target audience: Power users, performance-critical applications Estimated length: 500-600 lines Priority 3 - Domain Applications : Pixel-morphing vignette mentions ecology doesn’t show real examples Vegetation plot matching across time periods Species composition similarity (Bray-Curtis, Jaccard) Spatial autocorrelation handling Hierarchical matching large surveys (>1000 plots) Climate matching transplant experiments Animal pairing behavioral studies Target audience: Ecologists, conservation biologists Estimated length: 600-700 lines : Major use case matching explicitly covered Treatment effect estimation framework Propensity score matching Nearest neighbor calipers Exact matching key variables Sensitivity analysis (Rosenbaum bounds) Reporting standards (STROBE guidelines) Target audience: Epidemiologists, health services researchers Estimated length: 700-800 lines Priority 4 - Advanced Topics : Pixel-morphing shows approximation strategies needs dedicated guide exact LAP becomes impractical (n > 5,000) Feature quantization strategy (reduce problem size) Hierarchical decomposition (divide--conquer) Resolution reduction (coarse--fine) Greedy algorithms: sorted, row_best, priority queue Parallel batch solving Memory management Target audience: Data scientists, engineers large-n problems Estimated length: 500-600 lines : lap_solve_kbest() exists lacks usage guidance Murty’s algorithm explanation need multiple solutions Robustness analysis Cost landscape exploration Sensitivity perturbations Alternative planning scenarios Target audience: Decision scientists, operations researchers Estimated length: 400-500 lines : Many domains need specialized similarity measures Mahalanobis distance correlated variables Gower distance mixed-type data String edit distance text matching Network-based distances Spatial autocorrelation adjustments Creating custom cost matrices Target audience: Methodologists, statisticians Estimated length: 450-550 lines Priority 5 - Specialized Use Cases : Natural extension particle tracking example Panel data matching Trajectory alignment Dynamic time warping connections Temporal constraints (max displacement) Velocity-predicted matching Event sequence alignment Target audience: Physicists, video analysts, signal processors Estimated length: 500-600 lines “image-registration.Rmd” - Computer vision applications : Pixel-morphing shows potential doesn’t cover full CV workflow Feature point matching (SIFT, SURF) Image alignment warping Multi-resolution strategies Color space considerations Real-time performance Integration image processing packages Target audience: Computer vision researchers, photographers Estimated length: 550-650 lines","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"vignette-template-structure","dir":"","previous_headings":"Vignette Writing Style Guide","what":"Vignette Template Structure","title":"CLAUDE.md","text":"","code":"--- title: \"Title in Title Case\" author: \"Gilles Colling\" date: \"`r Sys.Date()`\" output: rmarkdown::html_vignette vignette: >   %\\VignetteIndexEntry{Title in Title Case}   %\\VignetteEngine{knitr::rmarkdown}   %\\VignetteEncoding{UTF-8} ---  {r setup, include = FALSE} knitr::opts_chunk$set(   collapse = TRUE,   comment = \"#>\",   fig.width = 6,   fig.height = 4 ) library(couplr)   ## Overview  [2-3 paragraphs explaining: what problem does this solve, who is it for, what will they learn]  **Key Features:** [3-5 bullet points]  **Related vignettes:** [Cross-references]  ## Problem Definition  [Mathematical formulation if applicable, with LaTeX]  [Plain language explanation]  ## Basic Usage  [Simplest possible example with minimal code]  {r basic-example} # Code here   ## Advanced Features  [Progressive complexity, each section follows:] ### Feature Name [Explanation] {r feature-demo} [When to use / when NOT to use]  ## Real-World Example  [Complete workflow with domain-specific data]  ## Performance Considerations  [Benchmarks, scalability, memory usage]  ## Summary  [Recap key points in 3-5 bullets]  **Learn more:** - [Links to related vignettes] - [Function documentation] - [External resources]"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"writing-checklist","dir":"","previous_headings":"Vignette Writing Style Guide","what":"Writing Checklist","title":"CLAUDE.md","text":"submitting new vignette: Follows progressive complexity principle Every concept working code example Cross-references related vignettes Includes “use” guidance Shows real-world application Performance/scalability notes Summary “Learn ” section Mathematical notation correct (used) Code self-contained reproducible Proper attribution algorithms/methods Builds successfully devtools::build_vignettes()","code":""},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"package-dependencies","dir":"","previous_headings":"","what":"Package Dependencies","title":"CLAUDE.md","text":"System Requirements: - R ≥ 3.5.0 - C++17 compiler (Rtools Windows g++ supporting C++17) - RcppEigen matrix operations Core Dependencies (Imports): Suggested Dependencies (Optional): LinkingTo: - Rcpp - R/C++ interface - RcppEigen - High-performance matrix library","code":"Rcpp (>= 1.0.0)           # C++ integration RcppEigen                 # Matrix operations tibble (>= 3.0.0)         # Modern data frames dplyr (>= 1.0.0)          # Data manipulation rlang (>= 0.4.0)          # Tidy evaluation purrr (>= 0.3.0)          # Functional programming magrittr (>= 2.0.0)       # Pipe operator # Testing testthat (>= 3.0.0)       # Unit testing framework withr                     # Temporary state management  # Documentation knitr                     # Vignette generation rmarkdown                 # Documentation rendering  # Performance bench                     # Benchmarking parallel                  # Parallel computation future (>= 1.20.0)        # Async parallel framework future.apply (>= 1.8.0)   # Future-compatible apply functions  # Image processing (for pixel morphing) magick                    # ImageMagick R bindings OpenImageR                # Image processing utilities farver                    # Fast color space manipulation av                        # Video encoding reticulate                # Python integration png                       # PNG file handling"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"development-history","dir":"","previous_headings":"","what":"Development History","title":"CLAUDE.md","text":"v1.0.0 (2025-11-19) - Major Release Complete rewrite 6 major enhancement steps: Automatic Preprocessing - Variable health checks, smart scaling, categorical encoding Balance Diagnostics - Standardized differences, variance ratios, KS tests, quality ratings Joined Dataset Output - join_matched(), augment() analysis-ready data Distance Caching - compute_distances() reusable precomputed distances Parallel Processing - Block matching parallelization via future framework Fun Error Messages - Couple-themed messages optional emoji support Key Metrics: - 1382 tests passing (1365) - 100% backward compatible - 20 R files, 22 C++ files - 3 vignettes, 8+ example files - Renamed lapr couplr v0.1.0 - Initial Release - 12 LAP solver algorithms + 3 greedy methods - Basic matching workflows - Pixel morphing visualization - Tidy interface tibble output","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"id_1-basic-optimal-matching","dir":"","previous_headings":"Quick Reference: Common Workflows","what":"1. Basic Optimal Matching","title":"CLAUDE.md","text":"","code":"library(couplr)  # Match with automatic preprocessing result <- match_couples(   left = treatment_df,   right = control_df,   vars = c(\"age\", \"income\", \"education\"),   auto_scale = TRUE,   max_distance = 0.5,   return_diagnostics = TRUE )  # Check balance balance <- balance_diagnostics(result, treatment_df, control_df, vars) print(balance)  # Get analysis-ready dataset matched_data <- join_matched(result, treatment_df, control_df)"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"id_2-fast-greedy-matching-for-large-data","dir":"","previous_headings":"Quick Reference: Common Workflows","what":"2. Fast Greedy Matching for Large Data","title":"CLAUDE.md","text":"","code":"# Use greedy algorithm for speed result <- greedy_couples(   left = large_treatment_df,   right = large_control_df,   vars = c(\"age\", \"income\"),   strategy = \"row_best\",  # or \"sorted\" or \"pq\"   auto_scale = TRUE )"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"id_3-matching-with-blocking","dir":"","previous_headings":"Quick Reference: Common Workflows","what":"3. Matching with Blocking","title":"CLAUDE.md","text":"","code":"# Create blocks blocks <- matchmaker(   left_df, right_df,   block_type = \"group\",   block_by = \"site\" )  # Match within blocks (optionally in parallel) result <- match_couples(   left_df, right_df,   vars = c(\"age\", \"income\"),   block_id = blocks$block_id,   parallel = TRUE )"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"id_4-distance-caching-for-experimentation","dir":"","previous_headings":"Quick Reference: Common Workflows","what":"4. Distance Caching for Experimentation","title":"CLAUDE.md","text":"","code":"# Compute distances once dist_obj <- compute_distances(   left_df, right_df,   vars = c(\"age\", \"income\", \"education\"),   scale = \"robust\" )  # Try different constraints quickly result1 <- match_couples(dist_obj, max_distance = 0.3) result2 <- match_couples(dist_obj, max_distance = 0.5) result3 <- greedy_couples(dist_obj, strategy = \"sorted\")  # Update constraints without recomputing dist_obj2 <- update_constraints(dist_obj, max_distance = 0.4)"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"id_5-lap-solving-low-level","dir":"","previous_headings":"Quick Reference: Common Workflows","what":"5. LAP Solving (Low-Level)","title":"CLAUDE.md","text":"","code":"# Create cost matrix cost <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9), nrow = 3)  # Solve with specific algorithm result <- lap_solve(cost, method = \"jv\")  # Jonker-Volgenant  # Or let the package choose result <- lap_solve(cost, method = \"auto\")"},{"path":"https://gcol33.github.io/couplr/CLAUDE.html","id":"id_6-publication-workflow","dir":"","previous_headings":"Quick Reference: Common Workflows","what":"6. Publication Workflow","title":"CLAUDE.md","text":"information: - See vignettes: browseVignettes(\"couplr\") - View examples: ?match_couples, ?balance_diagnostics - Check issues: https://github.com/gcol33/couplr/issues","code":"# 1. Match result <- match_couples(left, right, vars, auto_scale = TRUE)  # 2. Assess balance balance <- balance_diagnostics(result, left, right, vars)  # 3. Create publication table balance_table(balance, digits = 3)  # 4. Get matched dataset for analysis data <- join_matched(result, left, right,                      left_vars = c(\"outcome\", \"covariate1\"),                      right_vars = c(\"covariate1\"))  # 5. Run analysis on matched data lm(outcome_left ~ covariate1_left + covariate1_right, data = data)"},{"path":"https://gcol33.github.io/couplr/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to couplr","title":"Contributing to couplr","text":"Thank interest contributing couplr.","code":""},{"path":"https://gcol33.github.io/couplr/CONTRIBUTING.html","id":"reporting-issues","dir":"","previous_headings":"","what":"Reporting Issues","title":"Contributing to couplr","text":"Please open issue https://github.com/gcol33/couplr/issues : minimal reproducible example Expected vs. actual behavior Output sessionInfo()","code":""},{"path":"https://gcol33.github.io/couplr/CONTRIBUTING.html","id":"development-setup","dir":"","previous_headings":"","what":"Development Setup","title":"Contributing to couplr","text":"","code":"# Install dependencies install.packages(c(\"devtools\", \"testthat\", \"Rcpp\", \"RcppEigen\"))  # Clone and install git clone https://github.com/gcol33/couplr.git cd couplr devtools::install_deps() devtools::load_all() devtools::test()"},{"path":"https://gcol33.github.io/couplr/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull Requests","title":"Contributing to couplr","text":"Fork repository Create feature branch Make changes Run devtools::check() ensure tests pass Submit pull request","code":""},{"path":"https://gcol33.github.io/couplr/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"","what":"Code Style","title":"Contributing to couplr","text":"Follow tidyverse style R code Use C++17 C++ code Add tests new functionality Update documentation needed","code":""},{"path":"https://gcol33.github.io/couplr/CONTRIBUTING.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Contributing to couplr","text":"contributing, agree contributions licensed MIT License.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":null,"dir":"","previous_headings":"","what":"Quick Orientation","title":"Quick Orientation","text":"repository R package (couplr, formerly lapr) provides linear-assignment solvers, optimal matching workflows, image “pixel morphing” helpers. project mixes R (high-level API, data handling, vignettes/tests) C++ (many solver implementations, Rcpp exports, image routines). Key design points AI agents know: - R user-facing API: see R/assignment.R (method selection) R/lap_solve.R (tidy wrappers). - C++ implements algorithms: look src/ (many solve_*.cpp) unified interface src/rcpp_interface.cpp. - Exported C++ functions use lap_ prefix (e.g. lap_solve_jv, lap_solve_hungarian) called R via generated RcppExports.R. - Image/pixel utilities implemented C++ called R (see R/pixel_morph.R exports rcpp_interface.cpp).","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"files-to-reference-when-making-changes","dir":"","previous_headings":"","what":"Files to reference when making changes","title":"Quick Orientation","text":"R/assignment.R — central auto-selection logic assignment() wrapper. Add new solver names . R/lap_solve.R — tidy user-facing functions, grouped-data handling printing conventions. src/rcpp_interface.cpp — declare/export C++ entry points. New C++ solver impls must exposed . src/solve_*.cpp — algorithm implementations (one file per solver). R/RcppExports.R — autogenerated wrappers (.Call). edit manually; regenerate via Rcpp::compileAttributes() adding exports. DESCRIPTION — package metadata, imports (Rcpp, RcppEigen) SystemRequirements: C++17.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"build--test--debug-workflows-windows-notes","dir":"","previous_headings":"","what":"Build / test / debug workflows (Windows notes)","title":"Quick Orientation","text":"Prerequisites: R (see DESCRIPTION), dev packages (Rcpp, RcppEigen, devtools/remotes) C++ toolchain (Rtools Windows) supporting C++17. normal shell / Powershell: R CMD INSTALL --build . R: devtools::install(build = TRUE) (requires devtools). R CMD build . R CMD check <tarball> R: devtools::check() devtools::test() (uses testthat, parallel configured DESCRIPTION). encounter strange binary mismatches, remove committed build artefacts reinstalling: Remove-Item src\\*.o, src\\*.dll -Force (Powershell) simply run R CMD INSTALL --clean ..","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"conventions--patterns-to-follow","dir":"","previous_headings":"","what":"Conventions & patterns to follow","title":"Quick Orientation","text":"Naming: R-facing solver wrappers use lap_solve_<name> C++ method strings R map via assignment() (see switch() R/assignment.R). 0/1-based indexing: R uses 1-based assignment vectors; many C++ internals use 0-based. Conversions happen RcppExports.R / rcpp_interface.cpp — preserve conversions. Forbidden edges: NA Inf cost matrix marks forbidden assignments. assignment() converts inputs relies prepare_cost_matrix C++ masking. Add src/solve_<name>.cpp implementing algorithm. Declare impl function prototype src/rcpp_interface.cpp implement exported wrapper // [[Rcpp::export]] named lap_solve_<name>. Run Rcpp::compileAttributes() (regenerates R/RcppExports.R src/RcppExports.cpp). Wire method string R/assignment.R’s switch() add documentation.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"pixel-morph-specifics","dir":"","previous_headings":"","what":"Pixel morph specifics","title":"Quick Orientation","text":"R/pixel_morph.R orchestrates pixel-level operations calls several C++ helpers (e.g. compute_pixel_cost_cpp, morph_pixel_level_cpp). C++ image exports expect vectors length H * W * 3 perform strict validation; keep argument shapes type checks modifying paths. Assignment semantics: rendering C++ expects 0-based assignment indices; R returns 1-based vectors callers. Check conversions around assign_0based + 1L R/pixel_morph.R.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"dependencies--environment","dir":"","previous_headings":"","what":"Dependencies & environment","title":"Quick Orientation","text":"Declared DESCRIPTION: Rcpp, RcppEigen, tibble, dplyr, rlang, purrr, magrittr, many Suggests (testthat, knitr, magick…). Ensure required system libs Rtools (Windows) available compilation.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"common-pitfalls-to-avoid","dir":"","previous_headings":"","what":"Common pitfalls to avoid","title":"Quick Orientation","text":"manually edit auto-generated files: R/RcppExports.R src/RcppExports.cpp created Rcpp::compileAttributes(). src/ directory contains committed object files (*.o, *.dll); can stale. Clean building behavior unexpected. Keep method strings R/assignment.R exported lap_ C++ names sync.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"example-quick-tasks-for-an-ai-code-agent","dir":"","previous_headings":"","what":"Example quick tasks for an AI code agent","title":"Quick Orientation","text":"Add new solver: follow “Adding new C++ solver” steps add documentation man/ via roxygen comments. Improve auto-selection heuristics: modify R/assignment.R::method == 'auto' heuristics add tests tests/ demonstrating expected selection small/sparse/dense inputs.","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"critical-no-fabricated-data","dir":"","previous_headings":"","what":"CRITICAL: No Fabricated Data","title":"Quick Orientation","text":"Never include made-numbers, benchmarks, outputs documentation examples. ❌ fabricate benchmark results ❌ invent example outputs ❌ guess performance numbers ✅ Run actual code get real results ✅ Ask maintainers need benchmark data ✅ Mark placeholders: # TODO: Run actual benchmark : Fabricated data misleads users performance erodes trust.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"contact--issues","dir":"","previous_headings":"","what":"Contact / Issues","title":"Quick Orientation","text":"Bug reports URL DESCRIPTION: https://github.com/gcol33/couplr/issues — open issue ambiguous design decisions.","code":""},{"path":"https://gcol33.github.io/couplr/copilot-instructions.html","id":"additional-resources","dir":"","previous_headings":"","what":"Additional Resources","title":"Quick Orientation","text":"See CLAUDE.md repository root comprehensive development documentation file provides quick orientation; CLAUDE.md detailed architecture, testing strategies, development workflows","code":""},{"path":"https://gcol33.github.io/couplr/index.html","id":"couplr","dir":"","previous_headings":"","what":"couplr: Linear Assignment Problems and Matching in R","title":"couplr: Linear Assignment Problems and Matching in R","text":"couplr R package solving Linear Assignment Problems (LAP) production-ready matching workflows. provides optimal one--one matching two groups, automatic preprocessing, balance diagnostics, analysis-ready output.","code":""},{"path":"https://gcol33.github.io/couplr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"couplr: Linear Assignment Problems and Matching in R","text":"","code":"# Install from GitHub remotes::install_github(\"gcol33/couplr\")"},{"path":"https://gcol33.github.io/couplr/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"couplr: Linear Assignment Problems and Matching in R","text":"","code":"library(couplr)  # Match treatment and control groups on covariates result <- match_couples(  treated, control,  vars = c(\"age\", \"income\", \"education\"),  auto_scale = TRUE )  # Check covariate balance balance_diagnostics(result, treated, control, vars = c(\"age\", \"income\", \"education\"))  # Get analysis-ready dataset matched_data <- join_matched(result, treated, control)"},{"path":"https://gcol33.github.io/couplr/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"couplr: Linear Assignment Problems and Matching in R","text":"12 optimal LAP algorithms: Hungarian, Jonker-Volgenant, Auction, Gabow-Tarjan, 3 greedy algorithms: Fast approximate matching large datasets Automatic preprocessing: Variable scaling, health checks, categorical encoding Balance diagnostics: Standardized differences, variance ratios, KS statistics Blocking support: Exact matching stratification Distance caching: Precompute distances rapid experimentation Parallel processing: Multi-core matching via future framework","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/index.html","id":"optimal-matching","dir":"","previous_headings":"Usage","what":"Optimal Matching","title":"couplr: Linear Assignment Problems and Matching in R","text":"","code":"result <- match_couples(  left = treated,  right = control,  vars = c(\"age\", \"income\"),  auto_scale = TRUE,  max_distance = 0.5 )"},{"path":"https://gcol33.github.io/couplr/index.html","id":"greedy-matching-large-datasets","dir":"","previous_headings":"Usage","what":"Greedy Matching (Large Datasets)","title":"couplr: Linear Assignment Problems and Matching in R","text":"","code":"result <- greedy_couples(  left = treated,  right = control,  vars = c(\"age\", \"income\"),  strategy = \"row_best\" )"},{"path":"https://gcol33.github.io/couplr/index.html","id":"low-level-lap-solving","dir":"","previous_headings":"Usage","what":"Low-Level LAP Solving","title":"couplr: Linear Assignment Problems and Matching in R","text":"","code":"cost <- matrix(c(4, 2, 8, 4, 3, 7, 3, 1, 6), nrow = 3, byrow = TRUE) result <- lap_solve(cost)"},{"path":"https://gcol33.github.io/couplr/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"couplr: Linear Assignment Problems and Matching in R","text":"vignette(\"getting-started\", package = \"couplr\") vignette(\"algorithms\", package = \"couplr\") vignette(\"matching-workflows\", package = \"couplr\") vignette(\"pixel-morphing\", package = \"couplr\")","code":""},{"path":"https://gcol33.github.io/couplr/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"couplr: Linear Assignment Problems and Matching in R","text":"","code":"@software{couplr,  author = {Colling, Gilles},  title = {couplr: Optimal Matching via Linear Assignment},  year = {2025},  url = {https://github.com/gcol33/couplr} }"},{"path":"https://gcol33.github.io/couplr/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"couplr: Linear Assignment Problems and Matching in R","text":"MIT","code":""},{"path":"https://gcol33.github.io/couplr/reference/apply_all_constraints.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply all constraints to cost matrix — apply_all_constraints","title":"Apply all constraints to cost matrix — apply_all_constraints","text":"Main entry point applying constraints.","code":""},{"path":"https://gcol33.github.io/couplr/reference/apply_all_constraints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply all constraints to cost matrix — apply_all_constraints","text":"","code":"apply_all_constraints(   cost_matrix,   left,   right,   vars,   max_distance = Inf,   calipers = NULL,   forbidden = NULL )"},{"path":"https://gcol33.github.io/couplr/reference/apply_calipers.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply caliper constraints — apply_calipers","title":"Apply caliper constraints — apply_calipers","text":"Calipers impose per-variable maximum absolute differences.","code":""},{"path":"https://gcol33.github.io/couplr/reference/apply_calipers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply caliper constraints — apply_calipers","text":"","code":"apply_calipers(cost_matrix, left, right, calipers, vars)"},{"path":"https://gcol33.github.io/couplr/reference/apply_max_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply maximum distance constraint — apply_max_distance","title":"Apply maximum distance constraint — apply_max_distance","text":"Apply maximum distance constraint","code":""},{"path":"https://gcol33.github.io/couplr/reference/apply_max_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply maximum distance constraint — apply_max_distance","text":"","code":"apply_max_distance(cost_matrix, max_distance = Inf)"},{"path":"https://gcol33.github.io/couplr/reference/apply_scaling.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply scaling to matching variables — apply_scaling","title":"Apply scaling to matching variables — apply_scaling","text":"Apply scaling matching variables","code":""},{"path":"https://gcol33.github.io/couplr/reference/apply_scaling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply scaling to matching variables — apply_scaling","text":"","code":"apply_scaling(left_mat, right_mat, method = \"standardize\")"},{"path":"https://gcol33.github.io/couplr/reference/apply_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply weights to matching variables — apply_weights","title":"Apply weights to matching variables — apply_weights","text":"Apply weights matching variables","code":""},{"path":"https://gcol33.github.io/couplr/reference/apply_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply weights to matching variables — apply_weights","text":"","code":"apply_weights(mat, weights)"},{"path":"https://gcol33.github.io/couplr/reference/assignment.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear assignment solver — assignment","title":"Linear assignment solver — assignment","text":"Solve linear assignment problem (minimum- maximum-cost matching) using several algorithms. Forbidden edges can marked NA Inf.","code":""},{"path":"https://gcol33.github.io/couplr/reference/assignment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear assignment solver — assignment","text":"","code":"assignment(   cost,   maximize = FALSE,   method = c(\"auto\", \"jv\", \"hungarian\", \"auction\", \"auction_gs\", \"auction_scaled\", \"sap\",     \"ssp\", \"csflow\", \"hk01\", \"bruteforce\", \"ssap_bucket\", \"cycle_cancel\", \"gabow_tarjan\"),   auction_eps = NULL,   eps = NULL )"},{"path":"https://gcol33.github.io/couplr/reference/assignment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear assignment solver — assignment","text":"cost Numeric matrix; rows = tasks, columns = agents. NA Inf entries treated forbidden assignments. maximize Logical; TRUE, maximizes total cost instead minimizing. method Character string indicating algorithm use. One \"auto\", \"jv\", \"hungarian\", \"auction\", \"auction_gs\", \"sap\", \"ssp\", \"csflow\", \"hk01\", \"bruteforce\". \"ssp\" accepted alias \"sap\". auction_eps Optional numeric epsilon Auction/Auction-GS methods. NULL, internal default (e.g., 1e-9) used. eps Deprecated. Use auction_eps. provided auction_eps NULL, value used auction_eps.","code":""},{"path":"https://gcol33.github.io/couplr/reference/assignment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear assignment solver — assignment","text":"object class lap_solve_result, list elements: match — integer vector length min(nrow(cost), ncol(cost)) giving assigned column row (0 unassigned). total_cost — numeric scalar, objective value. status — character scalar, e.g. \"optimal\". method_used — character scalar, algorithm actually used.","code":""},{"path":"https://gcol33.github.io/couplr/reference/assignment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear assignment solver — assignment","text":"method = \"auto\" selects algorithm based problem size/shape data characteristics: small (n≤8): \"bruteforce\" — exact enumeration Binary/constant costs: \"hk01\" — specialized 0/1 costs Sparse (>50\\ Small-medium (8<n≤50): \"hungarian\" — provides exact dual solutions Medium (50<n≤75): \"jv\" — fast general-purpose solver Large (n>75): \"auction_scaled\" — fastest large dense problems Benchmarks show auction_scaled JV 100-1500x faster Hungarian n=500.","code":""},{"path":"https://gcol33.github.io/couplr/reference/assignment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear assignment solver — assignment","text":"","code":"cost <- matrix(c(4,2,5, 3,3,6, 7,5,4), nrow = 3, byrow = TRUE) res  <- assignment(cost) res$match; res$total_cost #> [1] 2 1 3 #> [1] 9"},{"path":"https://gcol33.github.io/couplr/reference/assign_blocks_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign blocks using clustering — assign_blocks_cluster","title":"Assign blocks using clustering — assign_blocks_cluster","text":"Assign blocks using clustering","code":""},{"path":"https://gcol33.github.io/couplr/reference/assign_blocks_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign blocks using clustering — assign_blocks_cluster","text":"","code":"assign_blocks_cluster(left, right, block_vars, method, n_blocks, ...)"},{"path":"https://gcol33.github.io/couplr/reference/assign_blocks_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign blocks based on grouping variable(s) — assign_blocks_group","title":"Assign blocks based on grouping variable(s) — assign_blocks_group","text":"Assign blocks based grouping variable(s)","code":""},{"path":"https://gcol33.github.io/couplr/reference/assign_blocks_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign blocks based on grouping variable(s) — assign_blocks_group","text":"","code":"assign_blocks_group(left, right, block_by)"},{"path":"https://gcol33.github.io/couplr/reference/as_assignment_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert assignment result to a binary matrix — as_assignment_matrix","title":"Convert assignment result to a binary matrix — as_assignment_matrix","text":"Turns tidy assignment result back 0/1 assignment matrix.","code":""},{"path":"https://gcol33.github.io/couplr/reference/as_assignment_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert assignment result to a binary matrix — as_assignment_matrix","text":"","code":"as_assignment_matrix(x, n_sources = NULL, n_targets = NULL)"},{"path":"https://gcol33.github.io/couplr/reference/as_assignment_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert assignment result to a binary matrix — as_assignment_matrix","text":"x assignment result object class lap_solve_result n_sources Number source nodes, optional n_targets Number target nodes, optional","code":""},{"path":"https://gcol33.github.io/couplr/reference/as_assignment_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert assignment result to a binary matrix — as_assignment_matrix","text":"Integer matrix 0 1 entries","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic Augment Function — augment","title":"Generic Augment Function — augment","text":"S3 generic augmenting model results original data.","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic Augment Function — augment","text":"","code":"augment(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/augment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic Augment Function — augment","text":"x object augment ... Additional arguments passed methods","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic Augment Function — augment","text":"Augmented data (depends method)","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.matching_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment Matching Results with Original Data (broom-style) — augment.matching_result","title":"Augment Matching Results with Original Data (broom-style) — augment.matching_result","text":"S3 method augmenting matching results following broom package conventions. thin wrapper around join_matched() sensible defaults quick exploration.","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.matching_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment Matching Results with Original Data (broom-style) — augment.matching_result","text":"","code":"# S3 method for class 'matching_result' augment(x, left, right, ...)"},{"path":"https://gcol33.github.io/couplr/reference/augment.matching_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment Matching Results with Original Data (broom-style) — augment.matching_result","text":"x matching_result object left original left dataset right original right dataset ... Additional arguments passed join_matched()","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.matching_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment Matching Results with Original Data (broom-style) — augment.matching_result","text":"tibble matched pairs original data (see join_matched())","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.matching_result.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augment Matching Results with Original Data (broom-style) — augment.matching_result","text":"method follows augment() convention broom package, making easy integrate couplr tidymodels workflows. equivalent calling join_matched() default parameters. broom package loaded, can use couplr::augment() access function.","code":""},{"path":"https://gcol33.github.io/couplr/reference/augment.matching_result.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augment Matching Results with Original Data (broom-style) — augment.matching_result","text":"","code":"left <- data.frame(   id = 1:5,   treatment = 1,   age = c(25, 30, 35, 40, 45) )  right <- data.frame(   id = 6:10,   treatment = 0,   age = c(24, 29, 36, 41, 44) )  result <- match_couples(left, right, vars = \"age\") couplr::augment(result, left, right) #> # A tibble: 5 × 9 #>   pair_id left_id right_id distance .age_diff treatment_left age_left #>     <int>   <int>    <int>    <dbl>     <dbl>          <dbl>    <dbl> #> 1       1       1        6        1         1              1       25 #> 2       2       2        7        1         1              1       30 #> 3       3       3        8        1        -1              1       35 #> 4       4       4        9        1        -1              1       40 #> 5       5       5       10        1         1              1       45 #> # ℹ 2 more variables: treatment_right <dbl>, age_right <dbl>"},{"path":"https://gcol33.github.io/couplr/reference/auto_encode_categorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically encode categorical variables — auto_encode_categorical","title":"Automatically encode categorical variables — auto_encode_categorical","text":"Converts categorical variables numeric representations suitable matching. Currently supports binary variables (0/1) ordered factors.","code":""},{"path":"https://gcol33.github.io/couplr/reference/auto_encode_categorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically encode categorical variables — auto_encode_categorical","text":"","code":"auto_encode_categorical(left, right, var)"},{"path":"https://gcol33.github.io/couplr/reference/auto_encode_categorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically encode categorical variables — auto_encode_categorical","text":"left Data frame left units right Data frame right units var Variable name encode","code":""},{"path":"https://gcol33.github.io/couplr/reference/auto_encode_categorical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatically encode categorical variables — auto_encode_categorical","text":"List encoded left right columns, plus encoding metadata","code":""},{"path":"https://gcol33.github.io/couplr/reference/balance_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Diagnostics for Matched Pairs — balance_diagnostics","title":"Balance Diagnostics for Matched Pairs — balance_diagnostics","text":"Computes comprehensive balance statistics comparing distribution matching variables left right units matched sample.","code":""},{"path":"https://gcol33.github.io/couplr/reference/balance_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Diagnostics for Matched Pairs — balance_diagnostics","text":"","code":"balance_diagnostics(   result,   left,   right,   vars = NULL,   left_id = \"id\",   right_id = \"id\" )"},{"path":"https://gcol33.github.io/couplr/reference/balance_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Diagnostics for Matched Pairs — balance_diagnostics","text":"result matching result object match_couples() greedy_couples() left Data frame left units right Data frame right units vars Character vector variable names check balance . Defaults variables used matching (available result). left_id Character, name ID column left data (default: \"id\") right_id Character, name ID column right data (default: \"id\")","code":""},{"path":"https://gcol33.github.io/couplr/reference/balance_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Diagnostics for Matched Pairs — balance_diagnostics","text":"S3 object class balance_diagnostics containing: var_stats Tibble per-variable balance statistics overall List overall balance metrics pairs Tibble matched pairs variables n_matched Number matched pairs n_unmatched_left Number unmatched left units n_unmatched_right Number unmatched right units method Matching method used has_blocks Whether blocking used block_stats Per-block statistics (blocking used)","code":""},{"path":"https://gcol33.github.io/couplr/reference/balance_diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Diagnostics for Matched Pairs — balance_diagnostics","text":"function computes several balance metrics: Standardized Difference: difference means divided pooled standard deviation. Values less 0.1 indicate excellent balance, 0.1-0.25 good balance. Variance Ratio: ratio standard deviations (left/right). Values close 1 ideal. KS Statistic: Kolmogorov-Smirnov test statistic comparing distributions. Lower values indicate similar distributions. Overall Metrics include mean absolute standardized difference across variables, proportion variables large imbalance (|std diff| > 0.25), maximum standardized difference.","code":""},{"path":"https://gcol33.github.io/couplr/reference/balance_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Diagnostics for Matched Pairs — balance_diagnostics","text":"","code":"if (FALSE) { # \\dontrun{ # Create sample data left <- data.frame(   id = 1:50,   age = rnorm(50, 45, 10),   income = rnorm(50, 50000, 15000) ) right <- data.frame(   id = 51:150,   age = rnorm(100, 47, 10),   income = rnorm(100, 52000, 15000) )  # Match result <- match_couples(left, right, vars = c(\"age\", \"income\"))  # Get balance diagnostics balance <- balance_diagnostics(result, left, right, vars = c(\"age\", \"income\")) print(balance)  # Get balance table balance_table(balance) } # }"},{"path":"https://gcol33.github.io/couplr/reference/balance_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Balance Table — balance_table","title":"Create Balance Table — balance_table","text":"Formats balance diagnostics clean table display export.","code":""},{"path":"https://gcol33.github.io/couplr/reference/balance_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Balance Table — balance_table","text":"","code":"balance_table(balance, digits = 3)"},{"path":"https://gcol33.github.io/couplr/reference/balance_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Balance Table — balance_table","text":"balance balance_diagnostics object balance_diagnostics() digits Number decimal places rounding (default: 3)","code":""},{"path":"https://gcol33.github.io/couplr/reference/balance_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Balance Table — balance_table","text":"tibble formatted balance statistics","code":""},{"path":"https://gcol33.github.io/couplr/reference/BIG_COST.html","id":null,"dir":"Reference","previous_headings":"","what":"Large value for forbidden pairs — BIG_COST","title":"Large value for forbidden pairs — BIG_COST","text":"Large value forbidden pairs","code":""},{"path":"https://gcol33.github.io/couplr/reference/BIG_COST.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Large value for forbidden pairs — BIG_COST","text":"","code":"BIG_COST"},{"path":"https://gcol33.github.io/couplr/reference/BIG_COST.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Large value for forbidden pairs — BIG_COST","text":"object class numeric length 1.","code":""},{"path":"https://gcol33.github.io/couplr/reference/build_cost_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Build cost matrix for matching — build_cost_matrix","title":"Build cost matrix for matching — build_cost_matrix","text":"main entry point distance computation.","code":""},{"path":"https://gcol33.github.io/couplr/reference/build_cost_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build cost matrix for matching — build_cost_matrix","text":"","code":"build_cost_matrix(   left,   right,   vars,   distance = \"euclidean\",   weights = NULL,   scale = FALSE )"},{"path":"https://gcol33.github.io/couplr/reference/calculate_var_balance.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Variable-Level Balance Statistics — calculate_var_balance","title":"Calculate Variable-Level Balance Statistics — calculate_var_balance","text":"Calculate Variable-Level Balance Statistics","code":""},{"path":"https://gcol33.github.io/couplr/reference/calculate_var_balance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Variable-Level Balance Statistics — calculate_var_balance","text":"","code":"calculate_var_balance(left_vals, right_vals, var_name)"},{"path":"https://gcol33.github.io/couplr/reference/calculate_var_balance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Variable-Level Balance Statistics — calculate_var_balance","text":"left_vals Numeric vector values left group right_vals Numeric vector values right group var_name Character, name variable","code":""},{"path":"https://gcol33.github.io/couplr/reference/calculate_var_balance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Variable-Level Balance Statistics — calculate_var_balance","text":"List balance statistics variable","code":""},{"path":"https://gcol33.github.io/couplr/reference/can_parallelize.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if parallel processing is available — can_parallelize","title":"Check if parallel processing is available — can_parallelize","text":"Check parallel processing available","code":""},{"path":"https://gcol33.github.io/couplr/reference/can_parallelize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if parallel processing is available — can_parallelize","text":"","code":"can_parallelize()"},{"path":"https://gcol33.github.io/couplr/reference/can_parallelize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if parallel processing is available — can_parallelize","text":"Logical indicating future package available","code":""},{"path":"https://gcol33.github.io/couplr/reference/check_cost_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Check cost distribution for problems — check_cost_distribution","title":"Check cost distribution for problems — check_cost_distribution","text":"Examines distance matrix common issues provides helpful warnings.","code":""},{"path":"https://gcol33.github.io/couplr/reference/check_cost_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check cost distribution for problems — check_cost_distribution","text":"","code":"check_cost_distribution(cost_matrix, threshold_zero = 1e-10, warn = TRUE)"},{"path":"https://gcol33.github.io/couplr/reference/check_cost_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check cost distribution for problems — check_cost_distribution","text":"cost_matrix Numeric matrix distances threshold_zero Threshold considering distance \"zero\" (default: 1e-10) warn TRUE, issue warnings problems found","code":""},{"path":"https://gcol33.github.io/couplr/reference/check_cost_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check cost distribution for problems — check_cost_distribution","text":"List diagnostic information","code":""},{"path":"https://gcol33.github.io/couplr/reference/check_full_matching.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if full matching was achieved — check_full_matching","title":"Check if full matching was achieved — check_full_matching","text":"Check full matching achieved","code":""},{"path":"https://gcol33.github.io/couplr/reference/check_full_matching.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if full matching was achieved — check_full_matching","text":"","code":"check_full_matching(result)"},{"path":"https://gcol33.github.io/couplr/reference/check_variable_health.html","id":null,"dir":"Reference","previous_headings":"","what":"Check variable health for matching — check_variable_health","title":"Check variable health for matching — check_variable_health","text":"Analyzes variables common problems can affect matching quality: constant columns, high missingness, extreme skewness, outliers.","code":""},{"path":"https://gcol33.github.io/couplr/reference/check_variable_health.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check variable health for matching — check_variable_health","text":"","code":"check_variable_health(   left,   right,   vars,   high_missingness_threshold = 0.5,   low_variance_threshold = 1e-06 )"},{"path":"https://gcol33.github.io/couplr/reference/check_variable_health.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check variable health for matching — check_variable_health","text":"left Data frame left units right Data frame right units vars Character vector variable names check high_missingness_threshold Threshold high missingness warning (default: 0.5) low_variance_threshold Threshold nearly-constant variables (default: 1e-6)","code":""},{"path":"https://gcol33.github.io/couplr/reference/check_variable_health.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check variable health for matching — check_variable_health","text":"list class \"variable_health\" containing: summary: Tibble per-variable diagnostics issues: List detected issues severity levels exclude_vars: Variables excluded warnings: Human-readable warnings","code":""},{"path":"https://gcol33.github.io/couplr/reference/compute_distances.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute and Cache Distance Matrix for Reuse — compute_distances","title":"Compute and Cache Distance Matrix for Reuse — compute_distances","text":"Precomputes distance matrix left right datasets, allowing reused across multiple matching operations different constraints. particularly useful exploring different matching parameters (max_distance, calipers, methods) without recomputing distances.","code":""},{"path":"https://gcol33.github.io/couplr/reference/compute_distances.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute and Cache Distance Matrix for Reuse — compute_distances","text":"","code":"compute_distances(   left,   right,   vars,   distance = \"euclidean\",   weights = NULL,   scale = FALSE,   auto_scale = FALSE,   left_id = \"id\",   right_id = \"id\",   block_id = NULL )"},{"path":"https://gcol33.github.io/couplr/reference/compute_distances.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute and Cache Distance Matrix for Reuse — compute_distances","text":"left Left dataset (data frame) right Right dataset (data frame) vars Character vector variable names use distance computation distance Distance metric (default: \"euclidean\") weights Optional numeric vector variable weights scale Scaling method: FALSE, \"standardize\", \"range\", \"robust\" auto_scale Apply automatic preprocessing (default: FALSE) left_id Name ID column left (default: \"id\") right_id Name ID column right (default: \"id\") block_id Optional block ID column name blocked matching","code":""},{"path":"https://gcol33.github.io/couplr/reference/compute_distances.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute and Cache Distance Matrix for Reuse — compute_distances","text":"S3 object class \"distance_object\" containing: cost_matrix: Numeric matrix distances left_ids: Character vector left IDs right_ids: Character vector right IDs block_id: Block ID column name (specified) metadata: List computation details (vars, distance, scale, etc.) original_left: Original left dataset (later joining) original_right: Original right dataset (later joining)","code":""},{"path":"https://gcol33.github.io/couplr/reference/compute_distances.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute and Cache Distance Matrix for Reuse — compute_distances","text":"function computes distances stores reusable object. resulting distance_object can passed match_couples() greedy_couples() instead providing datasets variables. Benefits: Performance: Avoid recomputing distances trying different constraints Exploration: Quickly test max_distance, calipers, methods Consistency: Ensures distances used across comparisons Memory efficient: Can use sparse matrices many pairs forbidden distance_object stores original datasets, allowing downstream functions like join_matched() work seamlessly.","code":""},{"path":"https://gcol33.github.io/couplr/reference/compute_distances.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute and Cache Distance Matrix for Reuse — compute_distances","text":"","code":"# Compute distances once left <- data.frame(id = 1:5, age = c(25, 30, 35, 40, 45), income = c(45, 52, 48, 61, 55) * 1000) right <- data.frame(id = 6:10, age = c(24, 29, 36, 41, 44), income = c(46, 51, 47, 60, 54) * 1000)  dist_obj <- compute_distances(   left, right,   vars = c(\"age\", \"income\"),   scale = \"standardize\" )  # Reuse for different matching strategies result1 <- match_couples(dist_obj, max_distance = 0.5) result2 <- match_couples(dist_obj, max_distance = 1.0) result3 <- greedy_couples(dist_obj, strategy = \"sorted\")  # All use the same precomputed distances"},{"path":"https://gcol33.github.io/couplr/reference/compute_distance_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute pairwise distance matrix — compute_distance_matrix","title":"Compute pairwise distance matrix — compute_distance_matrix","text":"Compute pairwise distance matrix","code":""},{"path":"https://gcol33.github.io/couplr/reference/compute_distance_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute pairwise distance matrix — compute_distance_matrix","text":"","code":"compute_distance_matrix(left_mat, right_mat, distance = \"euclidean\")"},{"path":"https://gcol33.github.io/couplr/reference/count_valid_pairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Count valid pairs in cost matrix — count_valid_pairs","title":"Count valid pairs in cost matrix — count_valid_pairs","text":"Count valid pairs cost matrix","code":""},{"path":"https://gcol33.github.io/couplr/reference/count_valid_pairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count valid pairs in cost matrix — count_valid_pairs","text":"","code":"count_valid_pairs(cost_matrix)"},{"path":"https://gcol33.github.io/couplr/reference/couplr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"couplr: Optimal Pairing and Matching via Linear Assignment — couplr-package","title":"couplr: Optimal Pairing and Matching via Linear Assignment — couplr-package","text":"Solves optimal pairing matching problems using linear assignment algorithms. Provides modern, tidy implementations Hungarian, Jonker-Volgenant, Auction, LAP solvers. Designed matching plots, sites, samples, pairwise optimization problem. Supports rectangular matrices, forbidden assignments, data frame inputs, batch solving, k-best solutions, pixel-level image morphing visualization. Includes automatic preprocessing variable health checks, multiple scaling methods (standardized, range, robust), greedy matching algorithms, comprehensive balance diagnostics assessing match quality using standardized differences distribution comparisons. Solves optimal pairing matching problems using linear assignment algorithms. Designed matching plots, sites, samples, pairwise optimization problem. Provides modern, tidy implementations Hungarian, Jonker–Volgenant, Auction, LAP solvers.","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr-package.html","id":"main-functions","dir":"Reference","previous_headings":"","what":"Main functions","title":"couplr: Optimal Pairing and Matching via Linear Assignment — couplr-package","text":"lap_solve: Solve single assignment problems lap_solve_batch: Solve multiple problems efficiently lap_solve_kbest: Find k-best optimal solutions","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/reference/couplr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"couplr: Optimal Pairing and Matching via Linear Assignment — couplr-package","text":"Maintainer: First Last first.last@example.com","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr_emoji.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a themed emoji — couplr_emoji","title":"Get a themed emoji — couplr_emoji","text":"Get themed emoji","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr_emoji.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a themed emoji — couplr_emoji","text":"","code":"couplr_emoji(   type = c(\"error\", \"warning\", \"info\", \"success\", \"heart\", \"broken\", \"sparkles\",     \"search\", \"chart\", \"warning_sign\", \"stop\", \"check\") )"},{"path":"https://gcol33.github.io/couplr/reference/couplr_inform.html","id":null,"dir":"Reference","previous_headings":"","what":"Info message with emoji — couplr_inform","title":"Info message with emoji — couplr_inform","text":"Info message emoji","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr_inform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Info message with emoji — couplr_inform","text":"","code":"couplr_inform(...)"},{"path":"https://gcol33.github.io/couplr/reference/couplr_messages.html","id":null,"dir":"Reference","previous_headings":"","what":"Couplr message helpers with emoji and humor — couplr_messages","title":"Couplr message helpers with emoji and humor — couplr_messages","text":"Light, fun error/warning messages inspired testthat, themed around coupling matching. Makes errors less intimidating memorable.","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr_stop.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop with a fun, themed error message — couplr_stop","title":"Stop with a fun, themed error message — couplr_stop","text":"Stop fun, themed error message","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr_stop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop with a fun, themed error message — couplr_stop","text":"","code":"couplr_stop(..., call. = FALSE)"},{"path":"https://gcol33.github.io/couplr/reference/couplr_success.html","id":null,"dir":"Reference","previous_headings":"","what":"Success message with emoji — couplr_success","title":"Success message with emoji — couplr_success","text":"Success message emoji","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr_success.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Success message with emoji — couplr_success","text":"","code":"couplr_success(...)"},{"path":"https://gcol33.github.io/couplr/reference/couplr_warn.html","id":null,"dir":"Reference","previous_headings":"","what":"Warn with a fun, themed warning message — couplr_warn","title":"Warn with a fun, themed warning message — couplr_warn","text":"Warn fun, themed warning message","code":""},{"path":"https://gcol33.github.io/couplr/reference/couplr_warn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warn with a fun, themed warning message — couplr_warn","text":"","code":"couplr_warn(..., call. = FALSE)"},{"path":"https://gcol33.github.io/couplr/reference/detect_blocking.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect and validate blocking — detect_blocking","title":"Detect and validate blocking — detect_blocking","text":"Detect validate blocking","code":""},{"path":"https://gcol33.github.io/couplr/reference/detect_blocking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect and validate blocking — detect_blocking","text":"","code":"detect_blocking(left, right, block_id, ignore_blocks)"},{"path":"https://gcol33.github.io/couplr/reference/diagnose_distance_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnose distance matrix and suggest fixes — diagnose_distance_matrix","title":"Diagnose distance matrix and suggest fixes — diagnose_distance_matrix","text":"Comprehensive diagnostics distance matrix actionable suggestions.","code":""},{"path":"https://gcol33.github.io/couplr/reference/diagnose_distance_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagnose distance matrix and suggest fixes — diagnose_distance_matrix","text":"","code":"diagnose_distance_matrix(   cost_matrix,   left = NULL,   right = NULL,   vars = NULL,   warn = TRUE )"},{"path":"https://gcol33.github.io/couplr/reference/diagnose_distance_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagnose distance matrix and suggest fixes — diagnose_distance_matrix","text":"cost_matrix Numeric matrix distances left Left dataset (variable checking) right Right dataset (variable checking) vars Variables used matching warn TRUE, issue warnings","code":""},{"path":"https://gcol33.github.io/couplr/reference/diagnose_distance_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diagnose distance matrix and suggest fixes — diagnose_distance_matrix","text":"List diagnostic results suggestions","code":""},{"path":"https://gcol33.github.io/couplr/reference/err_invalid_param.html","id":null,"dir":"Reference","previous_headings":"","what":"Invalid parameter error — err_invalid_param","title":"Invalid parameter error — err_invalid_param","text":"Invalid parameter error","code":""},{"path":"https://gcol33.github.io/couplr/reference/err_invalid_param.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Invalid parameter error — err_invalid_param","text":"","code":"err_invalid_param(param, value, expected)"},{"path":"https://gcol33.github.io/couplr/reference/err_missing_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing data error — err_missing_data","title":"Missing data error — err_missing_data","text":"Missing data error","code":""},{"path":"https://gcol33.github.io/couplr/reference/err_missing_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Missing data error — err_missing_data","text":"","code":"err_missing_data(dataset = \"left\")"},{"path":"https://gcol33.github.io/couplr/reference/err_missing_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing variables error — err_missing_vars","title":"Missing variables error — err_missing_vars","text":"Missing variables error","code":""},{"path":"https://gcol33.github.io/couplr/reference/err_missing_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Missing variables error — err_missing_vars","text":"","code":"err_missing_vars(vars, dataset = \"left\")"},{"path":"https://gcol33.github.io/couplr/reference/err_no_valid_pairs.html","id":null,"dir":"Reference","previous_headings":"","what":"All pairs forbidden error — err_no_valid_pairs","title":"All pairs forbidden error — err_no_valid_pairs","text":"pairs forbidden error","code":""},{"path":"https://gcol33.github.io/couplr/reference/err_no_valid_pairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"All pairs forbidden error — err_no_valid_pairs","text":"","code":"err_no_valid_pairs(reason = NULL)"},{"path":"https://gcol33.github.io/couplr/reference/example_costs.html","id":null,"dir":"Reference","previous_headings":"","what":"Example cost matrices for assignment problems — example_costs","title":"Example cost matrices for assignment problems — example_costs","text":"Small example datasets demonstrating assignR functionality","code":""},{"path":"https://gcol33.github.io/couplr/reference/example_costs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example cost matrices for assignment problems — example_costs","text":"","code":"example_costs"},{"path":"https://gcol33.github.io/couplr/reference/example_costs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example cost matrices for assignment problems — example_costs","text":"list containing several example cost matrices: simple_3x3 simple 3x3 cost matrix rectangular_3x5 3x5 rectangular cost matrix sparse_with_na matrix NA values indicating forbidden assignments binary_costs matrix binary (0/1) costs","code":""},{"path":"https://gcol33.github.io/couplr/reference/example_costs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example cost matrices for assignment problems — example_costs","text":"","code":"# Use simple example lap_solve(example_costs$simple_3x3) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      2     2 #> 2      2      1     3 #> 3      3      3     4 #>  #> Total cost: 9  #> Method: bruteforce   # Rectangular problem lap_solve(example_costs$rectangular_3x5) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      1     1 #> 2      2      5     2 #> 3      3      2     3 #>  #> Total cost: 6  #> Method: bruteforce   # With forbidden assignments lap_solve(example_costs$sparse_with_na) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      2     2 #> 2      2      1     3 #> 3      3      3     4 #>  #> Total cost: 9  #> Method: bruteforce"},{"path":"https://gcol33.github.io/couplr/reference/example_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Example assignment problem data frame — example_df","title":"Example assignment problem data frame — example_df","text":"tidy data frame representation assignment problems, suitable use grouped workflows.","code":""},{"path":"https://gcol33.github.io/couplr/reference/example_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example assignment problem data frame — example_df","text":"","code":"example_df"},{"path":"https://gcol33.github.io/couplr/reference/example_df.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example assignment problem data frame — example_df","text":"tibble 18 rows 4 columns: sim Simulation/problem identifier (1 2) source Source node index (1, 2, 3) target Target node index (1, 2, 3) cost Cost assignment","code":""},{"path":"https://gcol33.github.io/couplr/reference/example_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example assignment problem data frame — example_df","text":"","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  # Solve both problems example_df |>   group_by(sim) |>   lap_solve(source, target, cost) #> # A tibble: 6 × 4 #>     sim source target  cost #>   <int>  <int>  <int> <dbl> #> 1     1      1      2     3 #> 2     1      2      1     2 #> 3     1      3      3     4 #> 4     2      1      1     1 #> 5     2      2      2     3 #> 6     2      3      3     1  # Or use batch solving example_df |>   group_by(sim) |>   lap_solve_batch(source, target, cost) #> Batch Assignment Results #> ======================== #>  #>  #> # A tibble: 6 × 6 #>     sim source target  cost total_cost method_used #>   <int>  <int>  <int> <dbl>      <dbl> <chr>       #> 1     1      1      2     3          9 bruteforce  #> 2     1      2      1     2          9 bruteforce  #> 3     1      3      3     4          9 bruteforce  #> 4     2      1      1     1          5 bruteforce  #> 5     2      2      2     3          5 bruteforce  #> 6     2      3      3     1          5 bruteforce"},{"path":"https://gcol33.github.io/couplr/reference/extract_ids.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract and standardize IDs from data frames — extract_ids","title":"Extract and standardize IDs from data frames — extract_ids","text":"Extract standardize IDs data frames","code":""},{"path":"https://gcol33.github.io/couplr/reference/extract_ids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract and standardize IDs from data frames — extract_ids","text":"","code":"extract_ids(df, prefix = \"id\")"},{"path":"https://gcol33.github.io/couplr/reference/extract_matching_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract matching variables from data frame — extract_matching_vars","title":"Extract matching variables from data frame — extract_matching_vars","text":"Extract matching variables data frame","code":""},{"path":"https://gcol33.github.io/couplr/reference/extract_matching_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract matching variables from data frame — extract_matching_vars","text":"","code":"extract_matching_vars(df, vars)"},{"path":"https://gcol33.github.io/couplr/reference/filter_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter blocks based on size and balance criteria — filter_blocks","title":"Filter blocks based on size and balance criteria — filter_blocks","text":"Filter blocks based size balance criteria","code":""},{"path":"https://gcol33.github.io/couplr/reference/filter_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter blocks based on size and balance criteria — filter_blocks","text":"","code":"filter_blocks(   left,   right,   min_left,   min_right,   drop_imbalanced,   imbalance_threshold )"},{"path":"https://gcol33.github.io/couplr/reference/get_block_id_column.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize block ID column name — get_block_id_column","title":"Standardize block ID column name — get_block_id_column","text":"Standardize block ID column name","code":""},{"path":"https://gcol33.github.io/couplr/reference/get_block_id_column.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize block ID column name — get_block_id_column","text":"","code":"get_block_id_column(df)"},{"path":"https://gcol33.github.io/couplr/reference/get_method_used.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract method used from assignment result — get_method_used","title":"Extract method used from assignment result — get_method_used","text":"Extract method used assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/get_method_used.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract method used from assignment result — get_method_used","text":"","code":"get_method_used(x)"},{"path":"https://gcol33.github.io/couplr/reference/get_method_used.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract method used from assignment result — get_method_used","text":"x assignment result object","code":""},{"path":"https://gcol33.github.io/couplr/reference/get_method_used.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract method used from assignment result — get_method_used","text":"Character string indicating method used","code":""},{"path":"https://gcol33.github.io/couplr/reference/get_total_cost.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract total cost from assignment result — get_total_cost","title":"Extract total cost from assignment result — get_total_cost","text":"Extract total cost assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/get_total_cost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract total cost from assignment result — get_total_cost","text":"","code":"get_total_cost(x)"},{"path":"https://gcol33.github.io/couplr/reference/get_total_cost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract total cost from assignment result — get_total_cost","text":"x assignment result object","code":""},{"path":"https://gcol33.github.io/couplr/reference/get_total_cost.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract total cost from assignment result — get_total_cost","text":"Numeric total cost","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_blocks_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Greedy match blocks in parallel — greedy_blocks_parallel","title":"Greedy match blocks in parallel — greedy_blocks_parallel","text":"Greedy match blocks parallel","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_blocks_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Greedy match blocks in parallel — greedy_blocks_parallel","text":"","code":"greedy_blocks_parallel(   blocks,   left,   right,   left_ids,   right_ids,   block_col,   vars,   distance,   weights,   scale,   max_distance,   calipers,   strategy,   parallel = FALSE )"},{"path":"https://gcol33.github.io/couplr/reference/greedy_blocks_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Greedy match blocks in parallel — greedy_blocks_parallel","text":"blocks Vector block IDs left Left dataset block_col right Right dataset block_col left_ids IDs left right_ids IDs right block_col Name blocking column vars Variables matching distance Distance metric weights Variable weights scale Scaling method max_distance Maximum distance calipers Caliper constraints strategy Greedy strategy parallel Whether use parallel processing","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_blocks_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Greedy match blocks in parallel — greedy_blocks_parallel","text":"List combined results blocks","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast approximate matching using greedy algorithm — greedy_couples","title":"Fast approximate matching using greedy algorithm — greedy_couples","text":"Performs fast one--one matching using greedy strategies. guarantee optimal total distance much faster match_couples() large datasets. Supports blocking, distance constraints, various distance metrics.","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast approximate matching using greedy algorithm — greedy_couples","text":"","code":"greedy_couples(   left,   right = NULL,   vars = NULL,   distance = \"euclidean\",   weights = NULL,   scale = FALSE,   auto_scale = FALSE,   max_distance = Inf,   calipers = NULL,   block_id = NULL,   ignore_blocks = FALSE,   require_full_matching = FALSE,   strategy = c(\"row_best\", \"sorted\", \"pq\"),   return_unmatched = TRUE,   return_diagnostics = FALSE,   parallel = FALSE,   check_costs = TRUE )"},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast approximate matching using greedy algorithm — greedy_couples","text":"left Data frame \"left\" units (e.g., treated, cases) right Data frame \"right\" units (e.g., control, controls) vars Variable names use distance computation distance Distance metric: \"euclidean\", \"manhattan\", \"mahalanobis\", custom function weights Optional named vector variable weights scale Scaling method: FALSE (none), \"standardize\", \"range\", \"robust\" auto_scale TRUE, automatically check variable health select scaling method (default: FALSE) max_distance Maximum allowed distance (pairs exceeding forbidden) calipers Named list per-variable maximum absolute differences block_id Column name containing block IDs (stratified matching) ignore_blocks TRUE, ignore block_id even present require_full_matching TRUE, error units remain unmatched strategy Greedy strategy: \"row_best\": row, find best available column (default) \"sorted\": Sort pairs distance, greedily assign \"pq\": Use priority queue (good large problems) return_unmatched Include unmatched units output return_diagnostics Include detailed diagnostics output parallel Enable parallel processing blocked matching. Requires 'future' 'future.apply' packages. Can : FALSE: Sequential processing (default) TRUE: Auto-configure parallel backend Character: Specify future plan (e.g., \"multisession\", \"multicore\") check_costs TRUE, check distance distribution potential problems provide helpful warnings matching (default: TRUE)","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast approximate matching using greedy algorithm — greedy_couples","text":"list class \"matching_result\" (structure match_couples)","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fast approximate matching using greedy algorithm — greedy_couples","text":"Greedy strategies guarantee optimal total distance much faster: \"row_best\": O(n*m) time, simple often produces good results \"sorted\": O(nmlog(n*m)) time, better quality slower \"pq\": O(nmlog(n*m)) time, memory-efficient large problems Use greedy_couples : Dataset large (> 10,000 x 10,000) Approximate solution acceptable Speed important optimality","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fast approximate matching using greedy algorithm — greedy_couples","text":"","code":"# Basic greedy matching left <- data.frame(id = 1:100, x = rnorm(100)) right <- data.frame(id = 101:200, x = rnorm(100)) result <- greedy_couples(left, right, vars = \"x\")  # Compare to optimal result_opt <- match_couples(left, right, vars = \"x\") result_greedy <- greedy_couples(left, right, vars = \"x\") result_greedy$info$total_distance / result_opt$info$total_distance  # Quality ratio #> [1] 1.617414"},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples_blocked.html","id":null,"dir":"Reference","previous_headings":"","what":"Greedy matching with blocking — greedy_couples_blocked","title":"Greedy matching with blocking — greedy_couples_blocked","text":"Greedy matching blocking","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples_blocked.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Greedy matching with blocking — greedy_couples_blocked","text":"","code":"greedy_couples_blocked(   left,   right,   left_ids,   right_ids,   block_col,   vars,   distance,   weights,   scale,   max_distance,   calipers,   strategy,   parallel = FALSE )"},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples_from_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Greedy Matching from Precomputed Distance Object — greedy_couples_from_distance","title":"Greedy Matching from Precomputed Distance Object — greedy_couples_from_distance","text":"Internal function handle greedy matching distance_object provided","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples_from_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Greedy Matching from Precomputed Distance Object — greedy_couples_from_distance","text":"","code":"greedy_couples_from_distance(   dist_obj,   max_distance = Inf,   calipers = NULL,   ignore_blocks = FALSE,   require_full_matching = FALSE,   strategy = \"row_best\",   return_unmatched = TRUE,   return_diagnostics = FALSE )"},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Greedy matching without blocking — greedy_couples_single","title":"Greedy matching without blocking — greedy_couples_single","text":"Greedy matching without blocking","code":""},{"path":"https://gcol33.github.io/couplr/reference/greedy_couples_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Greedy matching without blocking — greedy_couples_single","text":"","code":"greedy_couples_single(   left,   right,   left_ids,   right_ids,   vars,   distance,   weights,   scale,   max_distance,   calipers,   strategy )"},{"path":"https://gcol33.github.io/couplr/reference/group_by.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-export of dplyr::group_by — group_by","title":"Re-export of dplyr::group_by — group_by","text":"Re-export dplyr::group_by","code":""},{"path":"https://gcol33.github.io/couplr/reference/has_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if data frame has blocking information — has_blocks","title":"Check if data frame has blocking information — has_blocks","text":"Check data frame blocking information","code":""},{"path":"https://gcol33.github.io/couplr/reference/has_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if data frame has blocking information — has_blocks","text":"","code":"has_blocks(df)"},{"path":"https://gcol33.github.io/couplr/reference/has_valid_pairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if any valid pairs exist — has_valid_pairs","title":"Check if any valid pairs exist — has_valid_pairs","text":"Check valid pairs exist","code":""},{"path":"https://gcol33.github.io/couplr/reference/has_valid_pairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if any valid pairs exist — has_valid_pairs","text":"","code":"has_valid_pairs(cost_matrix)"},{"path":"https://gcol33.github.io/couplr/reference/hospital_staff.html","id":null,"dir":"Reference","previous_headings":"","what":"Hospital staff scheduling example dataset — hospital_staff","title":"Hospital staff scheduling example dataset — hospital_staff","text":"comprehensive example dataset demonstrating couplr functionality across vignettes. Contains hospital staff scheduling data nurses, shifts, costs, preference scores suitable assignment problems, well nurse characteristics matching workflows.","code":""},{"path":"https://gcol33.github.io/couplr/reference/hospital_staff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hospital staff scheduling example dataset — hospital_staff","text":"","code":"hospital_staff"},{"path":"https://gcol33.github.io/couplr/reference/hospital_staff.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hospital staff scheduling example dataset — hospital_staff","text":"list containing several related datasets: basic_costs 10x10 cost matrix assigning 10 nurses 10 shifts. Lower values indicate better fit (less overtime, matches skills). preferences 10x10 preference matrix (0-10 scale, higher = preferred). Use maximize = TRUE. schedule_df tibble 100 rows (10 nurses x 10 shifts) containing: nurse_id Nurse identifier (1-10) shift_id Shift identifier (1-10) cost Assignment cost preference Nurse preference score (0-10) skill_match Whether nurse skills match shift needs (0/1) nurses tibble 10 rows describing nurse characteristics: nurse_id Nurse identifier (1-10) experience_years Years experience (1-20) department Primary department (ICU, ER, General, Pediatrics) shift_preference Preferred shift type (day, evening, night) certification_level Certification level (1-3) shifts tibble 10 rows describing shift requirements: shift_id Shift identifier (1-10) department Department needing coverage shift_type Shift type (day, evening, night) min_experience Minimum years experience required min_certification Minimum certification level required weekly_df tibble batch solving: 5 days x 10 nurses x 10 shifts. Contains columns: day, nurse_id, shift_id, cost, preference. nurses_extended tibble 200 nurses matching examples. Contains: nurse_id, age, experience_years, hourly_rate, department, certification_level, is_fulltime. controls_extended tibble 300 potential control nurses matching examples. structure nurses_extended.","code":""},{"path":"https://gcol33.github.io/couplr/reference/hospital_staff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hospital staff scheduling example dataset — hospital_staff","text":"dataset used throughout couplr documentation provide consistent, realistic example evolves complexity. dataset designed demonstrate progressively complex scenarios: Basic LAP (vignette(\"getting-started\")): basic_costs: Simple 10x10 assignment preferences: Maximization problem schedule_df: Data frame input, grouped workflows weekly_df: Batch solving across days Algorithm comparison (vignette(\"algorithms\")): Use basic_costs compare algorithm behavior Modify NA values sparse scenarios Matching workflows (vignette(\"matching-workflows\")): nurses_extended: Treatment group (full-time nurses) controls_extended: Control pool (part-time/registry nurses) Match age, experience, department causal analysis","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/reference/hospital_staff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hospital staff scheduling example dataset — hospital_staff","text":"","code":"# Basic assignment: assign nurses to shifts minimizing cost lap_solve(hospital_staff$basic_costs) #> Assignment Result #> ================= #>  #> # A tibble: 10 × 3 #>    source target  cost #>     <int>  <int> <dbl> #>  1      1      8     2 #>  2      2      2     2 #>  3      3      7     2 #>  4      4      4     2 #>  5      5      9     2 #>  6      6     10     3 #>  7      7      1     2 #>  8      8      3     2 #>  9      9      6     3 #> 10     10      5     2 #>  #> Total cost: 22  #> Method: hungarian   # Maximize preferences instead lap_solve(hospital_staff$preferences, maximize = TRUE) #> Assignment Result #> ================= #>  #> # A tibble: 10 × 3 #>    source target  cost #>     <int>  <int> <dbl> #>  1      1      8     9 #>  2      2      2     9 #>  3      3      7     9 #>  4      4      4     9 #>  5      5      9     9 #>  6      6     10     8 #>  7      7      1     9 #>  8      8      3     9 #>  9      9      6     8 #> 10     10      5     9 #>  #> Total cost: 88  #> Method: hungarian   # Data frame workflow library(dplyr) hospital_staff$schedule_df |>   lap_solve(nurse_id, shift_id, cost) #> Assignment Result #> ================= #>  #> # A tibble: 10 × 3 #>    source target  cost #>     <int>  <int> <dbl> #>  1      1      8     2 #>  2      2      2     2 #>  3      3      7     2 #>  4      4      4     2 #>  5      5      9     2 #>  6      6     10     3 #>  7      7      1     2 #>  8      8      3     2 #>  9      9      6     3 #> 10     10      5     2 #>  #> Total cost: 22  #> Method: hungarian   # Batch solve weekly schedule hospital_staff$weekly_df |>   group_by(day) |>   lap_solve(nurse_id, shift_id, cost) #> # A tibble: 50 × 4 #>    day    source target  cost #>    <fct>   <int>  <int> <dbl> #>  1 Monday      1      1     2 #>  2 Monday      2      9     2 #>  3 Monday      3      3     1 #>  4 Monday      4      4     0 #>  5 Monday      5      5     2 #>  6 Monday      6      6     1 #>  7 Monday      7      8     4 #>  8 Monday      8     10     1 #>  9 Monday      9      2     4 #> 10 Monday     10      7     1 #> # ℹ 40 more rows  # Matching workflow: match full-time to part-time nurses match_couples(   left = hospital_staff$nurses_extended,   right = hospital_staff$controls_extended,   vars = c(\"age\", \"experience_years\", \"certification_level\"),   auto_scale = TRUE ) #> Auto-selected scaling method: standardize #> Matching Result #> =============== #>  #> Method: lap  #> Pairs matched: 200  #> Unmatched (left): 0  #> Unmatched (right): 100  #> Total distance: 59.9496  #>  #> Matched pairs: #> # A tibble: 200 × 6 #>    left_id right_id  distance .age_diff .experience_years_diff #>    <chr>   <chr>        <dbl>     <dbl>                  <dbl> #>  1 left_1  right_60     0.217        -1                      1 #>  2 left_2  right_94     0.175         2                      0 #>  3 left_3  right_12     0             0                      0 #>  4 left_4  right_253    0.530        -4                      2 #>  5 left_5  right_262    0.481        -5                      1 #>  6 left_6  right_73     0             0                      0 #>  7 left_7  right_296    0.199         0                      1 #>  8 left_8  right_92     0.262         3                      0 #>  9 left_9  right_151    0.477        -3                      2 #> 10 left_10 right_247    0             0                      0 #> # ℹ 190 more rows #> # ℹ 1 more variable: .certification_level_diff <int>"},{"path":"https://gcol33.github.io/couplr/reference/info_low_match_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Low match rate info — info_low_match_rate","title":"Low match rate info — info_low_match_rate","text":"Low match rate info","code":""},{"path":"https://gcol33.github.io/couplr/reference/info_low_match_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Low match rate info — info_low_match_rate","text":"","code":"info_low_match_rate(n_matched, n_left, pct)"},{"path":"https://gcol33.github.io/couplr/reference/is_distance_object.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if Object is a Distance Object — is_distance_object","title":"Check if Object is a Distance Object — is_distance_object","text":"Check Object Distance Object","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_distance_object.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if Object is a Distance Object — is_distance_object","text":"","code":"is_distance_object(x)"},{"path":"https://gcol33.github.io/couplr/reference/is_distance_object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if Object is a Distance Object — is_distance_object","text":"x Object check","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_distance_object.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if Object is a Distance Object — is_distance_object","text":"Logical: TRUE x distance_object","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_distance_object.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if Object is a Distance Object — is_distance_object","text":"","code":"left <- data.frame(id = 1:3, x = c(1, 2, 3)) right <- data.frame(id = 4:6, x = c(1.1, 2.1, 3.1)) dist_obj <- compute_distances(left, right, vars = \"x\") is_distance_object(dist_obj)  # TRUE #> [1] TRUE is_distance_object(list())    # FALSE #> [1] FALSE"},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_batch_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is a batch assignment result — is_lap_solve_batch_result","title":"Check if object is a batch assignment result — is_lap_solve_batch_result","text":"Check object batch assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_batch_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is a batch assignment result — is_lap_solve_batch_result","text":"","code":"is_lap_solve_batch_result(x)"},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_batch_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is a batch assignment result — is_lap_solve_batch_result","text":"x Object test","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_batch_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is a batch assignment result — is_lap_solve_batch_result","text":"Logical indicating x batch assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_kbest_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is a k-best assignment result — is_lap_solve_kbest_result","title":"Check if object is a k-best assignment result — is_lap_solve_kbest_result","text":"Check object k-best assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_kbest_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is a k-best assignment result — is_lap_solve_kbest_result","text":"","code":"is_lap_solve_kbest_result(x)"},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_kbest_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is a k-best assignment result — is_lap_solve_kbest_result","text":"x Object test","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_kbest_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is a k-best assignment result — is_lap_solve_kbest_result","text":"Logical indicating x k-best assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is an assignment result — is_lap_solve_result","title":"Check if object is an assignment result — is_lap_solve_result","text":"Check object assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is an assignment result — is_lap_solve_result","text":"","code":"is_lap_solve_result(x)"},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is an assignment result — is_lap_solve_result","text":"x Object test","code":""},{"path":"https://gcol33.github.io/couplr/reference/is_lap_solve_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is an assignment result — is_lap_solve_result","text":"Logical indicating x assignment result","code":""},{"path":"https://gcol33.github.io/couplr/reference/join_matched.html","id":null,"dir":"Reference","previous_headings":"","what":"Join Matched Pairs with Original Data — join_matched","title":"Join Matched Pairs with Original Data — join_matched","text":"Creates analysis-ready dataset joining matched pairs variables original left right datasets. eliminates need manual joins provides convenient format downstream analysis.","code":""},{"path":"https://gcol33.github.io/couplr/reference/join_matched.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join Matched Pairs with Original Data — join_matched","text":"","code":"join_matched(   result,   left,   right,   left_vars = NULL,   right_vars = NULL,   left_id = \"id\",   right_id = \"id\",   suffix = c(\"_left\", \"_right\"),   include_distance = TRUE,   include_pair_id = TRUE,   include_block_id = TRUE )"},{"path":"https://gcol33.github.io/couplr/reference/join_matched.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join Matched Pairs with Original Data — join_matched","text":"result matching_result object match_couples() greedy_couples() left original left dataset right original right dataset left_vars Character vector variable names include left. NULL (default), includes variables except ID column. right_vars Character vector variable names include right. NULL (default), includes variables except ID column. left_id Name ID column left dataset (default: \"id\") right_id Name ID column right dataset (default: \"id\") suffix Character vector length 2 specifying suffixes left right variables (default: c(\"_left\", \"_right\")) include_distance Include matching distance output (default: TRUE) include_pair_id Include pair_id column (default: TRUE) include_block_id Include block_id blocking used (default: TRUE)","code":""},{"path":"https://gcol33.github.io/couplr/reference/join_matched.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join Matched Pairs with Original Data — join_matched","text":"tibble one row per matched pair, containing: pair_id: Sequential pair identifier (include_pair_id = TRUE) left_id: ID left dataset right_id: ID right dataset distance: Matching distance (include_distance = TRUE) block_id: Block identifier (blocking used include_block_id = TRUE) Variables left dataset (left suffix) Variables right dataset (right suffix)","code":""},{"path":"https://gcol33.github.io/couplr/reference/join_matched.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Join Matched Pairs with Original Data — join_matched","text":"function simplifies common workflow joining matched pairs original data. Instead manually merging result$pairs left right datasets, join_matched() handles joins automatically applies consistent naming conventions. variables appear left right datasets, suffixes appended distinguish (e.g., \"age_left\" \"age_right\"). makes easy compute differences use values models.","code":""},{"path":"https://gcol33.github.io/couplr/reference/join_matched.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Join Matched Pairs with Original Data — join_matched","text":"","code":"# Basic usage left <- data.frame(   id = 1:5,   treatment = 1,   age = c(25, 30, 35, 40, 45),   income = c(45000, 52000, 48000, 61000, 55000) )  right <- data.frame(   id = 6:10,   treatment = 0,   age = c(24, 29, 36, 41, 44),   income = c(46000, 51500, 47500, 60000, 54000) )  result <- match_couples(left, right, vars = c(\"age\", \"income\")) matched_data <- join_matched(result, left, right) head(matched_data) #> # A tibble: 5 × 12 #>   pair_id left_id right_id distance .age_diff .income_diff treatment_left #>     <int>   <int>    <int>    <dbl>     <dbl>        <dbl>          <dbl> #> 1       1       1        6    1000.         1        -1000              1 #> 2       2       2        7     500.         1          500              1 #> 3       3       3        8     500.        -1          500              1 #> 4       4       4        9    1000.        -1         1000              1 #> 5       5       5       10    1000.         1         1000              1 #> # ℹ 5 more variables: age_left <dbl>, income_left <dbl>, treatment_right <dbl>, #> #   age_right <dbl>, income_right <dbl>  # Specify which variables to include matched_data <- join_matched(   result, left, right,   left_vars = c(\"treatment\", \"age\", \"income\"),   right_vars = c(\"age\", \"income\"),   suffix = c(\"_treated\", \"_control\") )  # Without distance or pair_id matched_data <- join_matched(   result, left, right,   include_distance = FALSE,   include_pair_id = FALSE )"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve linear assignment problems — lap_solve","title":"Solve linear assignment problems — lap_solve","text":"Provides tidy interface solving linear assignment problem using Hungarian Jonker-Volgenant algorithms. Supports rectangular matrices, NA/Inf masking, data frame inputs.","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve linear assignment problems — lap_solve","text":"","code":"lap_solve(   x,   source = NULL,   target = NULL,   cost = NULL,   maximize = FALSE,   method = \"auto\",   forbidden = NA )"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve linear assignment problems — lap_solve","text":"x Cost matrix, data frame, tibble. data frame/tibble, must include columns specified source, target, cost. source Column name source/row indices (x data frame) target Column name target/column indices (x data frame) cost Column name costs (x data frame) maximize Logical; TRUE, maximizes total cost instead minimizing (default: FALSE) method Algorithm use. One : \"auto\" (default): automatically selects best algorithm \"jv\": Jonker-Volgenant algorithm (general purpose, fast) \"hungarian\": Classic Hungarian algorithm \"auction\": Auction algorithm (good large dense problems) \"sap\": Sparse assignment (good sparse/rectangular problems) \"hk01\": Hopcroft-Karp binary/uniform costs forbidden Value mark forbidden assignments (default: NA). Can also use Inf.","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve linear assignment problems — lap_solve","text":"tibble columns: source: row/source indices target: column/target indices cost: cost assignment total_cost: total cost (attribute)","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve linear assignment problems — lap_solve","text":"","code":"# Matrix input cost <- matrix(c(4, 2, 5, 3, 3, 6, 7, 5, 4), nrow = 3) lap_solve(cost) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      2     3 #> 2      2      1     2 #> 3      3      3     4 #>  #> Total cost: 9  #> Method: bruteforce   # Data frame input library(dplyr) df <- tibble(   source = rep(1:3, each = 3),   target = rep(1:3, times = 3),   cost = c(4, 2, 5, 3, 3, 6, 7, 5, 4) ) lap_solve(df, source, target, cost) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      2     2 #> 2      2      1     3 #> 3      3      3     4 #>  #> Total cost: 9  #> Method: bruteforce   # With NA masking (forbidden assignments) cost[1, 3] <- NA lap_solve(cost) #> Assignment Result #> ================= #>  #> # A tibble: 3 × 3 #>   source target  cost #>    <int>  <int> <dbl> #> 1      1      2     3 #> 2      2      1     2 #> 3      3      3     4 #>  #> Total cost: 9  #> Method: bruteforce   # Grouped data frames df <- tibble(   sim = rep(1:2, each = 9),   source = rep(1:3, times = 6),   target = rep(1:3, each = 3, times = 2),   cost = runif(18, 1, 10) ) df |> group_by(sim) |> lap_solve(source, target, cost) #> # A tibble: 6 × 4 #>     sim source target  cost #>   <int>  <int>  <int> <dbl> #> 1     1      1      1  4.30 #> 2     1      2      2  1.92 #> 3     1      3      3  5.77 #> 4     2      1      1  3.33 #> 5     2      2      3  8.44 #> 6     2      3      2  1.66"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve multiple assignment problems efficiently — lap_solve_batch","title":"Solve multiple assignment problems efficiently — lap_solve_batch","text":"Solve many independent assignment problems . Supports lists matrices, 3D arrays, grouped data frames. Optional parallel execution via n_threads.","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve multiple assignment problems efficiently — lap_solve_batch","text":"","code":"lap_solve_batch(   x,   source = NULL,   target = NULL,   cost = NULL,   maximize = FALSE,   method = \"auto\",   n_threads = 1,   forbidden = NA )"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve multiple assignment problems efficiently — lap_solve_batch","text":"x One : List cost matrices, 3D array, grouped data frame source Column name source indices (x grouped data frame) target Column name target indices (x grouped data frame) cost Column name costs (x grouped data frame) maximize Logical; TRUE, maximizes total cost (default: FALSE) method Algorithm use (default: \"auto\"). See lap_solve options. n_threads Number threads parallel execution (default: 1). Set NULL use available cores. forbidden Value mark forbidden assignments (default: NA)","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve multiple assignment problems efficiently — lap_solve_batch","text":"tibble columns: problem_id: identifier problem source: source indices assignments target: target indices assignments cost: cost assignment total_cost: total cost problem method_used: algorithm used problem","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve multiple assignment problems efficiently — lap_solve_batch","text":"","code":"# List of matrices costs <- list(   matrix(c(1, 2, 3, 4), 2, 2),   matrix(c(5, 6, 7, 8), 2, 2) ) lap_solve_batch(costs) #> Batch Assignment Results #> ======================== #>  #> Number of problems solved: 2  #> Total cost range: [5.00, 13.00]  #>  #> # A tibble: 4 × 6 #>   problem_id source target  cost total_cost method_used #>        <int>  <int>  <int> <dbl>      <dbl> <chr>       #> 1          1      1      1     1          5 bruteforce  #> 2          1      2      2     4          5 bruteforce  #> 3          2      1      1     5         13 bruteforce  #> 4          2      2      2     8         13 bruteforce   # 3D array arr <- array(runif(2 * 2 * 10), dim = c(2, 2, 10)) lap_solve_batch(arr) #> Batch Assignment Results #> ======================== #>  #> Number of problems solved: 10  #> Total cost range: [0.33, 1.15]  #>  #> # A tibble: 20 × 6 #>    problem_id source target   cost total_cost method_used #>         <int>  <int>  <int>  <dbl>      <dbl> <chr>       #>  1          1      1      2 0.516       0.615 bruteforce  #>  2          1      2      1 0.0986      0.615 bruteforce  #>  3          2      1      2 0.159       0.809 bruteforce  #>  4          2      2      1 0.650       0.809 bruteforce  #>  5          3      1      1 0.891       1.15  bruteforce  #>  6          3      2      2 0.260       1.15  bruteforce  #>  7          4      1      1 0.318       0.329 bruteforce  #>  8          4      2      2 0.0109      0.329 bruteforce  #>  9          5      1      1 0.0631      0.361 bruteforce  #> 10          5      2      2 0.298       0.361 bruteforce  #> 11          6      1      1 0.0946      0.497 bruteforce  #> 12          6      2      2 0.402       0.497 bruteforce  #> 13          7      1      1 0.0591      0.335 bruteforce  #> 14          7      2      2 0.276       0.335 bruteforce  #> 15          8      1      2 0.199       0.743 bruteforce  #> 16          8      2      1 0.544       0.743 bruteforce  #> 17          9      1      2 0.876       1.15  bruteforce  #> 18          9      2      1 0.271       1.15  bruteforce  #> 19         10      1      2 0.183       0.564 bruteforce  #> 20         10      2      1 0.381       0.564 bruteforce   # Grouped data frame library(dplyr) df <- tibble(   sim = rep(1:5, each = 9),   source = rep(1:3, times = 15),   target = rep(1:3, each = 3, times = 5),   cost = runif(45, 1, 10) ) df |> group_by(sim) |> lap_solve_batch(source, target, cost) #> Batch Assignment Results #> ======================== #>  #>  #> # A tibble: 15 × 6 #>      sim source target  cost total_cost method_used #>    <int>  <int>  <int> <dbl>      <dbl> <chr>       #>  1     1      1      3  1.69       8.95 bruteforce  #>  2     1      2      1  2.74       8.95 bruteforce  #>  3     1      3      2  4.52       8.95 bruteforce  #>  4     2      1      2  5.22      13.9  bruteforce  #>  5     2      2      1  5.51      13.9  bruteforce  #>  6     2      3      3  3.18      13.9  bruteforce  #>  7     3      1      3  3.03       8.85 bruteforce  #>  8     3      2      2  2.05       8.85 bruteforce  #>  9     3      3      1  3.77       8.85 bruteforce  #> 10     4      1      3  1.91       8.59 bruteforce  #> 11     4      2      1  2.83       8.59 bruteforce  #> 12     4      3      2  3.84       8.59 bruteforce  #> 13     5      1      3  5.46       9.56 bruteforce  #> 14     5      2      1  1.24       9.56 bruteforce  #> 15     5      3      2  2.85       9.56 bruteforce   # Parallel execution (requires n_threads > 1) lap_solve_batch(costs, n_threads = 2) #> Batch Assignment Results #> ======================== #>  #> Number of problems solved: 2  #> Total cost range: [5.00, 13.00]  #>  #> # A tibble: 4 × 6 #>   problem_id source target  cost total_cost method_used #>        <int>  <int>  <int> <dbl>      <dbl> <chr>       #> 1          1      1      1     1          5 bruteforce  #> 2          1      2      2     4          5 bruteforce  #> 3          2      1      1     5         13 bruteforce  #> 4          2      2      2     8         13 bruteforce"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_kbest.html","id":null,"dir":"Reference","previous_headings":"","what":"Find k-best optimal assignments — lap_solve_kbest","title":"Find k-best optimal assignments — lap_solve_kbest","text":"Returns top k optimal (near-optimal) assignments using Murty's algorithm. Useful exploring alternative optimal solutions finding robust assignments.","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_kbest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find k-best optimal assignments — lap_solve_kbest","text":"","code":"lap_solve_kbest(   x,   k = 3,   source = NULL,   target = NULL,   cost = NULL,   maximize = FALSE,   method = \"murty\",   single_method = \"jv\",   forbidden = NA )"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_kbest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find k-best optimal assignments — lap_solve_kbest","text":"x Cost matrix, data frame, tibble. data frame/tibble, must include columns specified source, target, cost. k Number best solutions return (default: 3) source Column name source/row indices (x data frame) target Column name target/column indices (x data frame) cost Column name costs (x data frame) maximize Logical; TRUE, finds k-best maximizing assignments (default: FALSE) method Algorithm sub-problem (default: \"murty\"). Future versions may support additional methods. single_method Algorithm used solving node search tree (default: \"jv\") forbidden Value mark forbidden assignments (default: NA)","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_kbest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find k-best optimal assignments — lap_solve_kbest","text":"tibble columns: rank: ranking solutions (1 = best, 2 = second best, etc.) solution_id: unique identifier solution source: source indices target: target indices cost: cost edge assignment total_cost: total cost complete solution","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_kbest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find k-best optimal assignments — lap_solve_kbest","text":"","code":"# Matrix input - find 5 best solutions cost <- matrix(c(4, 2, 5, 3, 3, 6, 7, 5, 4), nrow = 3) lap_solve_kbest(cost, k = 5) #> K-Best Assignment Results #> ========================= #>  #> Number of solutions: 5  #>  #> Solution costs: #>   Rank 1: 9.0000 #>   Rank 2: 11.0000 #>   Rank 3: 13.0000 #>   Rank 4: 15.0000 #>   Rank 5: 15.0000 #>  #> Assignments: #> # A tibble: 15 × 6 #>     rank solution_id source target  cost total_cost #>    <int>       <int>  <int>  <int> <dbl>      <dbl> #>  1     1           1      1      2     3          9 #>  2     1           1      2      1     2          9 #>  3     1           1      3      3     4          9 #>  4     2           2      1      1     4         11 #>  5     2           2      2      2     3         11 #>  6     2           2      3      3     4         11 #>  7     3           3      1      2     3         13 #>  8     3           3      2      3     5         13 #>  9     3           3      3      1     5         13 #> 10     4           4      1      1     4         15 #> 11     4           4      2      3     5         15 #> 12     4           4      3      2     6         15 #> 13     5           5      1      3     7         15 #> 14     5           5      2      1     2         15 #> 15     5           5      3      2     6         15  # Data frame input library(dplyr) df <- tibble(   source = rep(1:3, each = 3),   target = rep(1:3, times = 3),   cost = c(4, 2, 5, 3, 3, 6, 7, 5, 4) ) lap_solve_kbest(df, k = 3, source, target, cost) #> K-Best Assignment Results #> ========================= #>  #> Number of solutions: 3  #>  #> Solution costs: #>   Rank 1: 9.0000 #>   Rank 2: 11.0000 #>   Rank 3: 13.0000 #>  #> Assignments: #> # A tibble: 9 × 6 #>    rank solution_id source target  cost total_cost #>   <int>       <int>  <int>  <int> <dbl>      <dbl> #> 1     1           1      1      2     2          9 #> 2     1           1      2      1     3          9 #> 3     1           1      3      3     4          9 #> 4     2           2      1      1     4         11 #> 5     2           2      2      2     3         11 #> 6     2           2      3      3     4         11 #> 7     3           3      1      3     5         13 #> 8     3           3      2      1     3         13 #> 9     3           3      3      2     5         13  # With maximization lap_solve_kbest(cost, k = 3, maximize = TRUE) #> K-Best Assignment Results #> ========================= #>  #> Number of solutions: 3  #>  #> Solution costs: #>   Rank 1: 15.0000 #>   Rank 2: 15.0000 #>   Rank 3: 11.0000 #>  #> Assignments: #> # A tibble: 9 × 6 #>    rank solution_id source target  cost total_cost #>   <int>       <int>  <int>  <int> <dbl>      <dbl> #> 1     1           1      1      3     7         15 #> 2     1           1      2      2     3         15 #> 3     1           1      3      1     5         15 #> 4     2           2      1      1     4         15 #> 5     2           2      2      3     5         15 #> 6     2           2      3      2     6         15 #> 7     3           3      1      1     4         11 #> 8     3           3      2      2     3         11 #> 9     3           3      3      3     4         11"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_line_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve 1-D Line Assignment Problem — lap_solve_line_metric","title":"Solve 1-D Line Assignment Problem — lap_solve_line_metric","text":"Solves linear assignment problem sources targets ordered points line. Uses efficient O(n*m) dynamic programming rectangular problems O(n) sorting square problems.","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_line_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve 1-D Line Assignment Problem — lap_solve_line_metric","text":"","code":"lap_solve_line_metric(x, y, cost = \"L1\", maximize = FALSE)"},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_line_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve 1-D Line Assignment Problem — lap_solve_line_metric","text":"x Numeric vector source positions (sorted internally) y Numeric vector target positions (sorted internally) cost Cost function distance. Either: \"L1\" (default): absolute distance (Manhattan distance) \"L2\": squared distance (squared Euclidean distance) Can also use aliases: \"abs\", \"manhattan\" L1; \"sq\", \"squared\", \"quadratic\" L2 maximize Logical; TRUE, maximizes total cost instead minimizing (default: FALSE)","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_line_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve 1-D Line Assignment Problem — lap_solve_line_metric","text":"list components: match: Integer vector length n 1-based column indices total_cost: Total cost assignment","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_line_metric.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solve 1-D Line Assignment Problem — lap_solve_line_metric","text":"specialized solver exploits structure 1-dimensional assignment problems costs depend distance points line. much faster general LAP solvers special case. algorithm works follows: Square case (n == m): vectors sorted matched order: x[1] -> y[1], x[2] -> y[2], etc. optimal metric cost function line. Rectangular case (n < m): Uses dynamic programming find optimal assignment matches n sources subset m targets, minimizing total distance. DP recurrence : dp[][j] = min(dp[][j-1], dp[-1][j-1] + cost(x[], y[j])) finds minimum cost match first sources first j targets. Complexity: Time: O(n*m) rectangular, O(n log n) square Space: O(n*m) DP table","code":""},{"path":"https://gcol33.github.io/couplr/reference/lap_solve_line_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve 1-D Line Assignment Problem — lap_solve_line_metric","text":"","code":"# Square case: equal number of sources and targets x <- c(1.5, 3.2, 5.1) y <- c(2.0, 3.0, 5.5) result <- lap_solve_line_metric(x, y, cost = \"L1\") print(result) #> 1-D Line Assignment Result #> =========================== #>  #> Assignments (1-based): #>   Source 1 -> Target 1 #>   Source 2 -> Target 2 #>   Source 3 -> Target 3 #>  #> Total cost: 1.1   # Rectangular case: more targets than sources x <- c(1.0, 3.0, 5.0) y <- c(0.5, 2.0, 3.5, 4.5, 6.0) result <- lap_solve_line_metric(x, y, cost = \"L2\") print(result) #> 1-D Line Assignment Result #> =========================== #>  #> Assignments (1-based): #>   Source 1 -> Target 1 #>   Source 2 -> Target 3 #>   Source 3 -> Target 4 #>  #> Total cost: 0.75   # With unsorted inputs (will be sorted internally) x <- c(5.0, 1.0, 3.0) y <- c(4.5, 0.5, 6.0, 2.0, 3.5) result <- lap_solve_line_metric(x, y, cost = \"L1\") print(result) #> 1-D Line Assignment Result #> =========================== #>  #> Assignments (1-based): #>   Source 1 -> Target 1 #>   Source 2 -> Target 2 #>   Source 3 -> Target 5 #>  #> Total cost: 1.5"},{"path":"https://gcol33.github.io/couplr/reference/mark_forbidden_pairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Mark forbidden pairs — mark_forbidden_pairs","title":"Mark forbidden pairs — mark_forbidden_pairs","text":"Generic function mark specific pairs forbidden.","code":""},{"path":"https://gcol33.github.io/couplr/reference/mark_forbidden_pairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mark forbidden pairs — mark_forbidden_pairs","text":"","code":"mark_forbidden_pairs(cost_matrix, forbidden_indices)"},{"path":"https://gcol33.github.io/couplr/reference/matchmaker.html","id":null,"dir":"Reference","previous_headings":"","what":"Create blocks for stratified matching — matchmaker","title":"Create blocks for stratified matching — matchmaker","text":"Constructs blocks (strata) matching, using either grouping variables clustering algorithms. Returns input data frames block IDs assigned, along block summary statistics.","code":""},{"path":"https://gcol33.github.io/couplr/reference/matchmaker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create blocks for stratified matching — matchmaker","text":"","code":"matchmaker(   left,   right,   block_type = c(\"none\", \"group\", \"cluster\"),   block_by = NULL,   block_vars = NULL,   block_method = \"kmeans\",   n_blocks = NULL,   min_left = 1,   min_right = 1,   drop_imbalanced = FALSE,   imbalance_threshold = Inf,   return_dropped = TRUE,   ... )"},{"path":"https://gcol33.github.io/couplr/reference/matchmaker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create blocks for stratified matching — matchmaker","text":"left Data frame \"left\" units (e.g., treated, cases) right Data frame \"right\" units (e.g., control, controls) block_type Type blocking use: \"none\": blocking (default) \"group\": Block existing categorical variable(s) \"cluster\": Block using clustering algorithm block_by Variable name(s) grouping (block_type = \"group\") block_vars Variable names clustering (block_type = \"cluster\") block_method Clustering method (block_type = \"cluster\"): \"kmeans\": K-means clustering \"hclust\": Hierarchical clustering n_blocks Target number blocks (clustering) min_left Minimum number left units per block min_right Minimum number right units per block drop_imbalanced Drop blocks extreme imbalance imbalance_threshold Maximum allowed |n_left - n_right| / max(n_left, n_right) return_dropped Include dropped blocks output ... Additional arguments passed clustering function","code":""},{"path":"https://gcol33.github.io/couplr/reference/matchmaker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create blocks for stratified matching — matchmaker","text":"list class \"matchmaker_result\" containing: left: Left data frame block_id column added right: Right data frame block_id column added block_summary: Summary statistics block dropped: Information dropped blocks () info: Metadata blocking process","code":""},{"path":"https://gcol33.github.io/couplr/reference/matchmaker.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create blocks for stratified matching — matchmaker","text":"function perform matching - creates block structure. Use match_couples() greedy_couples() perform matching within blocks.","code":""},{"path":"https://gcol33.github.io/couplr/reference/matchmaker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create blocks for stratified matching — matchmaker","text":"","code":"# Group blocking left <- data.frame(id = 1:10, region = rep(c(\"A\", \"B\"), each = 5), x = rnorm(10)) right <- data.frame(id = 11:20, region = rep(c(\"A\", \"B\"), each = 5), x = rnorm(10)) blocks <- matchmaker(left, right, block_type = \"group\", block_by = \"region\") print(blocks$block_summary) #> # A tibble: 2 × 3 #>   block_id n_left n_right #>   <chr>     <dbl>   <dbl> #> 1 A             5       5 #> 2 B             5       5  # Clustering blocks <- matchmaker(left, right, block_type = \"cluster\",                      block_vars = \"x\", n_blocks = 3)"},{"path":"https://gcol33.github.io/couplr/reference/match_blocks_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Match blocks in parallel — match_blocks_parallel","title":"Match blocks in parallel — match_blocks_parallel","text":"Match blocks parallel","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_blocks_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match blocks in parallel — match_blocks_parallel","text":"","code":"match_blocks_parallel(   blocks,   left,   right,   left_ids,   right_ids,   block_col,   vars,   distance,   weights,   scale,   max_distance,   calipers,   method,   parallel = FALSE )"},{"path":"https://gcol33.github.io/couplr/reference/match_blocks_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match blocks in parallel — match_blocks_parallel","text":"blocks Vector block IDs left Left dataset block_col right Right dataset block_col left_ids IDs left right_ids IDs right block_col Name blocking column vars Variables matching distance Distance metric weights Variable weights scale Scaling method max_distance Maximum distance calipers Caliper constraints method LAP method parallel Whether use parallel processing","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_blocks_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match blocks in parallel — match_blocks_parallel","text":"List combined results blocks","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal matching using linear assignment — match_couples","title":"Optimal matching using linear assignment — match_couples","text":"Performs optimal one--one matching two datasets using linear assignment problem (LAP) solvers. Supports blocking, distance constraints, various distance metrics.","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal matching using linear assignment — match_couples","text":"","code":"match_couples(   left,   right = NULL,   vars = NULL,   distance = \"euclidean\",   weights = NULL,   scale = FALSE,   auto_scale = FALSE,   max_distance = Inf,   calipers = NULL,   block_id = NULL,   ignore_blocks = FALSE,   require_full_matching = FALSE,   method = \"auto\",   return_unmatched = TRUE,   return_diagnostics = FALSE,   parallel = FALSE,   check_costs = TRUE )"},{"path":"https://gcol33.github.io/couplr/reference/match_couples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal matching using linear assignment — match_couples","text":"left Data frame \"left\" units (e.g., treated, cases) right Data frame \"right\" units (e.g., control, controls) vars Variable names use distance computation distance Distance metric: \"euclidean\", \"manhattan\", \"mahalanobis\", custom function weights Optional named vector variable weights scale Scaling method: FALSE (none), \"standardize\", \"range\", \"robust\" auto_scale TRUE, automatically check variable health select scaling method (default: FALSE) max_distance Maximum allowed distance (pairs exceeding forbidden) calipers Named list per-variable maximum absolute differences block_id Column name containing block IDs (stratified matching) ignore_blocks TRUE, ignore block_id even present require_full_matching TRUE, error units remain unmatched method LAP solver: \"auto\", \"hungarian\", \"jv\", \"gabow_tarjan\", etc. return_unmatched Include unmatched units output return_diagnostics Include detailed diagnostics output parallel Enable parallel processing blocked matching. Requires 'future' 'future.apply' packages. Can : FALSE: Sequential processing (default) TRUE: Auto-configure parallel backend Character: Specify future plan (e.g., \"multisession\", \"multicore\") check_costs TRUE, check distance distribution potential problems provide helpful warnings matching (default: TRUE)","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal matching using linear assignment — match_couples","text":"list class \"matching_result\" containing: pairs: Tibble matched pairs distances unmatched: List unmatched left right IDs info: Matching diagnostics metadata","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal matching using linear assignment — match_couples","text":"function finds matching minimizes total distance among feasible matchings, subject constraints. Use greedy_couples() faster approximate matching large datasets.","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal matching using linear assignment — match_couples","text":"","code":"# Basic matching left <- data.frame(id = 1:5, x = c(1, 2, 3, 4, 5), y = c(2, 4, 6, 8, 10)) right <- data.frame(id = 6:10, x = c(1.1, 2.2, 3.1, 4.2, 5.1), y = c(2.1, 4.1, 6.2, 8.1, 10.1)) result <- match_couples(left, right, vars = c(\"x\", \"y\")) print(result$pairs) #> # A tibble: 5 × 5 #>   left_id right_id distance .x_diff .y_diff #>   <chr>   <chr>       <dbl>   <dbl>   <dbl> #> 1 1       6           0.141 -0.100  -0.100  #> 2 2       7           0.224 -0.200  -0.1000 #> 3 3       8           0.224 -0.100  -0.200  #> 4 4       9           0.224 -0.200  -0.1000 #> 5 5       10          0.141 -0.1000 -0.1000  # With constraints result <- match_couples(left, right, vars = c(\"x\", \"y\"),                         max_distance = 1,                         calipers = list(x = 0.5))  # With blocking left$region <- c(\"A\", \"A\", \"B\", \"B\", \"B\") right$region <- c(\"A\", \"A\", \"B\", \"B\", \"B\") blocks <- matchmaker(left, right, block_type = \"group\", block_by = \"region\") result <- match_couples(blocks$left, blocks$right, vars = c(\"x\", \"y\"))"},{"path":"https://gcol33.github.io/couplr/reference/match_couples_blocked.html","id":null,"dir":"Reference","previous_headings":"","what":"Match with blocking (multiple problems) — match_couples_blocked","title":"Match with blocking (multiple problems) — match_couples_blocked","text":"Match blocking (multiple problems)","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples_blocked.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match with blocking (multiple problems) — match_couples_blocked","text":"","code":"match_couples_blocked(   left,   right,   left_ids,   right_ids,   block_col,   vars,   distance,   weights,   scale,   max_distance,   calipers,   method,   parallel = FALSE )"},{"path":"https://gcol33.github.io/couplr/reference/match_couples_from_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Match from Precomputed Distance Object — match_couples_from_distance","title":"Match from Precomputed Distance Object — match_couples_from_distance","text":"Internal function handle matching distance_object provided","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples_from_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match from Precomputed Distance Object — match_couples_from_distance","text":"","code":"match_couples_from_distance(   dist_obj,   max_distance = Inf,   calipers = NULL,   ignore_blocks = FALSE,   require_full_matching = FALSE,   method = \"auto\",   return_unmatched = TRUE,   return_diagnostics = FALSE,   check_costs = TRUE )"},{"path":"https://gcol33.github.io/couplr/reference/match_couples_single.html","id":null,"dir":"Reference","previous_headings":"","what":"Match without blocking (single problem) — match_couples_single","title":"Match without blocking (single problem) — match_couples_single","text":"Match without blocking (single problem)","code":""},{"path":"https://gcol33.github.io/couplr/reference/match_couples_single.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match without blocking (single problem) — match_couples_single","text":"","code":"match_couples_single(   left,   right,   left_ids,   right_ids,   vars,   distance,   weights,   scale,   max_distance,   calipers,   method,   check_costs = TRUE )"},{"path":"https://gcol33.github.io/couplr/reference/parallel_lapply.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel lapply using future — parallel_lapply","title":"Parallel lapply using future — parallel_lapply","text":"Parallel lapply using future","code":""},{"path":"https://gcol33.github.io/couplr/reference/parallel_lapply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel lapply using future — parallel_lapply","text":"","code":"parallel_lapply(X, FUN, ..., parallel = FALSE)"},{"path":"https://gcol33.github.io/couplr/reference/parallel_lapply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel lapply using future — parallel_lapply","text":"X Vector iterate FUN Function apply ... Additional arguments FUN parallel Whether parallel processing enabled","code":""},{"path":"https://gcol33.github.io/couplr/reference/parallel_lapply.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel lapply using future — parallel_lapply","text":"List results","code":""},{"path":"https://gcol33.github.io/couplr/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://gcol33.github.io/couplr/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://gcol33.github.io/couplr/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://gcol33.github.io/couplr/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph.html","id":null,"dir":"Reference","previous_headings":"","what":"Pixel-level image morphing (final frame only) — pixel_morph","title":"Pixel-level image morphing (final frame only) — pixel_morph","text":"Computes optimal pixel assignment B returns final transported frame (without intermediate animation frames).","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pixel-level image morphing (final frame only) — pixel_morph","text":"","code":"pixel_morph(   imgA,   imgB,   n_frames = 16L,   mode = c(\"color_walk\", \"exact\", \"recursive\"),   lap_method = \"jv\",   maximize = FALSE,   quantize_bits = 5L,   downscale_steps = 0L,   alpha = 1,   beta = 0,   patch_size = 1L,   upscale = 1,   show = interactive() )"},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pixel-level image morphing (final frame only) — pixel_morph","text":"imgA Source image (file path magick image object) imgB Target image (file path magick image object) n_frames Internal parameter rendering (default: 16) mode Assignment algorithm: \"color_walk\" (default), \"exact\", \"recursive\" lap_method LAP solver method (default: \"jv\") maximize Logical, maximize instead minimize cost (default: FALSE) quantize_bits Color quantization \"color_walk\" mode (default: 5) downscale_steps Number 2x reductions computing assignment (default: 0) alpha Weight color distance cost function (default: 1) beta Weight spatial distance cost function (default: 0) patch_size Tile size tiled modes (default: 1) upscale Post-rendering upscaling factor (default: 1) show Logical, display result viewer (default: interactive())","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pixel-level image morphing (final frame only) — pixel_morph","text":"magick image object final transported frame","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph.html","id":"transport-only-semantics","dir":"Reference","previous_headings":"","what":"Transport-Only Semantics","title":"Pixel-level image morphing (final frame only) — pixel_morph","text":"function returns SHARP, pixel-perfect transport 's pixels positions determined assignment B. Key Points: Assignment computed using: cost = alpha * color_dist + beta * spatial_dist B's COLORS influence assignment appear output Result 's colors arranged match B's layout motion blur (unlike intermediate frames animation) See pixel_morph_animate detailed explanation assignment vs rendering semantics.","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph.html","id":"permutation-warnings","dir":"Reference","previous_headings":"","what":"Permutation Warnings","title":"Pixel-level image morphing (final frame only) — pixel_morph","text":"Assignment guaranteed bijection (permutation) : downscale_steps = 0 (resolution changes) mode = \"exact\" patch_size = 1 downscaling tiled modes, assignment may : Overlaps: Multiple source pixels map destination (last write wins) Holes: destinations never filled (remain transparent) assignment bijection (due downscaling tiling), warning issued. result may contain: Overlapped pixels (multiple sources -> one destination) Transparent holes (destinations unfilled) guaranteed pixel-perfect results, use:","code":"pixel_morph(A, B, mode = \"exact\", downscale_steps = 0)"},{"path":[]},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pixel-level image morphing (final frame only) — pixel_morph","text":"","code":"if (FALSE) { # \\dontrun{ # Basic morph result <- pixel_morph(\"imageA.png\", \"imageB.png\")  # Pure spatial rearrangement result <- pixel_morph(\"imageA.png\", \"imageB.png\",                       alpha = 0, beta = 1)  # Exact mode for small images (guaranteed permutation) result <- pixel_morph(\"small_A.png\", \"small_B.png\",                       mode = \"exact\", downscale_steps = 0) } # }"},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":null,"dir":"Reference","previous_headings":"","what":"Pixel-level image morphing (animation) — pixel_morph_animate","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"Creates animated morph computing optimal pixel assignment image image B, rendering intermediate frames showing transport.","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"","code":"pixel_morph_animate(   imgA,   imgB,   n_frames = 16L,   fps = 10L,   format = c(\"gif\", \"webp\", \"mp4\"),   outfile = NULL,   show = interactive(),   mode = c(\"color_walk\", \"exact\", \"recursive\"),   lap_method = \"jv\",   maximize = FALSE,   quantize_bits = 5L,   downscale_steps = 0L,   alpha = 1,   beta = 0,   patch_size = 1L,   upscale = 1 )"},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"imgA Source image (file path magick image object) imgB Target image (file path magick image object) n_frames Integer number animation frames (default: 16) fps Frames per second playback (default: 10) format Output format: \"gif\", \"webp\", \"mp4\" outfile Optional output file path show Logical, display animation viewer (default: interactive()) mode Assignment algorithm: \"color_walk\" (default), \"exact\", \"recursive\" lap_method LAP solver method (default: \"jv\") maximize Logical, maximize instead minimize cost (default: FALSE) quantize_bits Color quantization \"color_walk\" mode (default: 5) downscale_steps Number 2x reductions computing assignment (default: 0) alpha Weight color distance cost function (default: 1) beta Weight spatial distance cost function (default: 0) patch_size Tile size tiled modes (default: 1) upscale Post-rendering upscaling factor (default: 1)","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"Invisibly returns list animation object metadata: animation magick animation object width Image width pixels height Image height pixels assignment Integer vector 1-based assignment indices (R convention) n_pixels Total number pixels mode Mode used matching upscale Upscaling factor applied","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"assignment-vs-rendering-semantics","dir":"Reference","previous_headings":"","what":"Assignment vs Rendering Semantics","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"CRITICAL: function two separate phases different semantics: Phase 1 - Assignment Computation: assignment computed minimizing: means B's COLORS influence pixels map positions. Phase 2 - Rendering (Transport-): renderer uses 's colors: Intermediate frames: 's pixels move along paths motion blur Final frame: 's pixels assigned positions (sharp, blur) B's colors NEVER appear output Result: get 's colors rearranged match B's geometry/layout.","code":"cost(i,j) = alpha * color_distance(A[i], B[j]) +               beta * spatial_distance(pos_i, pos_j)"},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"what-this-means","dir":"Reference","previous_headings":"","what":"What This Means","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"B influences pixels go (via similarity cost function) B determine COLORS appear output Final image 's palette arranged mimic B's structure","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"parameter-guidance","dir":"Reference","previous_headings":"","what":"Parameter Guidance","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"pure spatial rearrangement (ignore B's colors assignment): color-similarity matching (default): hybrid (color + spatial):","code":"pixel_morph_animate(A, B, alpha = 0, beta = 1) pixel_morph_animate(A, B, alpha = 1, beta = 0) pixel_morph_animate(A, B, alpha = 1, beta = 0.2)"},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"permutation-guarantees","dir":"Reference","previous_headings":"","what":"Permutation Guarantees","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"Assignment guaranteed bijection (permutation) : downscale_steps = 0 (resolution changes) mode = \"exact\" patch_size = 1 downscaling tiled modes, assignment may : Overlaps: Multiple source pixels map destination (last write wins) Holes: destinations never filled (remain transparent) warning issued overlaps/holes detected final frame.","code":""},{"path":"https://gcol33.github.io/couplr/reference/pixel_morph_animate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pixel-level image morphing (animation) — pixel_morph_animate","text":"","code":"if (FALSE) { # \\dontrun{ # Basic animation with default settings pixel_morph_animate(\"imageA.png\", \"imageB.png\", outfile = \"morph.gif\")  # Pure spatial rearrangement (ignore B's colors in assignment) pixel_morph_animate(\"imageA.png\", \"imageB.png\",                     alpha = 0, beta = 1, outfile = \"spatial.gif\")  # Large image with downscaling pixel_morph_animate(\"largeA.png\", \"largeB.png\",                     mode = \"color_walk\", downscale_steps = 2,                     outfile = \"large_morph.gif\") } # }"},{"path":"https://gcol33.github.io/couplr/reference/preprocess_matching_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess matching variables with automatic checks and scaling — preprocess_matching_vars","title":"Preprocess matching variables with automatic checks and scaling — preprocess_matching_vars","text":"Main preprocessing function orchestrates variable health checks, categorical encoding, automatic scaling selection.","code":""},{"path":"https://gcol33.github.io/couplr/reference/preprocess_matching_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess matching variables with automatic checks and scaling — preprocess_matching_vars","text":"","code":"preprocess_matching_vars(   left,   right,   vars,   auto_scale = TRUE,   scale_method = \"auto\",   check_health = TRUE,   remove_problematic = TRUE,   verbose = TRUE )"},{"path":"https://gcol33.github.io/couplr/reference/preprocess_matching_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess matching variables with automatic checks and scaling — preprocess_matching_vars","text":"left Data frame left units right Data frame right units vars Character vector variable names auto_scale Logical, whether perform automatic preprocessing (default: TRUE) scale_method Scaling method: \"auto\", \"standardize\", \"range\", \"robust\", FALSE check_health Logical, whether check variable health (default: TRUE) remove_problematic Logical, automatically exclude constant/-NA variables (default: TRUE) verbose Logical, whether print warnings (default: TRUE)","code":""},{"path":"https://gcol33.github.io/couplr/reference/preprocess_matching_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess matching variables with automatic checks and scaling — preprocess_matching_vars","text":"list class \"preprocessing_result\" containing: left: Preprocessed left data frame right: Preprocessed right data frame vars: Final variable names (exclusions) health: Variable health diagnostics scaling_method: Selected scaling method excluded_vars: Variables excluded warnings: List warnings issued","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.balance_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for Balance Diagnostics — print.balance_diagnostics","title":"Print Method for Balance Diagnostics — print.balance_diagnostics","text":"Print Method Balance Diagnostics","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.balance_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for Balance Diagnostics — print.balance_diagnostics","text":"","code":"# S3 method for class 'balance_diagnostics' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.balance_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for Balance Diagnostics — print.balance_diagnostics","text":"x balance_diagnostics object ... Additional arguments (ignored)","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.distance_object.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for Distance Objects — print.distance_object","title":"Print Method for Distance Objects — print.distance_object","text":"Print Method Distance Objects","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.distance_object.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for Distance Objects — print.distance_object","text":"","code":"# S3 method for class 'distance_object' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.distance_object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for Distance Objects — print.distance_object","text":"x distance_object ... Additional arguments (ignored)","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_batch_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for batch assignment results — print.lap_solve_batch_result","title":"Print method for batch assignment results — print.lap_solve_batch_result","text":"Prints summary table results batch assignment problems solved lap_solve_batch().","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_batch_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for batch assignment results — print.lap_solve_batch_result","text":"","code":"# S3 method for class 'lap_solve_batch_result' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_batch_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for batch assignment results — print.lap_solve_batch_result","text":"x lap_solve_batch_result object. ... Additional arguments passed print(). Currently ignored.","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_kbest_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for k-best assignment results — print.lap_solve_kbest_result","title":"Print method for k-best assignment results — print.lap_solve_kbest_result","text":"Print method k-best assignment results","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_kbest_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for k-best assignment results — print.lap_solve_kbest_result","text":"","code":"# S3 method for class 'lap_solve_kbest_result' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_kbest_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for k-best assignment results — print.lap_solve_kbest_result","text":"x lap_solve_kbest_result. ... Additional arguments passed print(). Ignored.","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for assignment results — print.lap_solve_result","title":"Print method for assignment results — print.lap_solve_result","text":"Nicely prints lap_solve_result object, including assignments, total cost, method used.","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for assignment results — print.lap_solve_result","text":"","code":"# S3 method for class 'lap_solve_result' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.lap_solve_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for assignment results — print.lap_solve_result","text":"x lap_solve_result object. ... Additional arguments passed print(). Currently ignored.","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.matching_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for matching results — print.matching_result","title":"Print method for matching results — print.matching_result","text":"Print method matching results","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.matching_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for matching results — print.matching_result","text":"","code":"# S3 method for class 'matching_result' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.matching_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for matching results — print.matching_result","text":"x matching_result object ... Additional arguments (ignored)","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.matchmaker_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for matchmaker results — print.matchmaker_result","title":"Print method for matchmaker results — print.matchmaker_result","text":"Print method matchmaker results","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.matchmaker_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for matchmaker results — print.matchmaker_result","text":"","code":"# S3 method for class 'matchmaker_result' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.matchmaker_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for matchmaker results — print.matchmaker_result","text":"x matchmaker_result object ... Additional arguments (ignored)","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.preprocessing_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for preprocessing result — print.preprocessing_result","title":"Print method for preprocessing result — print.preprocessing_result","text":"Print method preprocessing result","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.preprocessing_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for preprocessing result — print.preprocessing_result","text":"","code":"# S3 method for class 'preprocessing_result' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.preprocessing_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for preprocessing result — print.preprocessing_result","text":"x preprocessing_result object ... Additional arguments (ignored)","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.variable_health.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for variable health — print.variable_health","title":"Print method for variable health — print.variable_health","text":"Print method variable health","code":""},{"path":"https://gcol33.github.io/couplr/reference/print.variable_health.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for variable health — print.variable_health","text":"","code":"# S3 method for class 'variable_health' print(x, ...)"},{"path":"https://gcol33.github.io/couplr/reference/print.variable_health.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for variable health — print.variable_health","text":"x variable_health object ... Additional arguments (ignored)","code":""},{"path":"https://gcol33.github.io/couplr/reference/restore_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Restore original parallel plan — restore_parallel","title":"Restore original parallel plan — restore_parallel","text":"Restore original parallel plan","code":""},{"path":"https://gcol33.github.io/couplr/reference/restore_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restore original parallel plan — restore_parallel","text":"","code":"restore_parallel(parallel_state)"},{"path":"https://gcol33.github.io/couplr/reference/restore_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restore original parallel plan — restore_parallel","text":"parallel_state State setup_parallel()","code":""},{"path":"https://gcol33.github.io/couplr/reference/setup_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup parallel processing with future — setup_parallel","title":"Setup parallel processing with future — setup_parallel","text":"Setup parallel processing future","code":""},{"path":"https://gcol33.github.io/couplr/reference/setup_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup parallel processing with future — setup_parallel","text":"","code":"setup_parallel(parallel = FALSE, n_workers = NULL)"},{"path":"https://gcol33.github.io/couplr/reference/setup_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup parallel processing with future — setup_parallel","text":"parallel Logical plan specification n_workers Number workers (NULL auto-detect)","code":""},{"path":"https://gcol33.github.io/couplr/reference/setup_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup parallel processing with future — setup_parallel","text":"List original plan whether set parallelization","code":""},{"path":"https://gcol33.github.io/couplr/reference/standardized_difference.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Standardized Difference — standardized_difference","title":"Calculate Standardized Difference — standardized_difference","text":"Computes standardized mean difference two groups. key metric assessing balance matched samples.","code":""},{"path":"https://gcol33.github.io/couplr/reference/standardized_difference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Standardized Difference — standardized_difference","text":"","code":"standardized_difference(x1, x2, pooled = TRUE)"},{"path":"https://gcol33.github.io/couplr/reference/standardized_difference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Standardized Difference — standardized_difference","text":"x1 Numeric vector group 1 x2 Numeric vector group 2 pooled Logical, TRUE use pooled standard deviation (default), FALSE use group 1 standard deviation","code":""},{"path":"https://gcol33.github.io/couplr/reference/standardized_difference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Standardized Difference — standardized_difference","text":"Numeric value representing standardized difference","code":""},{"path":"https://gcol33.github.io/couplr/reference/standardized_difference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Standardized Difference — standardized_difference","text":"Standardized difference = (mean1 - mean2) / pooled_sd pooled_sd = sqrt((sd1^2 + sd2^2) / 2) Common thresholds: less 0.1 excellent balance, 0.1-0.25 good balance, 0.25-0.5 acceptable balance, greater 0.5 poor balance.","code":""},{"path":"https://gcol33.github.io/couplr/reference/success_good_balance.html","id":null,"dir":"Reference","previous_headings":"","what":"Perfect balance success message — success_good_balance","title":"Perfect balance success message — success_good_balance","text":"Perfect balance success message","code":""},{"path":"https://gcol33.github.io/couplr/reference/success_good_balance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perfect balance success message — success_good_balance","text":"","code":"success_good_balance(mean_std_diff)"},{"path":"https://gcol33.github.io/couplr/reference/suggest_scaling.html","id":null,"dir":"Reference","previous_headings":"","what":"Suggest scaling method based on variable characteristics — suggest_scaling","title":"Suggest scaling method based on variable characteristics — suggest_scaling","text":"Analyzes variable distributions suggests appropriate scaling methods.","code":""},{"path":"https://gcol33.github.io/couplr/reference/suggest_scaling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Suggest scaling method based on variable characteristics — suggest_scaling","text":"","code":"suggest_scaling(left, right, vars)"},{"path":"https://gcol33.github.io/couplr/reference/suggest_scaling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Suggest scaling method based on variable characteristics — suggest_scaling","text":"left Data frame left units right Data frame right units vars Character vector variable names","code":""},{"path":"https://gcol33.github.io/couplr/reference/suggest_scaling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Suggest scaling method based on variable characteristics — suggest_scaling","text":"character string suggested scaling method: \"standardize\", \"range\", \"robust\", \"none\"","code":""},{"path":"https://gcol33.github.io/couplr/reference/summarize_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize block structure — summarize_blocks","title":"Summarize block structure — summarize_blocks","text":"Summarize block structure","code":""},{"path":"https://gcol33.github.io/couplr/reference/summarize_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize block structure — summarize_blocks","text":"","code":"summarize_blocks(left, right, block_vars = NULL)"},{"path":"https://gcol33.github.io/couplr/reference/summary.distance_object.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Distance Objects — summary.distance_object","title":"Summary Method for Distance Objects — summary.distance_object","text":"Summary Method Distance Objects","code":""},{"path":"https://gcol33.github.io/couplr/reference/summary.distance_object.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Distance Objects — summary.distance_object","text":"","code":"# S3 method for class 'distance_object' summary(object, ...)"},{"path":"https://gcol33.github.io/couplr/reference/summary.distance_object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Distance Objects — summary.distance_object","text":"object distance_object ... Additional arguments (ignored)","code":""},{"path":"https://gcol33.github.io/couplr/reference/summary.lap_solve_kbest_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Get summary of k-best results — summary.lap_solve_kbest_result","title":"Get summary of k-best results — summary.lap_solve_kbest_result","text":"Extract summary information k-best assignment results.","code":""},{"path":"https://gcol33.github.io/couplr/reference/summary.lap_solve_kbest_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get summary of k-best results — summary.lap_solve_kbest_result","text":"","code":"# S3 method for class 'lap_solve_kbest_result' summary(object, ...)"},{"path":"https://gcol33.github.io/couplr/reference/summary.lap_solve_kbest_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get summary of k-best results — summary.lap_solve_kbest_result","text":"object object class lap_solve_kbest_result. ... Additional arguments (unused).","code":""},{"path":"https://gcol33.github.io/couplr/reference/summary.lap_solve_kbest_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get summary of k-best results — summary.lap_solve_kbest_result","text":"tibble one row per solution containing: rank: solution rank solution_id: solution identifier total_cost: total cost solution n_assignments: number assignments solution","code":""},{"path":"https://gcol33.github.io/couplr/reference/update_constraints.html","id":null,"dir":"Reference","previous_headings":"","what":"Update Constraints on Distance Object — update_constraints","title":"Update Constraints on Distance Object — update_constraints","text":"Apply new constraints precomputed distance object without recomputing underlying distances. useful exploring different constraint scenarios quickly.","code":""},{"path":"https://gcol33.github.io/couplr/reference/update_constraints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update Constraints on Distance Object — update_constraints","text":"","code":"update_constraints(dist_obj, max_distance = Inf, calipers = NULL)"},{"path":"https://gcol33.github.io/couplr/reference/update_constraints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update Constraints on Distance Object — update_constraints","text":"dist_obj distance_object compute_distances() max_distance Maximum allowed distance (pairs distance > max_distance become Inf) calipers Named list per-variable calipers","code":""},{"path":"https://gcol33.github.io/couplr/reference/update_constraints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update Constraints on Distance Object — update_constraints","text":"new distance_object updated cost_matrix","code":""},{"path":"https://gcol33.github.io/couplr/reference/update_constraints.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update Constraints on Distance Object — update_constraints","text":"function creates new distance_object modified constraints applied cost matrix. original distance_object modified. Constraints: max_distance: Sets cost Inf pairs exceeding threshold calipers: Per-variable restrictions (e.g., calipers = list(age = 5)) function returns new object rather modifying place, following R's copy--modify semantics.","code":""},{"path":"https://gcol33.github.io/couplr/reference/update_constraints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update Constraints on Distance Object — update_constraints","text":"","code":"left <- data.frame(id = 1:5, age = c(25, 30, 35, 40, 45)) right <- data.frame(id = 6:10, age = c(24, 29, 36, 41, 44)) dist_obj <- compute_distances(left, right, vars = \"age\")  # Apply constraints constrained <- update_constraints(dist_obj, max_distance = 2) result <- match_couples(constrained) #> Warning: All distances are identical (1.0000) #>   Your matching variables aren't informative! #>   Possible causes: #>     - Constant variables (no variation) #>     - Highly correlated variables #>     - Inappropriate distance metric #>   Try: #>     - Using auto_scale = TRUE #>     - Checking variable variation #>     - Adding more informative variables #> Warning: 80.0% of pairs are forbidden! #>   Only 5 valid pairs for 5 left units - the matching pool is shallow! #>   Your constraints might be concerningly strict. #>   Consider: #>     - Relaxing max_distance threshold #>     - Widening calipers #>     - Using fewer/broader blocks #>     - Checking if your data actually overlaps"},{"path":"https://gcol33.github.io/couplr/reference/use_emoji.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if emoji should be used — use_emoji","title":"Check if emoji should be used — use_emoji","text":"Check emoji used","code":""},{"path":"https://gcol33.github.io/couplr/reference/use_emoji.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if emoji should be used — use_emoji","text":"","code":"use_emoji()"},{"path":"https://gcol33.github.io/couplr/reference/validate_calipers.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate calipers parameter — validate_calipers","title":"Validate calipers parameter — validate_calipers","text":"Validate calipers parameter","code":""},{"path":"https://gcol33.github.io/couplr/reference/validate_calipers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate calipers parameter — validate_calipers","text":"","code":"validate_calipers(calipers, vars)"},{"path":"https://gcol33.github.io/couplr/reference/validate_cost_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate and prepare cost data — validate_cost_data","title":"Validate and prepare cost data — validate_cost_data","text":"Internal helper ensures numeric, non-empty cost matrix.","code":""},{"path":"https://gcol33.github.io/couplr/reference/validate_cost_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate and prepare cost data — validate_cost_data","text":"","code":"validate_cost_data(x, forbidden = NA)"},{"path":"https://gcol33.github.io/couplr/reference/validate_cost_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate and prepare cost data — validate_cost_data","text":"x Cost matrix data frame forbidden Value representing forbidden assignments (use NA Inf)","code":""},{"path":"https://gcol33.github.io/couplr/reference/validate_cost_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate and prepare cost data — validate_cost_data","text":"Numeric cost matrix","code":""},{"path":"https://gcol33.github.io/couplr/reference/validate_matching_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate matching inputs — validate_matching_inputs","title":"Validate matching inputs — validate_matching_inputs","text":"Validate matching inputs","code":""},{"path":"https://gcol33.github.io/couplr/reference/validate_matching_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate matching inputs — validate_matching_inputs","text":"","code":"validate_matching_inputs(left, right, vars = NULL)"},{"path":"https://gcol33.github.io/couplr/reference/validate_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate weights parameter — validate_weights","title":"Validate weights parameter — validate_weights","text":"Validate weights parameter","code":""},{"path":"https://gcol33.github.io/couplr/reference/validate_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate weights parameter — validate_weights","text":"","code":"validate_weights(weights, vars)"},{"path":"https://gcol33.github.io/couplr/reference/warn_constant_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"All distances identical warning — warn_constant_distance","title":"All distances identical warning — warn_constant_distance","text":"distances identical warning","code":""},{"path":"https://gcol33.github.io/couplr/reference/warn_constant_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"All distances identical warning — warn_constant_distance","text":"","code":"warn_constant_distance(value)"},{"path":"https://gcol33.github.io/couplr/reference/warn_constant_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Constant variable warning — warn_constant_var","title":"Constant variable warning — warn_constant_var","text":"Constant variable warning","code":""},{"path":"https://gcol33.github.io/couplr/reference/warn_constant_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constant variable warning — warn_constant_var","text":"","code":"warn_constant_var(var)"},{"path":"https://gcol33.github.io/couplr/reference/warn_extreme_costs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extreme cost ratio warning — warn_extreme_costs","title":"Extreme cost ratio warning — warn_extreme_costs","text":"Extreme cost ratio warning","code":""},{"path":"https://gcol33.github.io/couplr/reference/warn_extreme_costs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extreme cost ratio warning — warn_extreme_costs","text":"","code":"warn_extreme_costs(p95, p99, ratio, problem_vars = NULL)"},{"path":"https://gcol33.github.io/couplr/reference/warn_many_forbidden.html","id":null,"dir":"Reference","previous_headings":"","what":"Many forbidden pairs warning — warn_many_forbidden","title":"Many forbidden pairs warning — warn_many_forbidden","text":"Many forbidden pairs warning","code":""},{"path":"https://gcol33.github.io/couplr/reference/warn_many_forbidden.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Many forbidden pairs warning — warn_many_forbidden","text":"","code":"warn_many_forbidden(pct_forbidden, n_valid, n_left)"},{"path":"https://gcol33.github.io/couplr/reference/warn_many_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Too many zeros warning — warn_many_zeros","title":"Too many zeros warning — warn_many_zeros","text":"many zeros warning","code":""},{"path":"https://gcol33.github.io/couplr/reference/warn_many_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Too many zeros warning — warn_many_zeros","text":"","code":"warn_many_zeros(pct, n_zeros)"},{"path":"https://gcol33.github.io/couplr/reference/warn_parallel_unavailable.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel package missing warning (reuse from matching_parallel.R) — warn_parallel_unavailable","title":"Parallel package missing warning (reuse from matching_parallel.R) — warn_parallel_unavailable","text":"Parallel package missing warning (reuse matching_parallel.R)","code":""},{"path":"https://gcol33.github.io/couplr/reference/warn_parallel_unavailable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel package missing warning (reuse from matching_parallel.R) — warn_parallel_unavailable","text":"","code":"warn_parallel_unavailable()"},{"path":"https://gcol33.github.io/couplr/reference/warn_poor_quality.html","id":null,"dir":"Reference","previous_headings":"","what":"High distance matches warning — warn_poor_quality","title":"High distance matches warning — warn_poor_quality","text":"High distance matches warning","code":""},{"path":"https://gcol33.github.io/couplr/reference/warn_poor_quality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"High distance matches warning — warn_poor_quality","text":"","code":"warn_poor_quality(pct_poor, threshold)"},{"path":[]},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"executive-summary","dir":"","previous_headings":"","what":"Executive Summary","title":"Vignette Improvement Plan for couplr","text":"document outlines comprehensive plan address structural, narrative, meta-explanatory weaknesses identified four couplr vignettes. improvements focus : Unified documentation ecosystem cross-references consistent structure Shared example dataset recurs across vignettes Explicit audience guidance difficulty indicators Progressive narrative flow concept example interpretation Discussion limitations, edge cases, failure modes Clear positioning package R ecosystem","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"id_1-create-a-unified-introduction-section","dir":"","previous_headings":"Cross-Cutting Improvements (All Vignettes)","what":"1. Create a Unified Introduction Section","title":"Vignette Improvement Plan for couplr","text":"Add consistent introductory block vignette : States purpose target audience Positions vignette within documentation ecosystem Provides difficulty/prerequisite indicators Links related vignettes Template add start vignette (Overview):","code":"### Who This Vignette Is For  **Audience**: [Beginners | Intermediate users | Advanced users / Algorithm developers]  **Prerequisites**: - [List any required vignettes or knowledge] - [e.g., \"Basic R knowledge\", \"Familiarity with matching concepts\"]  **What You'll Learn**: - [3-5 specific takeaways]  **Time to Complete**: [Approximate reading/working time]  ### Documentation Roadmap  The couplr documentation is organized as follows:  | Vignette | Focus | Difficulty | |----------|-------|------------| | **Getting Started** | Basic LAP solving, API introduction | Beginner | | **Algorithms** | Mathematical foundations, solver selection | Intermediate | | **Matching Workflows** | Production matching pipelines | Intermediate | | **Pixel Morphing** | Scientific applications, approximations | Advanced |  *You are here: [Current vignette]*"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"id_2-introduce-a-shared-example-dataset","dir":"","previous_headings":"Cross-Cutting Improvements (All Vignettes)","what":"2. Introduce a Shared Example Dataset","title":"Vignette Improvement Plan for couplr","text":"Create recurring dataset appears across vignettes, establishing coherence: Proposal: “Hospital Staff Scheduling” dataset Basic form (getting-started): 10 nurses × 10 shifts, simple cost matrix Extended form (algorithms): problem different cost structures demonstrate algorithm differences Matching form (matching-workflows): 200 nurses needing matched 300 controls study Large-scale form (pixel-morphing): Analogy visual matching, demonstrate approximations needed Implementation: Add data/ hospital_example documentation R/data.R","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"id_3-add-limitations-and-edge-cases-sections","dir":"","previous_headings":"Cross-Cutting Improvements (All Vignettes)","what":"3. Add “Limitations and Edge Cases” Sections","title":"Vignette Improvement Plan for couplr","text":"vignette include dedicated section discussing: method breaks Common failure modes Performance bottlenecks Infeasibility conditions Numerical issues","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"id_4-establish-narrative-transitions","dir":"","previous_headings":"Cross-Cutting Improvements (All Vignettes)","what":"4. Establish Narrative Transitions","title":"Vignette Improvement Plan for couplr","text":"Add explicit transition paragraphs major sections : Summarize just covered Preview comes next Explain transition makes sense","code":""},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"current-state","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd)","what":"Current State","title":"Vignette Improvement Plan for couplr","text":"394 lines Jumps directly examples Good technical content reads like reference documentation Missing orientation positioning","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"a-add-explicit-orientation-new-section-after-line-22","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd) > Improvements","what":"A. Add Explicit Orientation (New Section After Line 22)","title":"Vignette Improvement Plan for couplr","text":"Insert “## Overview”:","code":"### Why couplr?  The linear assignment problem (LAP) appears throughout data science, operations research, and scientific computing. While other R packages address LAP (see Comparison below), couplr distinguishes itself through:  1. **Tidy integration**: First-class support for tibbles, dplyr workflows, and grouped data 2. **Algorithm selection**: 12+ algorithms with automatic selection based on problem structure 3. **Production matching**: High-level matching functions for observational studies (v1.0.0) 4. **Visual applications**: Pixel morphing and transport visualization  **Alternative packages**: - `clue`: General purpose optimization (LAP is one feature among many) - `lpSolve`: Linear programming focus, less specialized for assignment - `RcppHungarian`: Single algorithm, no tidy interface  couplr focuses specifically on assignment problems with a user-friendly API and modern R idioms.  ### Who This Vignette Is For  **Audience**: Beginners to couplr, R users familiar with basic matrix operations  **Prerequisites**: - Basic R knowledge (data frames, functions) - Understanding of what a \"cost\" or \"distance\" matrix means  **What You'll Learn**: - How to solve basic assignment problems with `lap_solve()` - Working with data frames, rectangular problems, and forbidden assignments - Batch solving and finding multiple solutions - When to use different algorithms  **Time to Complete**: 20-30 minutes"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"b-add-narrative-frame-follow-one-problem-through","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd) > Improvements","what":"B. Add Narrative Frame: Follow One Problem Through","title":"Vignette Improvement Plan for couplr","text":"Restructure vignette around single problem evolves: Introduction: Hospital shift scheduling (simple 3×3) Data frame input: problem database Rectangular: shifts nurses Forbidden: nurses can’t work certain shifts Maximization: Preference scores instead costs Batch: Multiple days scheduling K-best: Alternative schedules flexibility Modification existing content: Keep current examples frame variations hospital problem. Add narrative transitions like: “Now can solve basic problem, happens shifts nurses fill ?”","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"c-add-common-pitfalls-section-before-summary","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd) > Improvements","what":"C. Add “Common Pitfalls” Section (Before Summary)","title":"Vignette Improvement Plan for couplr","text":"","code":"## Common Pitfalls and Troubleshooting  ### Problem: \"All assignments have Inf cost\"  **Cause**: Too many forbidden entries (NA/Inf) make the problem infeasible.  **Solution**: Check that a feasible solution exists. For rectangular problems with forbidden entries, ensure at least one valid assignment exists for each source.  ```r # Check feasibility feasible <- rowSums(is.finite(cost)) > 0 if (!all(feasible)) {   warning(\"Sources \", which(!feasible), \" have no valid targets\") }"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"problem-unexpected-assignments","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd)","what":"Problem: Unexpected assignments","title":"Vignette Improvement Plan for couplr","text":"Cause: Cost matrix orientation wrong (rows vs columns swapped). Solution: Remember: rows = sources, columns = targets. result match vector length = nrow, match[] column assigned row .","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"problem-different-results-with-different-methods","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd)","what":"Problem: Different results with different methods","title":"Vignette Improvement Plan for couplr","text":"Cause: Multiple optimal solutions may exist. Different algorithms may find different optima total cost. Solution: need deterministic results, set seed use method = \"hungarian\" deterministic tie-breaking.","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"problem-slow-performance-on-large-problems","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd)","what":"Problem: Slow performance on large problems","title":"Vignette Improvement Plan for couplr","text":"Cause: O(n³) complexity exact algorithms. Solution: - n > 1000: Consider method = \"auction\" - n > 5000: Use blocking greedy matching (vignette(\"matching-workflows\")) - n > 10000: Use approximation strategies (vignette(\"pixel-morphing\"))","code":"#### D. Improve Section Transitions  Add transition paragraphs. Example between \"Basic Usage\" and \"Working with Rectangular Problems\":  > \"The examples above assumed equal numbers of sources and targets. But real-world problems rarely have this symmetry—a hospital may have 20 nurses but need to cover 30 shifts, or have 50 tasks but only budget for 40 workers. couplr handles these rectangular problems automatically.\"  ---  ## 2. Algorithms (algorithms.Rmd)  ### Current State - 667 lines - Good mathematical content - Stays at intuitive level, lacks formal structure - No explicit comparison between algorithms - No failure modes discussed  ### Improvements  #### A. Add Structured Algorithm Template  Restructure each algorithm section to follow a consistent pattern:  ```markdown ### [Algorithm Name]  **Complexity**: [Big-O notation]  **When to Use**: - [Bullet points of ideal conditions]  **When NOT to Use**: - [Bullet points of poor conditions]  #### Core Idea  [1-2 paragraph intuitive explanation]  #### Formal Description  [Mathematical formulation with LaTeX]  **Input**: [Describe input requirements]  **Output**: [Describe output guarantees]  **Algorithm Steps**: 1. [Numbered steps with mathematical notation]  #### Implementation Notes  [Practical considerations, numerical issues]  #### Example  [Code demonstrating the algorithm]  #### Failure Modes and Edge Cases  - [When the algorithm may fail or perform poorly] - [Numerical stability concerns] - [Special cases to watch for]"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"b-add-comparative-analysis-section","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd) > Problem: Slow performance on large problems","what":"B. Add Comparative Analysis Section","title":"Vignette Improvement Plan for couplr","text":"Insert “## Algorithms couplr” (around line 68):","code":"### Algorithm Selection Guide  Before diving into individual algorithms, here's a decision framework: Is the cost matrix binary (0/1)?                           |           ┌───────────────┴───────────────┐           Yes                             No           |                               |       Use HK01                    Is sparsity > 50%?                                           |                           ┌───────────────┴───────────────┐                           Yes                             No                           |                               |                       Use SAP                      Is n > 1000?                                                           |                                           ┌───────────────┴───────────────┐                                           Yes                             No                                           |                               |                                       Use Auction              Use JV (default)                                       or consider                                       approximations ### Head-to-Head Comparisons  | Scenario | Hungarian | JV | Auction | SAP | HK01 | |----------|-----------|----|---------|----|------| | Dense 100×100 | ✓✓✓ | ✓✓✓ | ✓✓ | ✓ | N/A | | Dense 1000×1000 | ✓ | ✓✓✓ | ✓✓✓ | ✓ | N/A | | Sparse 80% forbidden | ✓ | ✓✓ | ✓ | ✓✓✓ | N/A | | Binary costs | ✓ | ✓ | ✓ | ✓ | ✓✓✓ | | Rectangular n×2n | ✗ | ✓✓ | ✗ | ✓✓✓ | ✓✓ | | Numerical precision | ✓✓✓ | ✓✓ | ✓ | ✓✓ | ✓✓✓ |  ✓✓✓ = Excellent, ✓✓ = Good, ✓ = Acceptable, ✗ = Not recommended"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"c-add-limitations-and-numerical-issues-section","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd) > Problem: Slow performance on large problems","what":"C. Add “Limitations and Numerical Issues” Section","title":"Vignette Improvement Plan for couplr","text":"Detection: Check rowSums(.finite(cost)) > 0 rows. 2. Nearly Degenerate Problems many costs nearly equal, small numerical errors can cause: - Different algorithms finding different solutions - Cycling auction algorithms - Incorrect optimality certification Mitigation: Use method = \"hungarian\" maximum numerical stability, add small random perturbations. 3. Overflow Dual Variables large cost ranges (> 10^10), dual variable updates may overflow: Mitigation: Scale costs reasonable range (0 10^6) solving.","code":"## Limitations and Numerical Issues  ### When LAP Algorithms Fail  **1. Infeasible Problems**  If too many entries are forbidden (NA/Inf), no valid assignment may exist:  ```r # Infeasible: no column reachable from row 2 cost <- matrix(c(1, 2, Inf, Inf), nrow = 2) # lap_solve(cost) will error or return partial solution # Problematic: cost range is 10^15 cost <- matrix(c(1e-5, 1e10, 1e10, 1e-5), nrow = 2)"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"algorithm-specific-issues","dir":"","previous_headings":"1. Getting Started (getting-started.Rmd)","what":"Algorithm-Specific Issues","title":"Vignette Improvement Plan for couplr","text":"Sources (rows) Targets (columns) Edge weights = costs Goal: Select one edge per source, one per target, minimizing total weight","code":"#### D. Add Conceptual Diagram Section  **Insert after Formal Definition (around line 45):**  ```markdown ### Visualizing the Assignment Problem  **Bipartite Graph Representation**  Imagine the LAP as a weighted bipartite graph: S₁ ───────2──────── T₁  │ ╲     ╱         ╱│  │  ╲4  ╱3        ╱ │  3   ╲ ╱        5   1  │    ╳          ╱  │  │   ╱ ╲       ╱    │ S₂ ─╱───╲──1──╱──── T₂    ╱     ╲   ╱     ╱   ╱       ╲ ╱    2 S₃ ────3───╳───── T₃ **Complementary Slackness Intuition**  At optimality, think of dual variables as \"prices\": - $u_i$ = how much source $i$ is willing to pay - $v_j$ = how much target $j$ is worth  An assignment $(i,j)$ is used only if $u_i + v_j = c_{ij}$ (price equals cost)."},{"path":[]},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"current-state-1","dir":"","previous_headings":"3. Matching Workflows (matching-workflows.Rmd)","what":"Current State","title":"Vignette Improvement Plan for couplr","text":"1134 lines (longest vignette) Applied concrete Reads like isolated steps rather cohesive journey Missing interpretation guidance pitfall discussion Good real-world example end comes late","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"a-move-real-world-example-earlier","dir":"","previous_headings":"3. Matching Workflows (matching-workflows.Rmd) > Improvements","what":"A. Move Real-World Example Earlier","title":"Vignette Improvement Plan for couplr","text":"Restructure follow real-world example throughout: Introduction: Present job training evaluation scenario Basic matching: First attempt match_couples() Preprocessing: need auto_scale = TRUE Balance assessment: match good enough? Refinements: Adding calipers, trying greedy Publication output: Tables effect estimates makes vignette narrative journey rather feature catalog.","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"b-add-what-can-go-wrong-section","dir":"","previous_headings":"3. Matching Workflows (matching-workflows.Rmd) > Improvements","what":"B. Add “What Can Go Wrong” Section","title":"Vignette Improvement Plan for couplr","text":"Insert “## Automatic Preprocessing” (around line 189): Solutions: - Relax caliper - Use coarser blocking - Consider propensity score matching wider bands","code":"### What Can Go Wrong  #### 1. Poor Match Quality Despite Convergence  **Symptom**: `match_couples()` completes but balance diagnostics show |std diff| > 0.25.  **Causes**: - Fundamental differences between groups that matching cannot overcome - Important confounders not included in matching variables - Caliper too loose  **Solutions**: - Add more matching variables - Tighten caliper (accept fewer matches) - Consider different estimand (ATT vs ATE) - Report sensitivity analysis  #### 2. Few or No Matches  **Symptom**: `n_matched` is much smaller than expected.  **Causes**: - Caliper too strict - Non-overlapping support (groups truly different) - Blocking variables create small strata  **Diagnosis**: ```r # Check overlap ggplot(bind_rows(left, right), aes(x = age, fill = group)) +   geom_density(alpha = 0.5)"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"id_3-imbalanced-but-optimal","dir":"","previous_headings":"3. Matching Workflows (matching-workflows.Rmd) > Improvements","what":"3. Imbalanced but Optimal","title":"Vignette Improvement Plan for couplr","text":"Symptom: Optimal matching completes balance worse greedy. Reality: Optimal minimizes total distance, balance metrics. globally optimal solution may sacrifice balance one variable gain another. Solutions: - Try greedy matching (may find different local optimum) - Add explicit balance constraints (future feature) - Use matching replacement (different estimand)","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"id_4-computational-issues","dir":"","previous_headings":"3. Matching Workflows (matching-workflows.Rmd) > Improvements","what":"4. Computational Issues","title":"Vignette Improvement Plan for couplr","text":"Symptom: match_couples() takes > 1 minute crashes. Causes: - n > 5000 optimal matching - Full cost matrix doesn’t fit memory Solutions: read : Overall assessment: well-balanced match. Proceed analysis. balance poor (|std_diff| > 0.25): 1. Check outliers problematic variable 2. Consider adding variable blocking 3. Tighten caliper 4. Report discuss limitations","code":"# For n > 5000: use greedy result <- greedy_couples(left, right, vars = vars, strategy = \"sorted\")  # For n > 10000: use blocking blocks <- matchmaker(left, right, block_type = \"cluster\", n_blocks = 20) result <- match_couples(blocks$left, blocks$right, vars = vars, block_id = \"block_id\") #### C. Add Interpretation Guidance Throughout  After each balance diagnostic output, add interpretation:  ```markdown ### Interpreting Balance Results  ```r print(balance) #> Balance Diagnostics #> ------------------- #> Variables: age, income, education #> #> Variable Statistics: #>   variable mean_left mean_right std_diff var_ratio ks_stat ks_p #>   age      45.2      45.8       -0.08    0.95      0.06    0.89 #>   income   58000     56500      0.12     1.08      0.09    0.45 #>   education 2.1      2.0        0.15     0.98      0.08    0.62 #### D. Add Section Transitions  Example transition after \"Basic Usage\":  > \"We've created our first matched sample, but how do we know it's any good? A match that pairs units with wildly different characteristics defeats the purpose. In the next section, we examine how automatic preprocessing prevents common data problems from degrading match quality.\"  ---  ## 4. Pixel Morphing (pixel-morphing.Rmd)  ### Current State - 884 lines - Excellent pedagogical intent - Conceptually rich but jumps between intuition and application - Purpose not fully clear (teach intuition? show feature? provide motivation?) - No connection to practical workflows  ### Improvements  #### A. Clarify Purpose Upfront  **Replace current Overview with:**  ```markdown ## Overview  This vignette serves three purposes:  1. **Visual intuition**: Use image morphing to build intuition for assignment problems. Pixels are entities, colors are features, positions are spatial coordinates—a direct analog to scientific matching.  2. **Scalability strategies**: Demonstrate three approximation approaches when exact LAP becomes infeasible (n > 1000).  3. **Scientific applications**: Show how the same algorithms apply to ecology, physics, and chemistry.  **This vignette is unusual**: Unlike the other couplr documentation, it emphasizes *understanding* over *doing*. If you're looking to solve a matching problem, start with `vignette(\"getting-started\")` or `vignette(\"matching-workflows\")`. Come here when you want to understand *why* these algorithms work and *when* approximations are appropriate.  ### Who This Vignette Is For  **Audience**: Advanced users, researchers, algorithm developers  **Prerequisites**: - Familiarity with `lap_solve()` (`vignette(\"getting-started\")`) - Basic understanding of complexity (Big-O notation) - Interest in algorithm design or scientific applications  **What You'll Learn**: - Why exact LAP becomes infeasible for large n - Three approximation strategies and their trade-offs - How matching problems appear in ecology, physics, and chemistry - Mathematical connections to optimal transport theory  **Time to Complete**: 45-60 minutes (conceptual reading)"},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"b-add-explicit-conceptual-scaffolding","dir":"","previous_headings":"3. Matching Workflows (matching-workflows.Rmd) > Improvements","what":"B. Add Explicit Conceptual Scaffolding","title":"Vignette Improvement Plan for couplr","text":"Insert Overview, “General Matching Problem”: Exact Solution Approximation Strategies Applications (Foundation) (exact fails) (Real-world) │ │ │ ▼ ▼ ▼ 1. Feature quantization Ecology: plots matching problem? 2. Hierarchical decomp. Physics: particles │ 3. Resolution reduction Chemistry: atoms │ │ │ ▼ ▼ ▼ Visual demo: Visual comparison Pseudocode pixel morphing approximations domain","code":"## How This Vignette Is Organized  We follow a specific arc: **Key insight**: The pixel morph is not just decoration—it's a computational testbed. Each pixel is an entity with features (color) and position, making the abstract matching problem concrete and visual."},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"c-add-connection-to-workflows-section","dir":"","previous_headings":"3. Matching Workflows (matching-workflows.Rmd) > Improvements","what":"C. Add “Connection to Workflows” Section","title":"Vignette Improvement Plan for couplr","text":"Insert Summary: n > 10000: n > 50000: Consider approximation strategies vignette, implemented via custom code using lap_solve() subproblems.","code":"## Connection to couplr Workflows  ### When Do These Strategies Apply?  The approximation strategies in this vignette become relevant in couplr's matching functions:  | Strategy | couplr Implementation | When to Use | |----------|----------------------|-------------| | Exact LAP | `match_couples(method = \"hungarian\")` | n < 3000 | | Feature quantization | Implicit in `scale = \"robust\"` | Reduces effective feature space | | Hierarchical | `matchmaker(block_type = \"cluster\")` | n > 3000, use blocking | | Resolution reduction | Future feature | Very large n |  ### Practical Recommendations  **For n < 3000**: Use `match_couples()` with exact algorithms. Runtime is seconds.  **For 3000 < n < 10000**: ```r # Use blocking to create smaller subproblems blocks <- matchmaker(left, right, block_type = \"cluster\", n_blocks = 10) result <- match_couples(blocks$left, blocks$right, vars, block_id = \"block_id\") # Use greedy matching result <- greedy_couples(left, right, vars, strategy = \"sorted\") #### D. Add Limitations Section  ```markdown ## Limitations of Approximation Strategies  ### Feature Quantization  **Works well when**: Features cluster naturally into distinct groups (e.g., vegetation types, particle species, atom types).  **Fails when**: - Feature space is continuous with no natural clusters - Important distinctions exist within clusters - Spatial structure doesn't align with feature groups  **Artifacts**: Band-like motion, loss of individual trajectories, discrete jumps.  ### Hierarchical Decomposition  **Works well when**: Spatial locality is meaningful (nearby entities should match nearby).  **Fails when**: - Optimal matches cross spatial boundaries (e.g., long-distance particle transport) - Patch boundaries cut through important structures - Hierarchy depth is mismatched to problem structure  **Artifacts**: Boundary discontinuities, suboptimal cross-region matches.  ### Resolution Reduction  **Works well when**: Coarse structure is sufficient, fine detail is noise.  **Fails when**: - Fine-grained structure matters (individual atom positions, exact pixel colors) - Upscaling introduces ambiguity  **Artifacts**: Blocky results, non-bijective mappings (multiple fine entities per coarse cell)."},{"path":[]},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"phase-1-cross-cutting-do-first","dir":"","previous_headings":"Implementation Checklist","what":"Phase 1: Cross-Cutting (Do First)","title":"Vignette Improvement Plan for couplr","text":"Create shared example dataset (hospital_example) Write standard documentation roadmap block Create transition paragraph templates","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"phase-2-getting-started","dir":"","previous_headings":"Implementation Checklist","what":"Phase 2: Getting Started","title":"Vignette Improvement Plan for couplr","text":"Add orientation paragraph (couplr, positioning) Add “Vignette ” block Restructure around hospital scheduling narrative Add “Common Pitfalls” section Add section transitions Review improve cross-references","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"phase-3-algorithms","dir":"","previous_headings":"Implementation Checklist","what":"Phase 3: Algorithms","title":"Vignette Improvement Plan for couplr","text":"Apply structured algorithm template algorithm Add comparative analysis section decision tree Add “Limitations Numerical Issues” section Add conceptual diagram (bipartite graph) Add algorithm-specific failure modes Improve cross-references","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"phase-4-matching-workflows","dir":"","previous_headings":"Implementation Checklist","what":"Phase 4: Matching Workflows","title":"Vignette Improvement Plan for couplr","text":"Restructure follow job training example throughout Add “Can Go Wrong” section Add interpretation guidance diagnostic Add section transitions Shorten/consolidate redundant sections Improve cross-references","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"phase-5-pixel-morphing","dir":"","previous_headings":"Implementation Checklist","what":"Phase 5: Pixel Morphing","title":"Vignette Improvement Plan for couplr","text":"Clarify purpose Overview Add conceptual scaffolding diagram Add “Connection Workflows” section Add limitations approximation strategies Improve cross-references","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"phase-6-final-integration","dir":"","previous_headings":"Implementation Checklist","what":"Phase 6: Final Integration","title":"Vignette Improvement Plan for couplr","text":"Verify cross-references work Check shared dataset used consistently Build vignettes verify rendering Review narrative flow across vignettes Final copyedit pass","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"estimated-effort","dir":"","previous_headings":"","what":"Estimated Effort","title":"Vignette Improvement Plan for couplr","text":"Total estimated effort: 3-5 focused work sessions","code":""},{"path":"https://gcol33.github.io/couplr/VIGNETTE_IMPROVEMENT_PLAN.html","id":"success-criteria","dir":"","previous_headings":"","what":"Success Criteria","title":"Vignette Improvement Plan for couplr","text":"improvements, vignette : Clearly state ’s ’ll learn Position within documentation ecosystem Follow narrative builds logically Provide interpretation just mechanics Discuss limitations honestly Cross-reference related vignettes appropriately Use shared dataset appropriate coherence documentation whole feel like chapters book rather independent reference documents.","code":""},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"automatic-preprocessing-and-scaling-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Automatic Preprocessing and Scaling","title":"couplr 1.0.0","text":"package now includes intelligent preprocessing improve matching quality: New auto_scale parameter match_couples() greedy_couples() enables automatic preprocessing Constant columns (SD = 0) automatically excluded warnings High missingness (>50%) triggers warnings Extreme skewness (|skewness| > 2) flagged “robust” scaling using median MAD (resistant outliers) “standardize” traditional mean-centering SD scaling “range” min-max normalization New preprocess_matching_vars() function manual preprocessing control Categorical variable encoding binary ordered factors","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"balance-diagnostics-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Balance Diagnostics","title":"couplr 1.0.0","text":"Comprehensive tools assess matching quality: Standardized differences: (mean_left - mean_right) / pooled_sd Variance ratios: SD_left / SD_right Kolmogorov-Smirnov tests distribution comparison Overall balance metrics (mean, max, % large imbalance) |Std Diff| < 0.10: Excellent balance |Std Diff| 0.10-0.25: Good balance |Std Diff| 0.25-0.50: Acceptable balance |Std Diff| > 0.50: Poor balance Per-block statistics quality ratings blocking used balance_table() creates publication-ready formatted tables Informative print methods interpretation guides","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"joined-matched-dataset-output-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Joined Matched Dataset Output","title":"couplr 1.0.0","text":"Create analysis-ready datasets directly matching results: Joins matched pairs original left right datasets Eliminates manual data wrangling matching Select specific variables via left_vars right_vars parameters Customizable suffixes (default: _left, _right) overlapping columns Optional metadata: pair_id, distance, block_id Works optimal greedy matching S3 method following broom package conventions Sensible defaults quick exploration Supports join_matched() parameters include_distance - Include/exclude matching distance include_pair_id - Include/exclude sequential pair IDs include_block_id - Include/exclude block identifiers Custom ID column support via left_id right_id Clean column ordering: pair_id → IDs → distance → block → variables","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"precomputed-and-reusable-distances-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Precomputed and Reusable Distances","title":"couplr 1.0.0","text":"Performance optimization exploring multiple matching strategies: Compute distances , reuse across multiple matching operations Store complete metadata: variables, distance metric, scaling method, timestamps Preserve original datasets seamless integration join_matched() Enable rapid exploration different matching parameters Performance improvement: ~60% faster trying multiple matching strategies Self-contained: cost matrix, IDs, metadata, original data Works match_couples() greedy_couples() Pass first argument instead datasets: match_couples(dist_obj, max_distance = 5) Informative print summary methods distance statistics Apply new max_distance calipers without recomputing distances Creates new distance object following copy--modify semantics Experiment different constraints efficiently Modified function signatures: match_couples(left, right = NULL, vars = NULL, ...) Automatically detects distance objects vs. datasets existing code continues work unchanged","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"parallel-processing-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Parallel Processing","title":"couplr 1.0.0","text":"Speed blocked matching multi-core processing: Enable parallel = TRUE automatic configuration Specify plan parallel = \"multisession\" future plan Works number blocks - automatically determines beneficial Gracefully falls back future packages installed Cross-platform support (Windows, Unix/Mac, clusters) Respects user-configured parallel backends Automatic worker management Clean restoration original plan execution Best 10+ blocks 50+ units per block Speedup scales number cores complexity Minimal overhead small problems Works blocking methods (exact, fuzzy, clustering) Compatible distance caching Step 4 Supports matching parameters (constraints, calipers, scaling)","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"fun-error-messages-and-cost-checking-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Fun Error Messages and Cost Checking","title":"couplr 1.0.0","text":"Like testthat, couplr makes errors light, memorable, helpful couple-themed messages: Automatically checks distance distributions matching Provides friendly, actionable warnings common problems Set FALSE skip checks production code 💔 “matches made - can’t couple without candidates!” 🔍 “constraints strict. Love can’t bloom vacuum!” ✨ Helpful suggestions: “Try increasing max_distance relaxing calipers” 💖 Success messages: “Excellent balance! couples well-matched!” many zeros: Warns duplicates identical values (>10% zero distances) Extreme costs: Detects skewed distributions (99th percentile > 10x 95th) Many forbidden pairs: Warns constraints eliminate >50% valid pairs Constant distances: Alerts distances identical Constant variables: Detects excludes variables variation Comprehensive analysis cost distributions Variable-specific problem detection Actionable suggestions fixes Quality rating (good/fair/poor) Emoji control: Disable options(couplr.emoji = FALSE) preferred Philosophy: Errors less intimidating, memorable, provide clear guidance","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"new-functions-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"New Functions","title":"couplr 1.0.0","text":"preprocess_matching_vars() - Main preprocessing orchestrator balance_diagnostics() - Comprehensive balance assessment balance_table() - Formatted balance tables reporting join_matched() - Create analysis-ready datasets matching results augment.matching_result() - Broom-style interface joined data compute_distances() - Precompute cache distance matrices update_constraints() - Modify constraints distance objects is_distance_object() - Type checking distance objects diagnose_distance_matrix() - Comprehensive distance diagnostics check_cost_distribution() - Check distribution problems Added robust scaling method using median MAD","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"documentation--examples-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Documentation & Examples","title":"couplr 1.0.0","text":"examples/auto_scale_demo.R - 5 preprocessing demonstrations examples/balance_diagnostics_demo.R - 6 balance diagnostic examples examples/join_matched_demo.R - 8 joined dataset demonstrations examples/distance_cache_demo.R - Distance caching reuse examples examples/parallel_matching_demo.R - 7 parallel processing examples examples/error_messages_demo.R - 10 fun error message demonstrations Complete implementation documentation (claude/IMPLEMENTATION_STEP1.md STEP6.md) functions full Roxygen documentation","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"tests-1-0-0","dir":"Changelog","previous_headings":"Major New Features (2025-11-19 Update)","what":"Tests","title":"couplr 1.0.0","text":"Added 34+ new tests (10 preprocessing, 11 balance diagnostics, 13 joined datasets, tests distance caching) 1509+ tests passing full backward compatibility","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"package-renamed-lapr--couplr-1-0-0","dir":"Changelog","previous_headings":"Major Changes (Initial 1.0.0 Release)","what":"Package Renamed: lapr → couplr","title":"couplr 1.0.0","text":"package renamed lapr couplr better reflect purpose general pairing matching toolkit. couplr = Optimal pairing matching via linear assignment","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"clean-release-1-0-0","dir":"Changelog","previous_headings":"Major Changes (Initial 1.0.0 Release)","what":"Clean 1.0.0 Release","title":"couplr 1.0.0","text":"First official stable release clean, well-organized codebase.","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"r-code-1-0-0","dir":"Changelog","previous_headings":"New Organization","what":"R Code","title":"couplr 1.0.0","text":"Eliminated 3 redundant files Consistent morph_* naming prefix Two-layer API: assignment() (low-level) + lap_solve() (tidy) 10 well-organized files (13)","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"c-code-1-0-0","dir":"Changelog","previous_headings":"New Organization","what":"C++ Code","title":"couplr 1.0.0","text":"src/core/ - Utilities headers src/interface/ - Rcpp exports src/solvers/ - 14 LAP algorithms src/gabow_tarjan/ - Gabow-Tarjan solver src/morph/ - Image morphing","code":""},{"path":[]},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"solvers-1-0-0","dir":"Changelog","previous_headings":"Features","what":"Solvers","title":"couplr 1.0.0","text":"Hungarian, Jonker-Volgenant, Auction (3 variants), SAP/SSP, SSAP-Bucket, Cost-scaling, Cycle-cancel, Gabow-Tarjan, Hopcroft-Karp, Line-metric, Brute-force, Auto-select","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"high-level-1-0-0","dir":"Changelog","previous_headings":"Features","what":"High-Level","title":"couplr 1.0.0","text":"✅ Tidy tibble interface ✅ Matrix & data frame inputs ✅ Grouped data frames ✅ Batch solving + parallelization ✅ K-best solutions (Murty, Lawler) ✅ Rectangular matrices ✅ Forbidden assignments (NA/Inf) ✅ Maximize/minimize ✅ Pixel morphing visualization","code":""},{"path":"https://gcol33.github.io/couplr/news/index.html","id":"api-1-0-0","dir":"Changelog","previous_headings":"","what":"API","title":"couplr 1.0.0","text":"lap_solve() - Main tidy interface lap_solve_batch() - Batch solving lap_solve_kbest() - K-best solutions assignment() - Low-level solver Utilities: get_total_cost(), as_assignment_matrix(), etc. Visualization: pixel_morph(), pixel_morph_animate() Development history “lapr” available git log v1.0.0.","code":""}]
